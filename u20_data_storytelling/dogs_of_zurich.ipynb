{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import some of the libaries that we will use\n",
    "import urllib.request\n",
    "import io\n",
    "import itertools as it\n",
    "import os\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import re\n",
    "import unicodedata\n",
    "import string\n",
    "\n",
    "from thefuzz import process\n",
    "from thefuzz import fuzz\n",
    "\n",
    "import json\n",
    "\n",
    "import colorcet as cc\n",
    "import panel as pn\n",
    "import panel.widgets as pnw\n",
    "\n",
    "from translate_app import translate_list_to_dict\n",
    "import recordlinkage as rl\n",
    "import missingno as msno\n",
    "import holoviews as hv\n",
    "import hvplot\n",
    "import hvplot.pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the zip file with the data from the link\n",
    "\n",
    "data_url = (\n",
    "    \"https://storage.googleapis.com/mrprime_dataset/dogs_of_zurich/dogs_of_zurich.zip\"\n",
    ")\n",
    "\n",
    "# create function which takes the url\n",
    "# retrieve zip and unzip it and return the csv files as a list\n",
    "\n",
    "\n",
    "def get_data(url):\n",
    "    \"\"\"Function which takes in a url, retrieves the zip file,\n",
    "    unzips it and returns the csv files as a list\"\"\"\n",
    "    # get the zip file\n",
    "    filename, headers = urllib.request.urlretrieve(url)\n",
    "    with zipfile.ZipFile(filename) as zip_ref:\n",
    "        # get the csv files\n",
    "        dfs = []\n",
    "        for file in zip_ref.namelist():\n",
    "            if file.endswith(\".csv\"):\n",
    "                csv_file = io.StringIO(zip_ref.read(file).decode(\"utf-8\"))\n",
    "                # readin csv as a pandas dataframe and append to list\n",
    "                df = pd.DataFrame()\n",
    "                df = pd.read_csv(csv_file)\n",
    "                df[\"roster\"] = file\n",
    "                dfs.append(df)\n",
    "\n",
    "    return dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call the function and assign the csv files to a variable\n",
    "dogs_of_zurich_dfs = get_data(data_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put all the column headers in one list\n",
    "list_of_headings = []\n",
    "for df in dogs_of_zurich_dfs:\n",
    "    list_of_headings += df.columns.tolist()\n",
    "\n",
    "more_german_words = list(\n",
    "    filter(lambda x: x is not np.nan, dogs_of_zurich_dfs[3].iloc[:, 2].unique())\n",
    ")\n",
    "list_of_headings += more_german_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ALTER',\n",
       " 'GEBURTSJAHR HUND',\n",
       " 'GESCHLECHT',\n",
       " 'GESCHLECHT HUND',\n",
       " 'HALTER ID',\n",
       " 'HUNDEFARBE',\n",
       " 'HUNDERASSE',\n",
       " 'HUNDERASSENTYP',\n",
       " 'HUNDERASSENTYP KURZ',\n",
       " 'Kleinwüchsig',\n",
       " 'RASSE1',\n",
       " 'RASSE1 MISCHLING',\n",
       " 'RASSE2',\n",
       " 'RASSE2 MISCHLING',\n",
       " 'RASSENTYP',\n",
       " 'Rassentypenliste I',\n",
       " 'Rassentypenliste II',\n",
       " 'STADTKREIS',\n",
       " 'STADTQUARTIER',\n",
       " 'roster'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Only keep unique column headers and replace underscores with spaces\n",
    "\n",
    "words_set = {word.replace(\"_\", \" \") for word in list_of_headings}\n",
    "words_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run translate app for columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionDenied",
     "evalue": "403 Cloud Translation API has not been used in project mrprime-349614 before or it is disabled. Enable it by visiting https://console.developers.google.com/apis/api/translate.googleapis.com/overview?project=mrprime-349614 then retry. If you enabled this API recently, wait a few minutes for the action to propagate to our systems and retry. [links {\n  description: \"Google developers console API activation\"\n  url: \"https://console.developers.google.com/apis/api/translate.googleapis.com/overview?project=mrprime-349614\"\n}\n, reason: \"SERVICE_DISABLED\"\ndomain: \"googleapis.com\"\nmetadata {\n  key: \"service\"\n  value: \"translate.googleapis.com\"\n}\nmetadata {\n  key: \"consumer\"\n  value: \"projects/mrprime-349614\"\n}\n]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_InactiveRpcError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32mb:\\project\\Springboard\\Springboard\\.venv\\lib\\site-packages\\google\\api_core\\grpc_helpers.py:75\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 75\u001b[0m     \u001b[39mreturn\u001b[39;00m callable_(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     76\u001b[0m \u001b[39mexcept\u001b[39;00m grpc\u001b[39m.\u001b[39mRpcError \u001b[39mas\u001b[39;00m exc:\n",
      "File \u001b[1;32mb:\\project\\Springboard\\Springboard\\.venv\\lib\\site-packages\\grpc\\_channel.py:1161\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable.__call__\u001b[1;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[0;32m   1155\u001b[0m (\n\u001b[0;32m   1156\u001b[0m     state,\n\u001b[0;32m   1157\u001b[0m     call,\n\u001b[0;32m   1158\u001b[0m ) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_blocking(\n\u001b[0;32m   1159\u001b[0m     request, timeout, metadata, credentials, wait_for_ready, compression\n\u001b[0;32m   1160\u001b[0m )\n\u001b[1;32m-> 1161\u001b[0m \u001b[39mreturn\u001b[39;00m _end_unary_response_blocking(state, call, \u001b[39mFalse\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m)\n",
      "File \u001b[1;32mb:\\project\\Springboard\\Springboard\\.venv\\lib\\site-packages\\grpc\\_channel.py:1004\u001b[0m, in \u001b[0;36m_end_unary_response_blocking\u001b[1;34m(state, call, with_call, deadline)\u001b[0m\n\u001b[0;32m   1003\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1004\u001b[0m     \u001b[39mraise\u001b[39;00m _InactiveRpcError(state)\n",
      "\u001b[1;31m_InactiveRpcError\u001b[0m: <_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.PERMISSION_DENIED\n\tdetails = \"Cloud Translation API has not been used in project mrprime-349614 before or it is disabled. Enable it by visiting https://console.developers.google.com/apis/api/translate.googleapis.com/overview?project=mrprime-349614 then retry. If you enabled this API recently, wait a few minutes for the action to propagate to our systems and retry.\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer ipv6:%5B2607:f8b0:4023:1000::5f%5D:443 {grpc_message:\"Cloud Translation API has not been used in project mrprime-349614 before or it is disabled. Enable it by visiting https://console.developers.google.com/apis/api/translate.googleapis.com/overview?project=mrprime-349614 then retry. If you enabled this API recently, wait a few minutes for the action to propagate to our systems and retry.\", grpc_status:7, created_time:\"2023-10-26T23:52:33.3958897+00:00\"}\"\n>",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mPermissionDenied\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32mb:\\project\\Springboard\\Springboard\\u20_data_storytelling\\dogs_of_zurich.ipynb Cell 7\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/b%3A/project/Springboard/Springboard/u20_data_storytelling/dogs_of_zurich.ipynb#Y154sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m translated_words \u001b[39m=\u001b[39m translate_list_to_dict(words_set, project_id\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mmrprimetranslator\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/b%3A/project/Springboard/Springboard/u20_data_storytelling/dogs_of_zurich.ipynb#Y154sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m translated_words\n",
      "File \u001b[1;32mb:\\project\\Springboard\\Springboard\\u20_data_storytelling\\translate_app.py:50\u001b[0m, in \u001b[0;36mtranslate_list_to_dict\u001b[1;34m(list_of_strings, project_id, source_lang, target_lang)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtranslate_list_to_dict\u001b[39m(\n\u001b[0;32m     44\u001b[0m     list_of_strings: Iterable[\u001b[39mstr\u001b[39m],\n\u001b[0;32m     45\u001b[0m     project_id: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mmrprimetranslator\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     46\u001b[0m     source_lang: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mde\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     47\u001b[0m     target_lang: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39men-US\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     48\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mdict\u001b[39m:\n\u001b[0;32m     49\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Translates a list of strings to a dictionary with the original text as key and the translated text as value.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 50\u001b[0m     response \u001b[39m=\u001b[39m translate_list(list_of_strings, project_id, source_lang, target_lang)\n\u001b[0;32m     51\u001b[0m     \u001b[39mreturn\u001b[39;00m translation_response_to_dict(list_of_strings, response)\n",
      "File \u001b[1;32mb:\\project\\Springboard\\Springboard\\u20_data_storytelling\\translate_app.py:17\u001b[0m, in \u001b[0;36mtranslate_list\u001b[1;34m(list_of_strings, project_id, source_lang, target_lang)\u001b[0m\n\u001b[0;32m     15\u001b[0m location \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mglobal\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     16\u001b[0m parent \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mprojects/\u001b[39m\u001b[39m{\u001b[39;00mproject_id\u001b[39m}\u001b[39;00m\u001b[39m/locations/\u001b[39m\u001b[39m{\u001b[39;00mlocation\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m---> 17\u001b[0m response \u001b[39m=\u001b[39m client\u001b[39m.\u001b[39;49mtranslate_text(\n\u001b[0;32m     18\u001b[0m     request\u001b[39m=\u001b[39;49m{\n\u001b[0;32m     19\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mparent\u001b[39;49m\u001b[39m\"\u001b[39;49m: parent,\n\u001b[0;32m     20\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mcontents\u001b[39;49m\u001b[39m\"\u001b[39;49m: list_of_strings,\n\u001b[0;32m     21\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mmime_type\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39mtext/plain\u001b[39;49m\u001b[39m\"\u001b[39;49m,  \u001b[39m# mime types: text/plain, text/html\u001b[39;49;00m\n\u001b[0;32m     22\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39msource_language_code\u001b[39;49m\u001b[39m\"\u001b[39;49m: source_lang,\n\u001b[0;32m     23\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mtarget_language_code\u001b[39;49m\u001b[39m\"\u001b[39;49m: target_lang,\n\u001b[0;32m     24\u001b[0m     }\n\u001b[0;32m     25\u001b[0m )\n\u001b[0;32m     26\u001b[0m \u001b[39mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mb:\\project\\Springboard\\Springboard\\.venv\\lib\\site-packages\\google\\cloud\\translate_v3\\services\\translation_service\\client.py:641\u001b[0m, in \u001b[0;36mTranslationServiceClient.translate_text\u001b[1;34m(self, request, parent, target_language_code, contents, model, mime_type, source_language_code, retry, timeout, metadata)\u001b[0m\n\u001b[0;32m    636\u001b[0m metadata \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(metadata) \u001b[39m+\u001b[39m (\n\u001b[0;32m    637\u001b[0m     gapic_v1\u001b[39m.\u001b[39mrouting_header\u001b[39m.\u001b[39mto_grpc_metadata(((\u001b[39m\"\u001b[39m\u001b[39mparent\u001b[39m\u001b[39m\"\u001b[39m, request\u001b[39m.\u001b[39mparent),)),\n\u001b[0;32m    638\u001b[0m )\n\u001b[0;32m    640\u001b[0m \u001b[39m# Send the request.\u001b[39;00m\n\u001b[1;32m--> 641\u001b[0m response \u001b[39m=\u001b[39m rpc(\n\u001b[0;32m    642\u001b[0m     request,\n\u001b[0;32m    643\u001b[0m     retry\u001b[39m=\u001b[39;49mretry,\n\u001b[0;32m    644\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[0;32m    645\u001b[0m     metadata\u001b[39m=\u001b[39;49mmetadata,\n\u001b[0;32m    646\u001b[0m )\n\u001b[0;32m    648\u001b[0m \u001b[39m# Done; return the response.\u001b[39;00m\n\u001b[0;32m    649\u001b[0m \u001b[39mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mb:\\project\\Springboard\\Springboard\\.venv\\lib\\site-packages\\google\\api_core\\gapic_v1\\method.py:131\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[1;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compression \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    129\u001b[0m     kwargs[\u001b[39m\"\u001b[39m\u001b[39mcompression\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m compression\n\u001b[1;32m--> 131\u001b[0m \u001b[39mreturn\u001b[39;00m wrapped_func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mb:\\project\\Springboard\\Springboard\\.venv\\lib\\site-packages\\google\\api_core\\timeout.py:120\u001b[0m, in \u001b[0;36mTimeToDeadlineTimeout.__call__.<locals>.func_with_timeout\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    117\u001b[0m     \u001b[39m# Avoid setting negative timeout\u001b[39;00m\n\u001b[0;32m    118\u001b[0m     kwargs[\u001b[39m\"\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m(\u001b[39m0\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout \u001b[39m-\u001b[39m time_since_first_attempt)\n\u001b[1;32m--> 120\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mb:\\project\\Springboard\\Springboard\\.venv\\lib\\site-packages\\google\\api_core\\grpc_helpers.py:77\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     75\u001b[0m     \u001b[39mreturn\u001b[39;00m callable_(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     76\u001b[0m \u001b[39mexcept\u001b[39;00m grpc\u001b[39m.\u001b[39mRpcError \u001b[39mas\u001b[39;00m exc:\n\u001b[1;32m---> 77\u001b[0m     \u001b[39mraise\u001b[39;00m exceptions\u001b[39m.\u001b[39mfrom_grpc_error(exc) \u001b[39mfrom\u001b[39;00m \u001b[39mexc\u001b[39;00m\n",
      "\u001b[1;31mPermissionDenied\u001b[0m: 403 Cloud Translation API has not been used in project mrprime-349614 before or it is disabled. Enable it by visiting https://console.developers.google.com/apis/api/translate.googleapis.com/overview?project=mrprime-349614 then retry. If you enabled this API recently, wait a few minutes for the action to propagate to our systems and retry. [links {\n  description: \"Google developers console API activation\"\n  url: \"https://console.developers.google.com/apis/api/translate.googleapis.com/overview?project=mrprime-349614\"\n}\n, reason: \"SERVICE_DISABLED\"\ndomain: \"googleapis.com\"\nmetadata {\n  key: \"service\"\n  value: \"translate.googleapis.com\"\n}\nmetadata {\n  key: \"consumer\"\n  value: \"projects/mrprime-349614\"\n}\n]"
     ]
    }
   ],
   "source": [
    "translated_words = translate_list_to_dict(words_set, project_id=\"mrprimetranslator\")\n",
    "translated_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# translate headers using the translate app\n",
    "# translated_words = translate_app.translate_list(\n",
    "#     words_set, project_id=\"mrprimetranslator\"\n",
    "# )\n",
    "# translated_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put the underscores back in the original headings\n",
    "translated_headings_underscores = {\n",
    "    key.replace(\" \", \"_\"): value.lower().replace(\" \", \"_\").replace(\"'s\", \"\")\n",
    "    for key, value in translated_words.items()\n",
    "}\n",
    "translated_headings_underscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is actually translated to districts as in the 12 districts of Zurich\n",
    "translated_headings_underscores[\"STADTKREIS\"] = \"district\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put the translated headings as the new column names\n",
    "for df in dogs_of_zurich_dfs:\n",
    "    df.rename(columns=translated_headings_underscores, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the 2 dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine 3 of 4 dataframes into one with dog owner info\n",
    "dog_owner_df = pd.DataFrame()\n",
    "dog_owner_df = pd.concat(\n",
    "    [dogs_of_zurich_dfs[0], dogs_of_zurich_dfs[1], dogs_of_zurich_dfs[2]], axis=0\n",
    ")\n",
    "dog_owner_df.info()\n",
    "\n",
    "# name last dataframe with dog breeds info\n",
    "dog_df = pd.DataFrame()\n",
    "dog_df = dogs_of_zurich_dfs[3]\n",
    "dog_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(dog_owner_df.sample(3))\n",
    "dog_df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.matrix(dog_owner_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only null values in breed2_mixed so drop column\n",
    "dog_owner_df = dog_owner_df.drop(columns=[\"breed2_mixed_breed\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.matrix(dog_owner_df.sort_values(by=[\"breed2\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset index\n",
    "dog_owner_df = dog_owner_df.reset_index(drop=True)\n",
    "# make the district column a category\n",
    "dog_owner_df[\"district\"] = dog_owner_df[\"district\"].astype(\"category\")\n",
    "\n",
    "# take the first 4 char of roster only and make it an ordered category colummn\n",
    "dog_owner_df[\"roster\"] = dog_owner_df[\"roster\"].str[:4]\n",
    "dog_owner_df[\"roster\"] = pd.Categorical(dog_owner_df[\"roster\"], ordered=True)\n",
    "\n",
    "\n",
    "# add a column with the first year the owner appeared in the roster\n",
    "dog_owner_df[\"first_appearance\"] = dog_owner_df.groupby(\"holder_id\")[\n",
    "    \"roster\"\n",
    "].transform(\"min\")\n",
    "\n",
    "# add column for the numberr of appearances in the roster\n",
    "dog_owner_df[\"appearances\"] = dog_owner_df.groupby(\"holder_id\")[\"roster\"].transform(\n",
    "    \"nunique\"\n",
    ")\n",
    "\n",
    "# add a column with the number of dogs per owner\n",
    "dog_owner_df[\"dog_count\"] = dog_owner_df.groupby([\"holder_id\", \"roster\"])[\n",
    "    \"holder_id\"\n",
    "].transform(\"size\")\n",
    "\n",
    "dog_owner_df.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dog with a year of birth after the roster year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the holder_id of the bad entries and observe other entries with the same holder_id\n",
    "bad_entry_holder_id = dog_owner_df[\n",
    "    dog_owner_df[\"dog_year_of_birth\"] > dog_owner_df[\"roster\"].astype(int)\n",
    "][\"holder_id\"]\n",
    "\n",
    "\n",
    "dog_owner_df[dog_owner_df[\"holder_id\"].isin(bad_entry_holder_id)].sort_values(\n",
    "    by=\"holder_id\"\n",
    ")\n",
    "\n",
    "# dog_owner_df[dog_owner_df[\"holder_id\"].isin(bad_entry_holder_id)].index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have Rosters for 3 separate years, we can see if that owner corrected its wrong entry in the later years. We can drop since the bad entries are consistent with no clue as to the correct entry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(dog_owner_df.shape)\n",
    "\n",
    "bad_entry_index = dog_owner_df[\n",
    "    dog_owner_df[\"holder_id\"].isin(bad_entry_holder_id)\n",
    "].index\n",
    "\n",
    "dog_owner_df.drop(bad_entry_index, inplace=True)\n",
    "\n",
    "dog_owner_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dogs with a year of birth too far before the roster year (before 1990) which is plausible, but not probable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the holder_id of the bad entries\n",
    "bad_entry_holder_id = dog_owner_df[dog_owner_df[\"dog_year_of_birth\"] < 1990][\n",
    "    \"holder_id\"\n",
    "]\n",
    "\n",
    "# isolate entries from these holder_ids and group them by holder_id\n",
    "dog_owner_group = (\n",
    "    dog_owner_df[dog_owner_df[\"holder_id\"].isin(bad_entry_holder_id)]\n",
    "    .sort_values(by=\"holder_id\")\n",
    "    .groupby(\"holder_id\")\n",
    ")\n",
    "\n",
    "dog_owner_df[dog_owner_df[\"holder_id\"].isin(bad_entry_holder_id)].sort_values(\n",
    "    by=\"holder_id\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can replace bad entries with matching entries from the later roster years as the owner corrected the value for th elater rosters. Luckly these owners only have one dog each.\n",
    "\n",
    "The one bad entry of `1980` with only 1 appearance we cannot safely replace so we drop it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these entries only have 1 dog so we can replace the year of birth with the mode making some assumptions\n",
    "dog_owner_df.loc[\n",
    "    dog_owner_df[\"holder_id\"].isin(bad_entry_holder_id), \"dog_year_of_birth\"\n",
    "] = dog_owner_group[\"dog_year_of_birth\"].transform(lambda x: x.mode().iloc[0])\n",
    "\n",
    "dog_owner_df[dog_owner_df[\"holder_id\"].isin(bad_entry_holder_id)].sort_values(\n",
    "    by=\"holder_id\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog_owner_df.city_quarter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the one with only 1 appearance we cannot safely replace so we drop it\n",
    "dog_owner_df = dog_owner_df.drop(\n",
    "    dog_owner_df[dog_owner_df[\"holder_id\"] == 129251].index\n",
    ")\n",
    "\n",
    "# No more 20/30something years-old dogs\n",
    "dog_owner_df[dog_owner_df[\"dog_year_of_birth\"] < 1990][\"holder_id\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add 1 to the dog age so that no dog has an age of 0. Consider it the dog's year of living."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dog's age is calculated by subtracting the year of birth from the year of the roster\n",
    "# added 1 in case i wanted to do something with log down the line\n",
    "dog_owner_df[\"dog_age\"] = (\n",
    "    dog_owner_df[\"roster\"].astype(int) - dog_owner_df[\"dog_year_of_birth\"] + 1\n",
    ")\n",
    "dog_owner_df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog_owner_df[\"dog_age\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(dog_owner_df[dog_owner_df.age.isnull()])\n",
    "\n",
    "\n",
    "# Drop these 5 rows with unknown\n",
    "dog_owner_df.dropna(subset=[\"age\"], inplace=True)\n",
    "dog_owner_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# owners each year\n",
    "owner_2015 = set(dog_owner_df[dog_owner_df[\"roster\"] == \"2015\"][\"holder_id\"])\n",
    "owner_2016 = set(dog_owner_df[dog_owner_df[\"roster\"] == \"2016\"][\"holder_id\"])\n",
    "owner_2017 = set(dog_owner_df[dog_owner_df[\"roster\"] == \"2017\"][\"holder_id\"])\n",
    "\n",
    "print(f\"{len(owner_2015)} initial owners in 2015\")\n",
    "# constant owners for all 3 years\n",
    "new_2016 = owner_2016.difference(owner_2015)\n",
    "returning_2016 = owner_2016.intersection(owner_2015)\n",
    "print(f\"{len(new_2016)} new owners in 2016 and {len(returning_2016)} returning owners\")\n",
    "\n",
    "new_2017 = owner_2017.difference(owner_2015.union(owner_2016))\n",
    "returning_2017 = owner_2017.intersection(owner_2015.union(owner_2016))\n",
    "print(f\"{len(new_2017)} new owners in 2017 and {len(returning_2017)} returning owners\")\n",
    "\n",
    "constistent_owners = owner_2015.intersection(owner_2016).intersection(owner_2017)\n",
    "print(f\"{len(constistent_owners)} constant owners\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog_owner_df[\"age\"] = pd.Categorical(\n",
    "    dog_owner_df[\"age\"],\n",
    "    ordered=True,\n",
    "    categories=[\n",
    "        \"11-20\",\n",
    "        \"21-30\",\n",
    "        \"31-40\",\n",
    "        \"41-50\",\n",
    "        \"51-60\",\n",
    "        \"61-70\",\n",
    "        \"71-80\",\n",
    "        \"81-90\",\n",
    "        \"91-100\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "\n",
    "# dog_owner_df.plot(\n",
    "#     kind=\"bar\",\n",
    "#     column=\"age\",\n",
    "#     by=\"roster\",\n",
    "#     bins=9,\n",
    "#     figsize=(10, 5),\n",
    "#     histtype=\"step\",\n",
    "# )\n",
    "dog_owner_df.groupby(\n",
    "    [\n",
    "        \"age\",\n",
    "        \"roster\",\n",
    "    ]\n",
    ").size().unstack().hvplot.bar(\n",
    "    xlabel=\"\",\n",
    "    rot=90,\n",
    "    legend=True,\n",
    "    tools=[\"hover\", \"box_select\"],\n",
    "    title=\"Owners age distribution each roster\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def age_group(age):\n",
    "    \"\"\"Function which widen the age groups of the oldest and youngest dog owners\"\"\"\n",
    "    if age == \"71-80\" or age == \"81-90\" or age == \"91-100\":\n",
    "        return \"71+\"\n",
    "    elif age == \"11-20\" or age == \"21-30\":\n",
    "        return \"11-30\"\n",
    "\n",
    "    else:\n",
    "        return age\n",
    "\n",
    "\n",
    "dog_owner_df[\"age_group\"] = dog_owner_df[\"age\"].apply(age_group).dropna()\n",
    "dog_owner_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog_owner_df[\"age_range\"] = dog_owner_df[\"age\"].str[:1] + \"0s\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"Number of null values in column 'breed_type': \",\n",
    "    dog_owner_df.breed_type.isnull().sum(),\n",
    ")\n",
    "\n",
    "# get the breed1 for the entries with missing breed_type\n",
    "breed_missing_breed_type = dog_owner_df[dog_owner_df[\"breed_type\"].isnull()][\n",
    "    \"breed1\"\n",
    "].unique()\n",
    "\n",
    "breed_missing_breed_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog_owner_df.groupby([\"breed_type\", \"roster\"]).size().unstack().hvplot.bar(\n",
    "    xlabel=\"\",\n",
    "    rot=90,\n",
    "    legend=True,\n",
    "    tools=[\"hover\", \"box_select\"],\n",
    "    title=\"Breed type distribution each roster\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", 100)\n",
    "bully_breed = dog_owner_df[dog_owner_df.breed_type == \"II\"][\"breed1\"].unique().tolist()\n",
    "dog_owner_df[dog_owner_df.breed1.isin(bully_breed)]\n",
    "dog_owner_df[dog_owner_df.breed_type == \"II\"].sort_values(\n",
    "    by=\"dog_count\", ascending=False\n",
    ")[\"holder_id\"].nunique()\n",
    "\n",
    "# bully_pattern = re.compile(r\"[P|p]it\\s?[B|b]ull|Staffordshire\")\n",
    "\n",
    "# dog_owner_df[\n",
    "#     dog_owner_df[\"breed1\"].str.contains(bully_pattern, na=False)\n",
    "#     | dog_owner_df[\"breed2\"].str.contains(bully_pattern, na=False)\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find these breeds in the dog_df and get the breed_type from there\n",
    "dog_df.drop(\"roster\", axis=1, inplace=True)\n",
    "dog_df[dog_df[\"dog_breed\"].isin(breed_missing_breed_type)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see what other dogs of these breeds have as breed_type\n",
    "dog_owner_df[dog_owner_df[\"breed1\"].isin(breed_missing_breed_type)].sort_values(\n",
    "    by=[\"breed1\", \"holder_id\"]\n",
    ")\n",
    "\n",
    "dog_breed_group = dog_owner_df[\n",
    "    dog_owner_df[\"breed1\"].isin(breed_missing_breed_type)\n",
    "].groupby(\"breed1\")\n",
    "\n",
    "# most breeds have a unanimous breed_type so we can just fillna with the mode\n",
    "display(dog_breed_group[\"breed_type\"].value_counts())\n",
    "\n",
    "\n",
    "# Fill in the missing breed_type with the mode of the breed1\n",
    "dog_owner_df[\"breed_type\"].fillna(\n",
    "    dog_owner_df.groupby(\"breed1\")[\"breed_type\"].transform(lambda x: x.mode().iloc[0]),\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "dog_owner_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_district_holder_id = dog_owner_df[dog_owner_df[\"district\"].isna()][\n",
    "    \"holder_id\"\n",
    "].unique()\n",
    "\n",
    "dog_owner_df[dog_owner_df[\"holder_id\"].isin(missing_district_holder_id)]\n",
    "\n",
    "# drop these missing rows with no district info\n",
    "dog_owner_df.dropna(subset=[\"district\"], inplace=True)\n",
    "\n",
    "dog_owner_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the string columns to lower case\n",
    "breed_columns = [\"breed1\", \"breed2\", \"breed1_mixed_breed\", \"breed_type\"]\n",
    "# for col in breed_columns:\n",
    "#     dog_owner_df[col] = dog_owner_df[col].str.lower()\n",
    "\n",
    "dog_owner_df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog_owner_df[\"breed1_mixed_breed\"].unique()\n",
    "dog_owner_df[\"breed1_mixed_breed\"].nunique()\n",
    "dog_owner_df[breed_columns].describe()\n",
    "# dog_df[\"dog_breed\"].unique()\n",
    "dog_owner_df[\"breed1\"].dropna().unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all of the dog breeds to translate and put in a list\n",
    "breed_list1 = dog_owner_df[[\"breed1\", \"breed2\"]].stack().dropna().unique().tolist()\n",
    "breed_list2 = dog_df[\"dog_breed\"].unique().tolist()\n",
    "breed_list3 = list(\n",
    "    filter(lambda x: x is not np.nan, dog_owner_df[\"breed1_mixed_breed\"].unique())\n",
    ")\n",
    "breed_set = set(breed_list1 + breed_list2 + breed_list3)\n",
    "len(breed_set)\n",
    "# breed_set\n",
    "unmatched_breeds_df = pd.DataFrame()\n",
    "unmatched_breeds_df[\"breed\"] = list(breed_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# breed_list1 = [\"Pitbull\", \"German Shepherd\", \"Golden Retriever\"]\n",
    "# breed_list2 = [\"Labrador Retriever\", \"Poodle\", \"Pit Bull\"]\n",
    "\n",
    "bully_pattern = re.compile(r\"[P|p]it\\s?[B|b]ull\")\n",
    "russel_pattern = re.compile(r\"([P|p]arson|[J|j]ack|[R|r]ussel[l]?)+\")\n",
    "\n",
    "list(filter(bully_pattern.findall, sorted(set(breed_list1 + breed_list2))))\n",
    "list(filter(russel_pattern.findall, sorted(set(breed_list1 + breed_list2))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the AKC breeds saved to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the dog_breeds dataframe from the data folder\n",
    "akc_breeds_df = pd.read_csv(\"../data/akc_dog_breeds.csv\")\n",
    "akc_breeds_df = akc_breeds_df.rename(columns={\"breed\": \"akc_breed\"})\n",
    "# akc_dog_breeds.sample(3)\n",
    "\n",
    "fci_breeds_df = pd.read_csv(\"../data/fci_breeds_trans.csv\")\n",
    "# fci_dog_breeds\n",
    "\n",
    "# breed_choices = (\n",
    "#     akc_breeds_df[\"akc_breed\"].tolist() + fci_breeds_df[\"breed_en\"].tolist()\n",
    "# )\n",
    "# breed_choices = list(set(breed_choices))\n",
    "# breed_choices_df = pd.DataFrame(breed_choices, columns=[\"breed\"])\n",
    "# # breed_choices_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", 200)\n",
    "\n",
    "\n",
    "def remove_accents(input_str):\n",
    "    \"\"\"Function to remove accents from a string.\n",
    "    It takes as argument a string and returns the same string\n",
    "    without accents.\"\"\"\n",
    "    nfkd_form = (\n",
    "        unicodedata.normalize(\"NFKD\", input_str).encode(\"ASCII\", \"ignore\").decode()\n",
    "    )\n",
    "    # return \"\".join([c for c in nfkd_form if not unicodedata.combining(c)])\n",
    "    return nfkd_form\n",
    "\n",
    "\n",
    "remove_accents(\"résuméö\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "punc = string.punctuation.replace(\",\", \"\").replace(\"-\", \"\")  # + \"’\"\n",
    "\n",
    "pd.options.display.max_colwidth = 100\n",
    "\n",
    "fci_breeds_df[\"alt_names\"] = (\n",
    "    fci_breeds_df[\"breed\"]\n",
    "    + \", \"\n",
    "    + fci_breeds_df[\"translations\"]\n",
    "    .str.replace(rf\"[{punc}]\", \"\", regex=True)\n",
    "    .str.strip()\n",
    ")\n",
    "fci_breeds_df[\"alt_names\"] = (\n",
    "    fci_breeds_df[\"alt_names\"]\n",
    "    .str.lower()\n",
    "    .str.split(\",\")\n",
    "    .apply(lambda x: [i.strip() for i in x])\n",
    ")\n",
    "\n",
    "\n",
    "fci_breeds_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breed_set = {breed.lower() for breed in breed_set}\n",
    "breed_to_trans = {breed: [] for breed in breed_set}\n",
    "\n",
    "for index, row in enumerate(fci_breeds_df[\"no_accent\"]):\n",
    "    for item in set(row).intersection(breed_set):\n",
    "        breed_to_trans[item].append(index)\n",
    "\n",
    "matches_df = pd.DataFrame.from_dict(breed_to_trans, orient=\"index\").reset_index()\n",
    "matches_df.columns = [\"breed\", \"index_match\"]\n",
    "matches_df[matches_df[\"index_match\"].notnull()].sort_values(by=\"index_match\")\n",
    "# breed_to_trans\n",
    "# fci_breeds_df\n",
    "# punc\n",
    "\n",
    "\n",
    "def find_standard_breed_index(breed, remove_accents=True):\n",
    "    \"\"\"Func which matches the breed to the standard breed\"\"\"\n",
    "    if remove_accents:\n",
    "        breed = unicodedata.normalize(\"NFKD\", breed)\n",
    "    index = fci_breeds_df[\n",
    "        fci_breeds_df[\"no_accent\"].apply(lambda x: breed.casefold() in x)\n",
    "    ].index\n",
    "    if index.empty:\n",
    "        return np.nan\n",
    "    return index[0]\n",
    "\n",
    "\n",
    "find_standard_breed_index(\"german shepherd dog\")\n",
    "dog_df[\"standard_index\"] = dog_df[\"dog_breed\"].apply(find_standard_breed_index)\n",
    "dog_df[dog_df[\"standard_index\"].notnull()].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_dict = {}\n",
    "standard_dict = {\n",
    "    row[1][\"breed_en\"]: row[1][\"alt_names\"] for row in fci_breeds_df.iterrows()\n",
    "}\n",
    "\n",
    "\n",
    "all_fci_names = list(it.chain.from_iterable(fci_breeds_df[\"alt_names\"]))\n",
    "# all_fci_names\n",
    "# standard_dict\n",
    "\n",
    "# print(row[1][\"breed_en\"])\n",
    "# print(row[1][\"no_accent\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_breed_name(name, choices, scorer=fuzz.token_sort_ratio):\n",
    "    mismo, score, *_ = process.extractOne(name, choices, scorer=scorer)\n",
    "    return mismo, score\n",
    "\n",
    "\n",
    "unmatched_breeds_df[\"closest_match\"], unmatched_breeds_df[\"score\"] = zip(\n",
    "    *unmatched_breeds_df[\"breed\"].apply(\n",
    "        lambda x: match_breed_name(x, all_fci_names, scorer=fuzz.token_set_ratio)\n",
    "    )\n",
    ")\n",
    "\n",
    "unmatched_breeds_df[\"standard\"] = unmatched_breeds_df[\n",
    "    unmatched_breeds_df[\"score\"] > 80\n",
    "][\"closest_match\"].apply(\n",
    "    lambda x: [key for key, value in standard_dict.items() if x in value][0]\n",
    ")\n",
    "matches_df = unmatched_breeds_df[unmatched_breeds_df[\"standard\"].notnull()]\n",
    "matches_df\n",
    "unmatched_breeds_df[unmatched_breeds_df[\"standard\"].isnull()].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "match_list = []\n",
    "\n",
    "for breed in breed_set:\n",
    "    no_accent_breed = remove_accents(breed)\n",
    "\n",
    "    matches = fci_breeds_df[\n",
    "        fci_breeds_df[\"no_accent\"].apply(lambda breeds: breed in breeds)\n",
    "    ]\n",
    "    if len(matches):\n",
    "        row = matches.iloc[0]\n",
    "\n",
    "        match_list.append(\n",
    "            {\n",
    "                \"from_breed_set\": breed,\n",
    "                \"fci_index\": matches.index[0],\n",
    "                \"fci_translate\": row.translations,\n",
    "            },\n",
    "        )\n",
    "    else:\n",
    "        match_list.append(\n",
    "            {\"from_breed_set\": breed, \"fci_index\": None, \"fci_translate\": None},\n",
    "        )\n",
    "match_df = pd.DataFrame(match_list)\n",
    "# match_df[match_df[\"fci_index\"].isna()]\n",
    "match_df[match_df[\"fci_index\"].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pn.state.kill_all_servers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_df(breed):\n",
    "    \"\"\"Function which filters the dog_df by breed and returns a dataframe\"\"\"\n",
    "    return fci_breeds_df[\n",
    "        fci_breeds_df[\"translations\"]\n",
    "        .apply(lambda x: unicodedata.normalize(\"NFKD\", x))\n",
    "        .str.contains(breed, case=False, regex=True)\n",
    "    ][[\"breed\", \"translations\"]]\n",
    "\n",
    "\n",
    "breed_filter = pnw.TextInput(placeholder=\"Enter breed here\")\n",
    "\n",
    "filtered_view = pn.Column(\n",
    "    pn.Column(breed_filter),\n",
    "    pn.panel(pn.bind(filter_df, breed=breed_filter)),\n",
    ")\n",
    "filtered_view.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_akc_breed(breed):\n",
    "    \"\"\"Function which finds the AKC breed in the dog_breeds dataframe\"\"\"\n",
    "    return akc_breeds_df[akc_breeds_df[\"akc_breed\"].str.contains(breed, case=False)]\n",
    "\n",
    "\n",
    "search_akc_breed(\"swiss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matched_breeds = {}\n",
    "# matched_breeds = {\n",
    "#     breed: breed.lower()\n",
    "#     for breed in breed_set\n",
    "#     if breed.lower() in akc_dog_breeds[\"akc_breed\"].tolist()\n",
    "# }\n",
    "# print(f\"{len(matched_breeds)} breed entries found in AKC list.\")\n",
    "\n",
    "# sorted(breed_set)\n",
    "# unmatched_breeds = sorted(breed_set.difference(matched_breeds))\n",
    "# print(f\"{len(unmatched_breeds)} breed entries not yet found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run translate app for breeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# translate the dog breeds\n",
    "unmatched_translations = translate_app.translate_list(unmatched_breeds)\n",
    "# unmatched_translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the items in unmatched_translations which are in unmatched_breeds\n",
    "# unmatched_breeds = get_updated_unmatched_breeds(matches)\n",
    "unmatched_dict = {\n",
    "    breed: unmatched_translations.get(breed) for breed in unmatched_breeds\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manuel inputs:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manually change some of the breeds which may not have been translated correctly or at all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unmatched_translations[\"västgötaspets\"] = \"swedish vallhund\"\n",
    "unmatched_translations[\"jack russel terrier\"] = \"parson russell terrier\"\n",
    "unmatched_translations[\"berger blanc suisse\"] = \"white swiss shepherd dog\"\n",
    "unmatched_translations[\"trüffelhund\"] = \"lagotto romagnolo\"\n",
    "unmatched_translations[\"Polski Owczarek Nizinny\"] = \"polish lowland sheepdog\"\n",
    "unmatched_translations[\"Do-Khyi\"] = \"tibetan mastiff\"\n",
    "\n",
    "# unmatched_translations[\"zwergspitz\"] = \"pomeranian\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unmatched_df = pd.DataFrame()\n",
    "unmatched_df = get_translated_unmatched_df(unmatched_dict)\n",
    "fuzzy_matches_df = apply_match_breed_name(\n",
    "    unmatched_df, \"breed_en\", breed_choices, scorer=fuzz.token_sort_ratio\n",
    ")\n",
    "\n",
    "matches = fuzzy_matches_df[fuzzy_matches_df[\"score\"] > 90][\n",
    "    [\"breed_de\", \"closest_match\"]\n",
    "]\n",
    "update_matches = dict(zip(matches[\"breed_de\"], matches[\"closest_match\"]))\n",
    "\n",
    "matches_dict |= update_matches\n",
    "\n",
    "unmatched_breeds = get_updated_unmatched_breeds(matches_dict)\n",
    "len(unmatched_breeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unmatched_df = pd.DataFrame()\n",
    "unmatched_df[\"breed_de\"] = unmatched_breeds\n",
    "\n",
    "unmatched_df = apply_match_breed_name(\n",
    "    unmatched_df, \"breed_de\", akc_breeds_df[\"akc_breed\"].tolist()\n",
    ")\n",
    "unmatched_df.set_index(\"breed_de\", inplace=True)\n",
    "\n",
    "matches.update(unmatched_df[unmatched_df[\"score\"] > 90][\"closest_match\"].to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog_owner_df.loc[\n",
    "    (dog_owner_df[\"breed1_mixed_breed_en\"].notnull())\n",
    "    | (dog_owner_df[\"breed2_en\"].notnull())\n",
    "    | (dog_owner_df[\"breed1_en\"].str.contains(r\"mixed.*\", regex=True)),\n",
    "    \"mixed_breed\",\n",
    "] = True\n",
    "dog_owner_df[\"mixed_breed\"].fillna(False, inplace=True)\n",
    "dog_owner_df[\"pure_breed\"] = ~dog_owner_df[\"mixed_breed\"]\n",
    "only_child_dogs = dog_owner_df[dog_owner_df[\"dog_count\"] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the translation from the breed_translations_dict and add it to the dataframes\n",
    "\n",
    "dog_owner_df[\"breed1_en\"] = dog_owner_df[\"breed1\"].map(unmatched_translations)\n",
    "dog_owner_df[\"breed2_en\"] = dog_owner_df[\"breed2\"].map(unmatched_translations)\n",
    "dog_owner_df[\"breed1_mixed_breed_en\"] = dog_owner_df[\"breed1_mixed_breed\"].map(\n",
    "    unmatched_translations\n",
    ")\n",
    "\n",
    "dog_df[\"dog_breed\"] = dog_df[\"dog_breed\"].str.lower()\n",
    "dog_df[\"breed_en\"] = dog_df[\"dog_breed\"].map(unmatched_translations)\n",
    "dog_df[\"breed_en\"] = dog_df[\"breed_en\"].str.lower()\n",
    "dog_df[\"dog_breed_type_en\"] = dog_df[\"dog_breed_type\"].map(translated_words)\n",
    "# dog_df.drop(\"roster\", axis=1, inplace=True)\n",
    "dog_df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_breed(breed, choices, scorer=fuzz.token_set_ratio, limit=2):\n",
    "    \"\"\"Function which uses process.extractOne to find the best match for a breed in a list of choices\"\"\"\n",
    "    return process.extractOne(breed, choices, scorer=scorer)\n",
    "\n",
    "\n",
    "akc_dog_breed_list = akc_breeds_df[\"akc_breed\"].to_list()\n",
    "\n",
    "\n",
    "# match the dog breeds in the dog_owner_df to the akc_dog_breeds\n",
    "# find possible matches for the dog breeds in the unmatched_breeds list\n",
    "# and put them in a dictionary with the dog breed as the key and the possible matches as the value\n",
    "matches_dict = {\n",
    "    breed: match_breed(breed, akc_dog_breed_list, scorer=fuzz.partial_ratio)\n",
    "    for breed in unmatched_breeds\n",
    "}\n",
    "\n",
    "matches_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breed_translations_df[breed_translations_df[\"breed_group\"].isnull()].head(50)\n",
    "breed_translations_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_dog_breeds(breed):\n",
    "    \"\"\"Function which filters the dog_df by breed and returns a dataframe\"\"\"\n",
    "    return akc_breeds_df[akc_breeds_df[\"breeds\"].str.contains(breed)]\n",
    "\n",
    "\n",
    "dog_breed_filter = pnw.TextInput(placeholder=\"Enter breed here\")\n",
    "\n",
    "filtered_dog_breeds = pn.Row(\n",
    "    pn.Column(dog_breed_filter),\n",
    "    pn.panel(pn.bind(filter_dog_breeds, breed=dog_breed_filter)),\n",
    ")\n",
    "# filtered_dog_breeds.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breed_translations_df[\n",
    "    breed_translations_df[\"breed_de\"] == breed_translations_df[\"breed_en\"]\n",
    "].tail(50)\n",
    "\n",
    "# breed_translation_df['breed_count'] =\n",
    "breed_translations_df[\"breed_en_count\"] = breed_translations_df.groupby(\"breed_en\")[\n",
    "    \"breed_en\"\n",
    "].transform(\"count\")\n",
    "\n",
    "breed_translations_df[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog_owner_df[\"breed1_en_count\"] = dog_owner_df.groupby(\"breed1_en\")[\n",
    "    \"breed1_en\"\n",
    "].transform(\"count\")\n",
    "\n",
    "# Find all the breeds with pinscher in the name\n",
    "pattern = re.compile(r\"mixed.*\")\n",
    "\n",
    "dog_owner_df.loc[dog_owner_df[\"breed1_en\"].str.contains(pattern, regex=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog_owner_df.rename(\n",
    "    columns={\n",
    "        \"holder_id\": \"owner_id\",\n",
    "        \"age_range\": \"owner_age\",\n",
    "        \"gender\": \"owner_gender\",\n",
    "        \"breed1_en\": \"main_breed\",\n",
    "        \"breed1_en_count\": \"main_breed_count\",\n",
    "        \"breed2_en\": \"second_breed\",\n",
    "        \"breed1_mixed_breed_en\": \"mixed_breed\",\n",
    "    },\n",
    "    inplace=True,\n",
    ")\n",
    "# dog_owner_df[\"city\"] = \"Zurich\"\n",
    "\n",
    "dog_owner_df.info(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog_owner_df[dog_owner_df[\"breed_type\"] == \"i\"][\"main_breed\"].count()\n",
    "dog_owner_df[dog_owner_df[\"breed_type\"] == \"ii\"][\"main_breed\"].count()\n",
    "dog_owner_df[dog_owner_df[\"breed_type\"] == \"k\"][\"main_breed\"].unique()\n",
    "\n",
    "swiss_breeds = list(\n",
    "    map(\n",
    "        lambda x: x.lower(),\n",
    "        [\n",
    "            \"The Greater Swiss\",\n",
    "            \"Bernese Mountain Dog\",\n",
    "            \"Appenzeller Mountain Dog\",\n",
    "            \"Entlebucher\",\n",
    "            \"Bernese\",\n",
    "            \"Bruno Jura\",\n",
    "            \"Saint Hubert Jura\",\n",
    "            \"Lucerne Hound\",\n",
    "            \"Schwyz\",\n",
    "            \"White Swiss Shepherd\",\n",
    "            \"St. Bernard\",\n",
    "        ],\n",
    "    )\n",
    ")\n",
    "\n",
    "swiss_keywords = set(it.chain.from_iterable(breed.split() for breed in swiss_breeds))\n",
    "\n",
    "\n",
    "common_words = {\"the\", \"hound\", \"dog\", \"white\"}\n",
    "\n",
    "words_to_look_for = swiss_keywords.difference(common_words)\n",
    "words_to_look_for\n",
    "# dog_owner_df.loc[dog_owner_df['main_breed'].contains(swiss_breeds), 'breed_type'] = 'swiss'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the rows which contain one of the words_to_look_for in the main_breed column\n",
    "\n",
    "swiss_pattern = r\"\\b(?:{})\\b\".format(\"|\".join(words_to_look_for))\n",
    "\n",
    "\n",
    "swiss_dogs = dog_owner_df[\n",
    "    dog_owner_df[\"main_breed\"].str.contains(swiss_pattern, regex=True)\n",
    "]\n",
    "swiss_dogs[swiss_dogs[\"main_breed\"] == \"swiss low running dog\"]\n",
    "# dog_owner_df[dog_owner_df[\"main_breed\"].isin(swiss_breeds)][\"main_breed\"].value_counts()\n",
    "# dog_owner_df[\"main_breed\"].value_counts().head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog_owner_df.to_csv(\"../data/dog_owner_df.csv\", index=False)\n",
    "dog_df.to_csv(\"../data/dog_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if any of the word in each row of the main_breed column matches any of the words in the items in the swiss_breeds list\n",
    "dog_owner_df[\"swiss_breed\"] = dog_owner_df[\"main_breed\"].apply(\n",
    "    lambda x: any(word in x.split() for word in swiss_breeds)\n",
    ")\n",
    "\n",
    "dog_owner_df[\"swiss_breed\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "    breed: unmatched_translations[breed]\n",
    "    for breed in sorted(list(unmatched_translations.keys()))\n",
    "}\n",
    "dog_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_set = set(dog_owner_df[\"dog_color\"].str.replace(\"/\", \" \").to_list())\n",
    "color_translated_dict = translate_app.translate_list(color_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_translated_underscores = {\n",
    "    key.replace(\" \", \"/\"): value for key, value in color_translated_dict.items()\n",
    "}\n",
    "color_translated_underscores\n",
    "dog_owner_df[\"dog_color_en\"] = dog_owner_df[\"dog_color\"].map(\n",
    "    color_translated_underscores\n",
    ")\n",
    "# dog_owner_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc.b_glasbey_category10[:3]\n",
    "roster_colors = {\n",
    "    \"2015\": cc.b_glasbey_category10[0],\n",
    "    \"2016\": cc.b_glasbey_category10[1],\n",
    "    \"2017\": cc.b_glasbey_category10[2],\n",
    "}\n",
    "\n",
    "\n",
    "def filter_df(breed):\n",
    "    \"\"\"Function which filters the dog_df by breed and returns a dataframe\"\"\"\n",
    "    return dog_owner_df[dog_owner_df[\"breed1_en\"].str.contains(breed)]\n",
    "\n",
    "\n",
    "breed_filter = pnw.TextInput(placeholder=\"Enter breed here\")\n",
    "\n",
    "filtered_view = pn.Row(\n",
    "    pn.Column(breed_filter),\n",
    "    pn.panel(pn.bind(filter_df, breed=breed_filter)),\n",
    ")\n",
    "# filtered_view.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog_owner_df.hvplot.hist(\n",
    "    y=\"dog_age\",\n",
    "    by=\"roster\",\n",
    "    color=hv.dim(\"roster\").categorize(roster_colors),\n",
    "    alpha=0.6,\n",
    "    muted_alpha=0.05,\n",
    "    legend=\"top_right\",\n",
    "    title=\"Dog age distribution each roster\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### checkpoint"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
