{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# import some of the libaries that we will use\n",
    "\n",
    "\n",
    "\n",
    "import urllib.request\n",
    "import io\n",
    "import itertools as it\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "import re\n",
    "\n",
    "\n",
    "\n",
    "import unicodedata\n",
    "import math\n",
    "import string\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "from thefuzz import process\n",
    "\n",
    "\n",
    "\n",
    "from thefuzz import fuzz\n",
    "\n",
    "\n",
    "\n",
    "import json\n",
    "\n",
    "import colorcet as cc\n",
    "import panel as pn\n",
    "\n",
    "\n",
    "\n",
    "import panel.widgets as pnw\n",
    "\n",
    "\n",
    "from translate_app import translate_list_to_dict\n",
    "\n",
    "\n",
    "\n",
    "import recordlinkage as rl\n",
    "import missingno as msno\n",
    "\n",
    "\n",
    "\n",
    "import holoviews as hv\n",
    "\n",
    "\n",
    "\n",
    "from holoviews import streams\n",
    "\n",
    "\n",
    "\n",
    "from holoviews.selection import link_selections\n",
    "\n",
    "\n",
    "\n",
    "from holoviews import opts\n",
    "\n",
    "\n",
    "\n",
    "import hvplot\n",
    "\n",
    "\n",
    "\n",
    "import hvplot.pandas\n",
    "\n",
    "\n",
    "\n",
    "import geoviews as gv\n",
    "import geopandas as gpd\n",
    "\n",
    "\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "\n",
    "\n",
    "\n",
    "from panel.template import FastListTemplate\n",
    "from wordcloud import WordCloud\n",
    "from PIL import Image, ImageDraw\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, MultiLabelBinarizer\n",
    "import lightgbm as lgb\n",
    "import time\n",
    "import xgboost as xgb\n",
    "from sklearn.cluster import KMeans\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    roc_curve,\n",
    "    precision_recall_curve,\n",
    ")\n",
    "import time\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "\n",
    "\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "pn.extension(template=\"fast\", sizing_mode=\"stretch_width\")\n",
    "pn.config.throttled = True\n",
    "hv.extension(\"bokeh\")\n",
    "gv.extension(\"bokeh\")\n",
    "# don't show pandas warning\n",
    "pd.options.mode.chained_assignment = None\n",
    "pd.set_option(\"display.max_columns\", 40)\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", 200)\n",
    "\n",
    "\n",
    "def remove_accents(input_str):\n",
    "    \"\"\"Function to remove accents from a string.\n",
    "    It takes as argument a string and returns the same string\n",
    "    without accents.\"\"\"\n",
    "    nfkd_form = (\n",
    "        unicodedata.normalize(\"NFKD\", input_str).encode(\n",
    "            \"ASCII\", \"ignore\").decode()\n",
    "    )\n",
    "    # return \"\".join([c for c in nfkd_form if not unicodedata.combining(c)])\n",
    "    return nfkd_form\n",
    "\n",
    "\n",
    "remove_accents(\"résuméö\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# get the zip file with the data from the link\n",
    "\n",
    "data_url = (\n",
    "    \"https://storage.googleapis.com/mrprime_dataset/dogs_of_zurich/dogs_of_zurich.zip\"\n",
    ")\n",
    "\n",
    "# create function which takes the url\n",
    "# retrieve zip and unzip it and return the csv files as a list\n",
    "\n",
    "\n",
    "def get_data(url):\n",
    "    \"\"\"Function which takes in a url, retrieves the zip file,\n",
    "    unzips it and returns the csv files as a list\"\"\"\n",
    "    # get the zip file\n",
    "    filename, headers = urllib.request.urlretrieve(url)\n",
    "    with zipfile.ZipFile(filename) as zip_ref:\n",
    "        # get the csv files\n",
    "        dfs = []\n",
    "        for file in zip_ref.namelist():\n",
    "            if file.endswith(\".csv\"):\n",
    "                csv_file = io.StringIO(zip_ref.read(file).decode(\"utf-8\"))\n",
    "                # readin csv as a pandas dataframe and append to list\n",
    "                df = pd.DataFrame()\n",
    "                df = pd.read_csv(csv_file)\n",
    "                df[\"roster\"] = file\n",
    "                dfs.append(df)\n",
    "\n",
    "    return dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Functions for getting the owner numbers roster to roster\n",
    "def get_owners(df, year):\n",
    "    \"\"\"Function which takes in a dataframe and a year and returns a set of the holder_id\"\"\"\n",
    "    return set(df[df[\"roster\"] == year][\"holder_id\"])\n",
    "\n",
    "\n",
    "def get_new_owners(owner_current_year, owner_previous_year):\n",
    "    \"\"\"Function which takes in two sets of holder_id and returns\n",
    "    the set difference of the current year owners minus the previous year owners\"\"\"\n",
    "    return owner_current_year.difference(owner_previous_year)\n",
    "\n",
    "\n",
    "def get_returning_owners(owner_current_year, owner_previous_year):\n",
    "    \"\"\"Function which takes in two sets of holder_id and returns\n",
    "    the intersection between the current year owners and the previous year owners\"\"\"\n",
    "    return owner_current_year.intersection(owner_previous_year)\n",
    "\n",
    "\n",
    "def get_left_owners(owner_current_year, owner_previous_year):\n",
    "    \"\"\"Function which takes in two sets of holder_id and returns\n",
    "    the set difference of the previous year minus the current year\"\"\"\n",
    "\n",
    "    return owner_previous_year.difference(owner_current_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "def find_breed_match(input_breed, breeds_df, scoring_function=fuzz.token_set_ratio):\n",
    "    \"\"\"Find the match for the breed in the FCI breeds dataframe.\n",
    "    breeds_df dataframe must have both a breed_en and alt_names column.\"\"\"\n",
    "    max_score = 85\n",
    "    best_match = np.nan\n",
    "    for index, breed_row in breeds_df.iterrows():\n",
    "        alternative_names = breed_row[\"alt_names\"]\n",
    "        current_score = max(\n",
    "            scoring_function(input_breed, alt_name) for alt_name in alternative_names\n",
    "        )\n",
    "        if current_score > max_score:\n",
    "            max_score = current_score\n",
    "            best_match = breed_row[\"breed_en\"]\n",
    "        if max_score == 100:\n",
    "            break\n",
    "\n",
    "    return best_match\n",
    "\n",
    "\n",
    "def apply_fuzzy_matching_to_breed_column(\n",
    "    dataframe, breed_column, fci_df, scoring_function\n",
    "):\n",
    "    \"\"\"Apply fuzzy matching to the breed column in the dataframe.\"\"\"\n",
    "    return dataframe[breed_column].apply(\n",
    "        lambda breed: find_breed_match(breed, fci_df, scoring_function)\n",
    "    )\n",
    "\n",
    "\n",
    "# Usage example\n",
    "# apply_fuzzy_matching_to_breed_column(\n",
    "#     dog_owner_df, \"breed1\", fci_breeds, fuzz.token_set_ratio\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Shapefile for Zurich\n",
    "zurich_shapefile = \"../data/zurich_shape_data.zip\"\n",
    "\n",
    "# Get the path to the shapefile within the zip archive\n",
    "shapefile_path = \"zip://\" + zurich_shapefile + \"!data/stzh.adm_stadtkreise_v.shp\"\n",
    "\n",
    "# Description of zurich districts\n",
    "zurich_desc_path = \"../data/zurich_districts.csv\"\n",
    "\n",
    "# Read the shapefile with GeoPandas\n",
    "gdf = gpd.read_file(shapefile_path)\n",
    "\n",
    "# read in csv as a pandas dataframe\n",
    "zurich_desc = pd.read_csv(zurich_desc_path)\n",
    "\n",
    "# call the function and assign the csv files to a variable\n",
    "dogs_of_zurich_dfs = get_data(data_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put all the column headers in one list\n",
    "list_of_headings = []\n",
    "for df in dogs_of_zurich_dfs:\n",
    "    list_of_headings += df.columns.tolist()\n",
    "\n",
    "more_german_words = list(\n",
    "    filter(lambda x: x is not np.nan,\n",
    "           dogs_of_zurich_dfs[3].iloc[:, 2].unique())\n",
    ")\n",
    "list_of_headings += more_german_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only keep unique column headers and replace underscores with spaces\n",
    "\n",
    "words_set = {word.replace(\"_\", \" \") for word in list_of_headings}\n",
    "words_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run translate app for columns\n",
    "\n",
    "We run the translation app on \n",
    "- the columns names.\n",
    "- the dog breeds\n",
    "- the dog colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translated_words = translate_list_to_dict(words_set, project_id=\"mrprimetranslator\")\n",
    "\n",
    "\n",
    "translated_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put the underscores back in the original headings\n",
    "translated_headings_underscores = {\n",
    "    key.replace(\" \", \"_\"): value.lower().replace(\" \", \"_\").replace(\"'s\", \"\")\n",
    "    for key, value in translated_words.items()\n",
    "}\n",
    "translated_headings_underscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is actually translated to districts as in the 12 districts of Zurich\n",
    "translated_headings_underscores[\"STADTKREIS\"] = \"district\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put the translated headings as the new column names\n",
    "for df in dogs_of_zurich_dfs:\n",
    "    df.rename(columns=translated_headings_underscores, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the 2 dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine 3 of 4 dataframes into one with dog owner info\n",
    "dog_owner_df = pd.DataFrame()\n",
    "dog_owner_df = pd.concat(\n",
    "    [\n",
    "        dogs_of_zurich_dfs[0],\n",
    "        dogs_of_zurich_dfs[1],\n",
    "        dogs_of_zurich_dfs[2],\n",
    "    ],\n",
    "    axis=0,\n",
    ")\n",
    "dog_owner_df.info()\n",
    "\n",
    "# name last dataframe with dog breeds info\n",
    "dog_df = pd.DataFrame()\n",
    "dog_df = dogs_of_zurich_dfs[3]\n",
    "dog_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(dog_owner_df.sample(3))\n",
    "dog_df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.matrix(dog_owner_df)\n",
    "\n",
    "msno.nullity_sort(dog_owner_df, sort=\"descending\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only null values in breed2_mixed so drop column\n",
    "dog_owner_df = dog_owner_df.drop(columns=[\"breed2_mixed_breed\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This code snippet performs various operations on the 'dog_owner_df' DataFrame:\n",
    "\n",
    "1. Resets the index of the DataFrame.\n",
    "2. Converts the 'district' column to a categorical data type.\n",
    "3. Converts all the breed columns ('breed1', 'breed2', 'breed1_mixed_breed') to lowercase.\n",
    "4. Takes the first 4 characters of the 'roster' column and converts it to an ordered categorical column.\n",
    "5. Adds a column 'first_roster' that represents the first year the owner appeared in the roster.\n",
    "6. Adds a column 'roster_count' that represents the number of unique rosters each owner appeared in.\n",
    "7. Adds a column 'dog_count' that represents the number of dogs per owner in each roster.\n",
    "8. Adds a column 'district_count' that represents the number of unique districts each owner appeared in.\n",
    "\n",
    "9. Converts the 'holder_id' column to a string data type.\n",
    "10. Adds a column 'is_male_owner' that indicates whether the owner is male or not based on the 'gender' column.\n",
    "11. Adds a column 'is_male_dog' that indicates whether the dog is male or not based on the 'gender_dog' column.\n",
    "\"\"\"\n",
    "\n",
    "dog_owner_df = dog_owner_df.reset_index(drop=True)\n",
    "dog_owner_df[\"holder_id\"] = dog_owner_df[\"holder_id\"].astype(str).str.zfill(6)\n",
    "dog_owner_df[\"district\"] = dog_owner_df[\"district\"].astype(\"category\")\n",
    "\n",
    "dog_owner_df[\"breed1\"] = dog_owner_df[\"breed1\"].str.lower()\n",
    "\n",
    "dog_owner_df[\"breed2\"] = dog_owner_df[\"breed2\"].str.lower()\n",
    "\n",
    "dog_owner_df[\"breed1_mixed_breed\"] = dog_owner_df[\"breed1_mixed_breed\"].str.lower()\n",
    "\n",
    "dog_owner_df[\"roster\"] = dog_owner_df[\"roster\"].str[:4]\n",
    "\n",
    "dog_owner_df[\"roster\"] = pd.Categorical(dog_owner_df[\"roster\"], ordered=True)\n",
    "\n",
    "dog_owner_df[\"first_roster\"] = dog_owner_df.groupby(\"holder_id\")[\"roster\"].transform(\n",
    "    \"min\"\n",
    ")\n",
    "\n",
    "dog_owner_df[\"roster_count\"] = dog_owner_df.groupby(\"holder_id\")[\"roster\"].transform(\n",
    "    \"nunique\"\n",
    ")\n",
    "\n",
    "dog_owner_df[\"dog_count\"] = dog_owner_df.groupby([\"holder_id\", \"roster\"])[\n",
    "    \"holder_id\"\n",
    "].transform(\"size\")\n",
    "\n",
    "dog_owner_df[\"district_count\"] = (\n",
    "    dog_owner_df[[\"holder_id\", \"district\"]]\n",
    "    .groupby(\"holder_id\")[\"district\"]\n",
    "    .transform(\"nunique\")\n",
    ")\n",
    "\n",
    "dog_owner_df[\"holder_id\"] = dog_owner_df[\"holder_id\"].astype(str)\n",
    "dog_owner_df[\"is_male_owner\"] = dog_owner_df[\"gender\"].str.contains(\"m\")\n",
    "dog_owner_df[\"is_male_dog\"] = dog_owner_df[\"gender_dog\"].str.contains(\"m\")\n",
    "dog_owner_df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of holders: {dog_owner_df['holder_id'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dog with a year of birth after the roster year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the holder_id of the bad entries and observe other entries with the same holder_id\n",
    "bad_entry_holder_id = dog_owner_df[\n",
    "    dog_owner_df[\"dog_year_of_birth\"] > dog_owner_df[\"roster\"].astype(int)\n",
    "][\"holder_id\"]\n",
    "\n",
    "\n",
    "dog_owner_df[dog_owner_df[\"holder_id\"].isin(bad_entry_holder_id)].sort_values(\n",
    "    by=\"holder_id\"\n",
    ")\n",
    "\n",
    "# dog_owner_df[dog_owner_df[\"holder_id\"].isin(bad_entry_holder_id)].index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have Rosters for 3 separate years, we can see if that owner corrected its wrong entry in the later years. We can drop since the bad entries are consistent with no clue as to the correct entry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(dog_owner_df.shape)\n",
    "\n",
    "bad_entry_index = dog_owner_df[\n",
    "    dog_owner_df[\"holder_id\"].isin(bad_entry_holder_id)\n",
    "].index\n",
    "\n",
    "dog_owner_df.drop(bad_entry_index, inplace=True)\n",
    "\n",
    "dog_owner_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dogs with a year of birth too far before the roster year (before 1990) which is plausible, but not probable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the holder_id of the bad entries\n",
    "bad_entry_holder_id = dog_owner_df[dog_owner_df[\"dog_year_of_birth\"] < 1990][\n",
    "    \"holder_id\"\n",
    "]\n",
    "\n",
    "# isolate entries from these holder_ids and group them by holder_id\n",
    "dog_owner_group = (\n",
    "    dog_owner_df[dog_owner_df[\"holder_id\"].isin(bad_entry_holder_id)]\n",
    "    .sort_values(by=\"holder_id\")\n",
    "    .groupby(\"holder_id\")\n",
    ")\n",
    "\n",
    "dog_owner_df[dog_owner_df[\"holder_id\"].isin(bad_entry_holder_id)].sort_values(\n",
    "    by=\"holder_id\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can replace bad entries with matching entries from the later roster years as the owner corrected the value for th elater rosters. Luckly these owners only have one dog each.\n",
    "\n",
    "The one bad entry of `1980` with only 1 appearance we cannot safely replace so we drop it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these entries only have 1 dog so we can replace the year of birth with the mode making some assumptions\n",
    "dog_owner_df.loc[\n",
    "    dog_owner_df[\"holder_id\"].isin(bad_entry_holder_id), \"dog_year_of_birth\"\n",
    "] = dog_owner_group[\"dog_year_of_birth\"].transform(lambda x: x.mode().iloc[0])\n",
    "\n",
    "dog_owner_df[dog_owner_df[\"holder_id\"].isin(bad_entry_holder_id)].sort_values(\n",
    "    by=\"holder_id\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the one with only 1 appearance we cannot safely replace so we drop it\n",
    "dog_owner_df = dog_owner_df.drop(\n",
    "    dog_owner_df[dog_owner_df[\"holder_id\"] == \"129251\"].index\n",
    ")\n",
    "\n",
    "# No more 20/30something years-old dogs\n",
    "dog_owner_df[dog_owner_df[\"dog_year_of_birth\"] < 1990][\"holder_id\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add 1 to the dog age so that no dog has an age of 0. Consider it the dog's year of living."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dog's age is calculated by subtracting the year of birth from the year of the roster\n",
    "# added 1 in case i wanted to do something with log down the line\n",
    "dog_owner_df[\"dog_age\"] = (\n",
    "    dog_owner_df[\"roster\"].astype(int) - dog_owner_df[\"dog_year_of_birth\"] + 1\n",
    ")\n",
    "dog_owner_df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog_owner_df[\"dog_age\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(dog_owner_df[dog_owner_df.age.isnull()])\n",
    "\n",
    "\n",
    "# Drop these 5 rows with unknown\n",
    "dog_owner_df.dropna(subset=[\"age\"], inplace=True)\n",
    "dog_owner_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get owners for each year\n",
    "owner_2015 = get_owners(dog_owner_df, \"2015\")\n",
    "owner_2016 = get_owners(dog_owner_df, \"2016\")\n",
    "# owner_2017 = get_owners(dog_owner_df, \"2017\")\n",
    "\n",
    "# Print the number of initial owners in 2015\n",
    "print(f\"{len(owner_2015)} initial owners in 2015\")\n",
    "\n",
    "# Calculate and print the new, returning, and left owners for 2016\n",
    "new_2016 = get_new_owners(owner_2016, owner_2015)\n",
    "returning_2016 = get_returning_owners(owner_2016, owner_2015)\n",
    "left_2016 = get_left_owners(owner_2016, owner_2015)\n",
    "print(\n",
    "    f\"{len(new_2016)} new owners in 2016, {len(returning_2016)} returning owners, and {len(left_2016)} owners left in 2016\"\n",
    ")\n",
    "\n",
    "# Calculate and print the new, returning, and left owners for 2017\n",
    "# new_2017 = get_new_owners(owner_2017, owner_2016.union(owner_2015))\n",
    "# returning_2017 = get_returning_owners(owner_2017, owner_2016.union(owner_2015))\n",
    "# left_2017 = get_left_owners(owner_2017, owner_2016)\n",
    "# print(\n",
    "#     f\"{len(new_2017)} new owners in 2017, {len(returning_2017)} returning owners, and {len(left_2017)} owners left in 2017\"\n",
    "# )\n",
    "\n",
    "# Calculate and print the constant owners\n",
    "constant_owners = owner_2015.intersection(\n",
    "    owner_2016)  # .intersection(owner_2017)\n",
    "print(f\"{len(constant_owners)} constant owners\")\n",
    "\n",
    "# Calculate and print the gap owners\n",
    "# gap_owners = owner_2015.intersection(owner_2017).difference(owner_2016)\n",
    "# print(f\"{len(gap_owners)} owners with a gap year\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog_owner_df[\"age\"] = pd.Categorical(\n",
    "    dog_owner_df[\"age\"],\n",
    "    ordered=True,\n",
    "    categories=[\n",
    "        \"11-20\",\n",
    "        \"21-30\",\n",
    "        \"31-40\",\n",
    "        \"41-50\",\n",
    "        \"51-60\",\n",
    "        \"61-70\",\n",
    "        \"71-80\",\n",
    "        \"81-90\",\n",
    "        \"91-100\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def age_group(age):\n",
    "    \"\"\"Function which widen the age groups of the oldest and youngest dog owners\"\"\"\n",
    "    if age == \"71-80\" or age == \"81-90\" or age == \"91-100\":\n",
    "        return \"71+\"\n",
    "    elif age == \"11-20\" or age == \"21-30\":\n",
    "        return \"11-30\"\n",
    "\n",
    "    else:\n",
    "        return age\n",
    "\n",
    "\n",
    "dog_owner_df[\"age_group\"] = dog_owner_df[\"age\"].apply(age_group).dropna()\n",
    "# dog_owner_df\n",
    "dog_owner_df[\"age_range\"] = dog_owner_df[\"age\"].str[:1] + \"0s\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missing values for breed type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"Number of null values in column 'breed_type': \",\n",
    "    dog_owner_df.breed_type.isnull().sum(),\n",
    ")\n",
    "\n",
    "# get the breed1 for the entries with missing breed_type\n",
    "breed_missing_breed_type = dog_owner_df[dog_owner_df[\"breed_type\"].isnull()][\n",
    "    \"breed1\"\n",
    "].unique()\n",
    "\n",
    "breed_missing_breed_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find these breeds in the dog_df and get the breed_type from there\n",
    "# dog_df.drop(\"roster\", axis=1, inplace=True)\n",
    "# dog_df[dog_df[\"dog_breed\"].isin(breed_missing_breed_type)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see what other dogs of these breeds have as breed_type\n",
    "dog_owner_df[dog_owner_df[\"breed1\"].isin(breed_missing_breed_type)].sort_values(\n",
    "    by=[\"breed1\", \"holder_id\"]\n",
    ")\n",
    "\n",
    "dog_breed_group = dog_owner_df[\n",
    "    dog_owner_df[\"breed1\"].isin(breed_missing_breed_type)\n",
    "].groupby(\"breed1\")\n",
    "\n",
    "# most breeds have a unanimous breed_type so we can just fillna with the mode\n",
    "display(dog_breed_group[\"breed_type\"].value_counts())\n",
    "\n",
    "\n",
    "# Fill in the missing breed_type with the mode of the breed1\n",
    "dog_owner_df[\"breed_type\"].fillna(\n",
    "    dog_owner_df.groupby(\"breed1\")[\"breed_type\"].transform(\n",
    "        lambda x: x.mode().iloc[0]),\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "dog_owner_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_district_holder_id = dog_owner_df[dog_owner_df[\"district\"].isna()][\n",
    "    \"holder_id\"\n",
    "].unique()\n",
    "\n",
    "dog_owner_df[dog_owner_df[\"holder_id\"].isin(missing_district_holder_id)]\n",
    "\n",
    "# drop these missing rows with no district info\n",
    "dog_owner_df.dropna(subset=[\"district\"], inplace=True)\n",
    "\n",
    "dog_owner_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the string columns to lower case\n",
    "breed_columns = [\"breed1\", \"breed2\", \"breed1_mixed_breed\", \"breed_type\"]\n",
    "# for col in breed_columns:\n",
    "#     dog_owner_df[col] = dog_owner_df[col].str.lower()\n",
    "\n",
    "dog_owner_df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog_owner_df[\"breed1_mixed_breed\"].unique()\n",
    "dog_owner_df[\"breed1_mixed_breed\"].nunique()\n",
    "dog_owner_df[breed_columns].describe()\n",
    "# dog_df[\"dog_breed\"].unique()\n",
    "# dog_owner_df[\"breed1\"].dropna().unique().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run translate app for breeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all of the dog breeds to translate and put in a list\n",
    "breed_list1 = dog_owner_df[[\"breed1\", \"breed2\"]\n",
    "                           ].stack().dropna().unique().tolist()\n",
    "breed_list2 = dog_df[\"dog_breed\"].unique().tolist()\n",
    "breed_list3 = list(\n",
    "    filter(lambda x: x is not np.nan,\n",
    "           dog_owner_df[\"breed1_mixed_breed\"].unique())\n",
    ")\n",
    "breed_set = set(breed_list1 + breed_list2 + breed_list3)\n",
    "breed_set = {breed.lower() for breed in breed_set}\n",
    "\n",
    "display(len(breed_set))\n",
    "# breed_set\n",
    "translations_df = pd.DataFrame()\n",
    "translations_df[\"breed\"] = list(breed_set)\n",
    "# sort the breeds alphabetically\n",
    "translations_df.sort_values(by=\"breed\", inplace=True)\n",
    "translations_df.shape\n",
    "translations_df[\"breed\"] = translations_df[\"breed\"].str.lower()\n",
    "translations_df[\"translation\"] = \"\"\n",
    "trans_dict = translate_list_to_dict(translations_df[\"breed\"].tolist())\n",
    "translations_df[\"translation\"] = translations_df[\"breed\"].map(trans_dict)\n",
    "translations_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get number of unique breeds in the translation column\n",
    "translations_df[\"translation\"].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Translate colors\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make 1 set of all the unique colors\n",
    "color_set = set()\n",
    "\n",
    "dog_colors_df = dog_owner_df[\"dog_color\"].str.split(\"/\", expand=True)\n",
    "dog_colors_list = dog_colors_df.melt().value.unique().tolist()\n",
    "dog_colors_list = [color for color in dog_colors_list if color is not None]\n",
    "# dog_colors_list\n",
    "\n",
    "# get translation for colors\n",
    "dog_color_dict = translate_list_to_dict(dog_colors_list)\n",
    "\n",
    "# dog_color_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog_colors_en = dog_colors_df.applymap(dog_color_dict.get)\n",
    "dog_colors_en.columns = [\"color1\", \"color2\", \"color3\"]\n",
    "dog_owner_df = dog_owner_df.merge(\n",
    "    dog_colors_en, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the AKC & FCI breeds saved to disk\n",
    "\n",
    "We will use the AKC and FCI breeds list as a source of truth for the dog breed names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# get the dog_breeds dataframe from the data folder\n",
    "fci_breeds = pd.read_json(\"../data/fci_breeds.json\", orient=\"records\")\n",
    "akc_breeds = pd.read_json(\"../data/akc_breeds.json\", orient=\"records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the match first with the FCI list as it has a lot more than the AKC list. The search for a match is run onthe `alt_names` column since the breed can be referred to by any of its alternative names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the fci_breed column with NaNs\n",
    "translations_df[\"standard\"] = np.nan\n",
    "\n",
    "# List of columns and fuzz functions to apply\n",
    "columns = [\"breed\", \"translation\"]\n",
    "fuzz_funcs = [\n",
    "    fuzz.WRatio,\n",
    "    fuzz.partial_ratio,\n",
    "    # fuzz.ratio,\n",
    "    # fuzz.token_sort_ratio,\n",
    "    # fuzz.token_set_ratio,\n",
    "]\n",
    "\n",
    "# Apply each fuzz function to each column\n",
    "for column in columns:\n",
    "    for fuzz_func in fuzz_funcs:\n",
    "        translations_df[\"standard\"] = translations_df[\"standard\"].fillna(\n",
    "            apply_fuzzy_matching_to_breed_column(\n",
    "                translations_df, column, fci_breeds, fuzz_func\n",
    "            ),\n",
    "        )\n",
    "        print(f\"Nulls left: {translations_df['standard'].isna().sum()}\")\n",
    "\n",
    "translations_df[translations_df[\"standard\"].isna()].shape\n",
    "# translations_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Follow up with the AKC list for some for which no match was found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "akc_breeds = akc_breeds[[\"breed\", \"alt_names\"]]\n",
    "akc_breeds[\"breed_en\"] = akc_breeds[\"breed\"].copy()\n",
    "# remove None values from alt_names\n",
    "akc_breeds[\"alt_names\"] = akc_breeds[\"alt_names\"].apply(\n",
    "    lambda x: list(filter(None, x)))\n",
    "akc_breeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply each fuzz function to each column\n",
    "\n",
    "\n",
    "for column in columns:\n",
    "    for fuzz_func in fuzz_funcs:\n",
    "        translations_df[\"standard\"] = translations_df[\"standard\"].fillna(\n",
    "            apply_fuzzy_matching_to_breed_column(\n",
    "                translations_df, column, akc_breeds, fuzz_func\n",
    "            ),\n",
    "        )\n",
    "        # print(f\"Nulls left: {translations_df['standard'].isna().sum()}\")\n",
    "\n",
    "\n",
    "translations_df[translations_df[\"standard\"].isna()].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translations_df[translations_df[\"standard\"].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# translations_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get an empty column of the dog_owner dataframe and map the fci_breed to the breed1 column\n",
    "\n",
    "dog_owner_df = dog_owner_df.merge(\n",
    "    translations_df, how=\"left\", left_on=\"breed1\", right_on=\"breed\"\n",
    ")\n",
    "# dog_owner_df[[\"breed1\", \"fci_breed\"]].sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some we know there is no matching breed for like `Mischling` as this just means mixed in german."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog_owner_df.loc[\n",
    "    dog_owner_df[\"breed1\"].str.contains(\"mischling klein\"), \"standard\"\n",
    "] = \"mixed breed small\"\n",
    "dog_owner_df.loc[\n",
    "    dog_owner_df[\"breed1\"].str.contains(\"mischling gross\"), \"standard\"\n",
    "] = \"mixed breed large\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog_owner_df.loc[\n",
    "    (dog_owner_df[\"breed1_mixed_breed\"].notnull())\n",
    "    | (dog_owner_df[\"breed2\"].notnull())\n",
    "    | (dog_owner_df[\"translation\"].str.contains(r\"mixed.*\", regex=True)),\n",
    "    \"mixed_breed\",\n",
    "] = True\n",
    "dog_owner_df[\"mixed_breed\"].fillna(False, inplace=True)\n",
    "dog_owner_df[\"pure_breed\"] = ~dog_owner_df[\"mixed_breed\"]\n",
    "only_child_dogs = dog_owner_df[dog_owner_df[\"dog_count\"] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look for the count of the white swiss shepherd\n",
    "dog_owner_df.standard.value_counts().head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correction to the Shepherds\n",
    "\n",
    "To fix mismatch of German Shepherd breed, we transate the colors and change the rows with the WHITE SWISS SHEPHERD DOG to the correct breed of GERMAN SHEPHERD DOG. Our fuzzy algorithm mistook Shepherd to mean white Swiss Shepherd instead of German Shepherd. While all of them would not German shepherds we can safely say that the ones that were not white were not white swiss shepherds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coi = [\"breed\", \"dog_color\", \"breed1\", \"breed2\", \"color1\", \"color2\", \"color3\"]\n",
    "\n",
    "german_shephard_tidying = dog_owner_df[\n",
    "    dog_owner_df[\"breed1\"].str.contains(\n",
    "        r\"^schäfer\", case=False, regex=True, na=False)\n",
    "][coi]\n",
    "# check if white in any of the columns and put True in has_white column\n",
    "german_shephard_tidying[\"has_white\"] = german_shephard_tidying[coi].apply(\n",
    "    lambda x: \"white\" in x.values, axis=1\n",
    ")\n",
    "# get the indexes of the rows with has_white as False\n",
    "real_german_shepherd_idx = german_shephard_tidying[\n",
    "    ~german_shephard_tidying[\"has_white\"]\n",
    "].index.tolist()\n",
    "\n",
    "# change the standard column to GERMAN SHEPHERD DOG from WHITE SWISS SHEPHERD DOG\n",
    "dog_owner_df.loc[real_german_shepherd_idx, \"standard\"] = \"german shepherd dog\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the count of the white swiss shepherd should not be visible anymore and the german shepherd dog should be visible\n",
    "dog_owner_df.standard.value_counts().head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correction to the Doodles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mask for rows where the 'breed1' column contains 'doodle'\n",
    "doodle_dogs_mask = dog_owner_df[\"breed1\"].str.contains(\n",
    "    \"doodle\", case=False, regex=True, na=False\n",
    ")\n",
    "\n",
    "# For rows where the mask is True, set the 'breed2' column to 'poodle'\n",
    "dog_owner_df.loc[doodle_dogs_mask, \"breed2\"] = \"poodle\"\n",
    "\n",
    "# For rows where the mask is True, set the 'pure_breed' column to False\n",
    "dog_owner_df.loc[doodle_dogs_mask, \"pure_breed\"] = False\n",
    "\n",
    "# For rows where the mask is True, set the 'mixed_breed' column to True\n",
    "dog_owner_df.loc[doodle_dogs_mask, \"mixed_breed\"] = True\n",
    "\n",
    "# For rows where the mask is True, set the 'standard' column to 'mixed breed large'\n",
    "dog_owner_df.loc[doodle_dogs_mask, \"standard\"] = \"mixed breed large\"\n",
    "\n",
    "# For rows where the mask is True, replace 'labradoodle' with 'labrador retriever'\n",
    "# and 'goldendoodle' with 'golden retriever' in the 'breed1' column\n",
    "dog_owner_df.loc[doodle_dogs_mask, \"breed1\"] = dog_owner_df.loc[\n",
    "    doodle_dogs_mask, \"breed1\"\n",
    "].replace(\n",
    "    {\"labradoodle\": \"labrador retriever\", \"goldendoodle\": \"golden retriever\"},\n",
    "    regex=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add in the country of origin for the breeds\n",
    "\n",
    "In case we need to use it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the county of origin to the dog_owner_df dataframe for all the standard breeds\n",
    "dog_owner_df = dog_owner_df.merge(\n",
    "    fci_breeds[[\"breed_en\", \"country_of_origin\"]],\n",
    "    how=\"left\",\n",
    "    left_on=\"standard\",\n",
    "    right_on=\"breed_en\",\n",
    ")\n",
    "dog_owner_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "swiss_breeds = fci_breeds.loc[\n",
    "    fci_breeds[\"country_of_origin\"].str.contains(\n",
    "        \"switz\", case=False, regex=True),\n",
    "    \"breed_en\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new column is_swiss and set it to false\n",
    "dog_owner_df[\"is_swiss\"] = False\n",
    "\n",
    "\n",
    "dog_owner_df.loc[\n",
    "    dog_owner_df[\"country_of_origin\"].str.contains(\n",
    "        \"switz\", case=False, regex=True, na=False\n",
    "    ),\n",
    "    \"is_swiss\",\n",
    "] = True\n",
    "\n",
    "# dog_owner_df[dog_owner_df[\"is_swiss\"] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog_owner_df.to_csv(\"../data/dog_owner_df.csv\", index=False)\n",
    "# dog_df.to_csv(\"../data/dog_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog_owner_df = pd.read_csv(\"../data/dog_owner_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog_owner_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog_owner_df.groupby([\"roster\"])[\"dog_count\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map the standard unique values to a cmap for consistency\n",
    "cmap = cc.glasbey_dark\n",
    "# explicit mapping for the colir to use for each standard breed\n",
    "explicit_mapping = {\n",
    "    breed: cmap[i] for i, breed in enumerate(dog_owner_df[\"standard\"].unique())\n",
    "}\n",
    "my_colors = hv.Cycle(list(explicit_mapping.values()))\n",
    "boy_cmap = list(sns.color_palette(\"light:#00008b\", n_colors=6).as_hex())\n",
    "girl_cmap = list(sns.color_palette(\"light:#8b008b\", n_colors=6).as_hex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in shape file for Zurich\n",
    "gdf = gpd.read_file(shapefile_path)\n",
    "\n",
    "# Calculate the area of each district in square kilometers\n",
    "gdf[\"km2\"] = gdf.to_crs(ccrs.GOOGLE_MERCATOR).area / 10**6\n",
    "gdf[\"km2\"] = gdf[\"km2\"].round(2)\n",
    "\n",
    "# Calculate the center coordinates of each district\n",
    "gdf[\"center\"] = gdf.to_crs(ccrs.GOOGLE_MERCATOR).centroid.to_crs(epsg=4326)\n",
    "\n",
    "# Rename the 'knr' column to 'district'\n",
    "gdf = gdf.rename(columns={\"knr\": \"district\"})\n",
    "\n",
    "# Merge the district descriptions from 'zurich_desc' dataframe\n",
    "gdf = gdf.merge(\n",
    "    zurich_desc[[\"district\", \"desc\", \"district_name\"]], how=\"left\", on=\"district\"\n",
    ")\n",
    "# drop objid column\n",
    "gdf.drop(columns=[\"objid\"], inplace=True)\n",
    "\n",
    "# Display the updated dataframe\n",
    "gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf[[\"district\", \"center\"]]\n",
    "\n",
    "# Extract x and y coordinates\n",
    "gdf[\"x\"] = gdf[\"center\"].apply(lambda point: point.x)\n",
    "gdf[\"y\"] = gdf[\"center\"].apply(lambda point: point.y)\n",
    "\n",
    "# Create a Labels element\n",
    "labels = hv.Labels(gdf, [\"x\", \"y\"], \"district\")\n",
    "xy_to_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.extension(\"bokeh\")\n",
    "gdf.to_crs(epsg=4326, inplace=True)\n",
    "zurich_poly = gv.Polygons(gdf).opts(\n",
    "    projection=ccrs.GOOGLE_MERCATOR,\n",
    "    # tools=[\"hover\"],\n",
    "    height=500,\n",
    "    width=800,\n",
    "    alpha=0.5,\n",
    "    fill_color=\"cyan\",\n",
    "    line_color=\"red\",\n",
    "    xaxis=None,\n",
    "    yaxis=None,\n",
    "    title=\"Zurich Districts\",\n",
    "    color_index=None,\n",
    "    aspect=\"equal\",\n",
    ")\n",
    "\n",
    "# add a basemap\n",
    "basemap = gv.tile_sources.OSM().opts(alpha=0.5, bgcolor=\"black\")\n",
    "\n",
    "# basemap * zurich_poly\n",
    "zurich_poly * labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog_owner_df.dropna(subset=[\"standard\"], inplace=True)\n",
    "dog_owner_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dog_owner_df[\"district\"] = pd.Categorical(\n",
    "#     dog_owner_df[\"district\"], ordered=False, categories=list(range(13))\n",
    "# )\n",
    "dog_owner_df[\"age_group\"] = pd.Categorical(\n",
    "    dog_owner_df[\"age_group\"], ordered=True)\n",
    "\n",
    "\n",
    "dog_owner_df[\"age_range\"] = pd.Categorical(\n",
    "    dog_owner_df[\"age_range\"],\n",
    "    ordered=True,\n",
    "    categories=[\"10s\", \"20s\", \"30s\", \"40s\", \"50s\", \"60s\", \"70s\", \"80s\", \"90s\"],\n",
    ")\n",
    "dog_owner_df[\"roster\"] = dog_owner_df[\"roster\"].astype(str)\n",
    "\n",
    "\n",
    "dog_owner_df[\"roster\"] = pd.Categorical(dog_owner_df[\"roster\"], ordered=True)\n",
    "dog_owner_df[\"holder_id\"] = dog_owner_df[\"holder_id\"].astype(str).str.zfill(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# gap_owners\n",
    "# # convert the gap_owners string to numeric\n",
    "# gap_owners = [str(x) for x in gap_owners]\n",
    "\n",
    "\n",
    "# dog_owner_df.loc[dog_owner_df[\"holder_id\"].isin(\n",
    "#     gap_owners)].sort_values(by=\"holder_id\")\n",
    "fci_breeds[\"date_of_acceptance\"] = pd.to_datetime(\n",
    "    fci_breeds[\"date_of_acceptance\"])\n",
    "fci_breeds.sort_values(by=\"date_of_acceptance\", ascending=False)\n",
    "\n",
    "# search the alt_names column for the list which contains the search term using regex for the search\n",
    "search_term = \"russian\"\n",
    "\n",
    "# Create a regex pattern to match the search term\n",
    "pattern = re.compile(f\".*{search_term}.*\", re.IGNORECASE)\n",
    "\n",
    "# Filter the dataframe based on the regex pattern\n",
    "filtered_df = fci_breeds[\n",
    "    fci_breeds[\"alt_names\"].apply(\n",
    "        lambda x: any(pattern.match(name) for name in x))\n",
    "]\n",
    "for item in dog_owner_df[\"standard\"].unique().tolist():\n",
    "    if item not in fci_breeds[\"breed_en\"].unique().tolist():\n",
    "        print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.opts.defaults(\n",
    "    hv.opts.HeatMap(\n",
    "        tools=[\"hover\", \"tap\", \"box_select\"],\n",
    "        active_tools=[\"box_zoom\"],\n",
    "        width=800,\n",
    "        height=500,\n",
    "        ylabel=\"\",\n",
    "        line_color=\"white\",\n",
    "        line_width=2,\n",
    "        toolbar=\"above\",\n",
    "        selection_line_color=\"red\",\n",
    "        nonselection_alpha=0.9,\n",
    "        nonselection_line_color=\"white\",\n",
    "    )\n",
    ")\n",
    "\n",
    "poly_opts = dict(\n",
    "    width=800,\n",
    "    height=500,\n",
    "    line_width=2,\n",
    "    xaxis=None,\n",
    "    yaxis=None,\n",
    "    aspect=\"equal\",\n",
    "    # cmap=explicit_mapping,\n",
    "    # projection=ccrs.GOOGLE_MERCATOR,\n",
    ")\n",
    "bar_opts = dict(\n",
    "    invert_axes=True,\n",
    "    width=800,\n",
    "    height=500,\n",
    "    tools=[\"hover\", \"tap\", \"box_select\"],\n",
    "    xaxis=None,\n",
    "    ylabel=\"\",\n",
    "    xlabel=\"\",\n",
    "    cmap=explicit_mapping,\n",
    "    show_legend=False,\n",
    "    active_tools=[\"box_zoom\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Owner Age Distribution by Age Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the top n small breeds in Zurich\n",
    "ktopn = (\n",
    "    dog_owner_df.loc[dog_owner_df[\"breed_type\"] == \"K\"][\"standard\"]\n",
    "    .value_counts()\n",
    "    .head(15)\n",
    "    .index.tolist()\n",
    ")\n",
    "ktopn_pure = (\n",
    "    dog_owner_df.loc[(dog_owner_df[\"breed_type\"] == \"K\")\n",
    "                     & (dog_owner_df[\"pure_breed\"])]\n",
    "    .standard.value_counts()\n",
    "    .head(15)\n",
    "    .index.tolist()\n",
    ")\n",
    "\n",
    "# The top n big breeds in Zurich\n",
    "itopn = (\n",
    "    dog_owner_df[dog_owner_df[\"breed_type\"] == \"I\"][\"standard\"]\n",
    "    .value_counts()\n",
    "    .head(15)\n",
    "    .index.tolist()\n",
    ")\n",
    "itopn_pure = (\n",
    "    dog_owner_df.loc[(dog_owner_df[\"breed_type\"] == \"I\")\n",
    "                     & (dog_owner_df[\"pure_breed\"])]\n",
    "    .standard.value_counts()\n",
    "    .head(15)\n",
    "    .index.tolist()\n",
    ")\n",
    "\n",
    "topn = ktopn + itopn\n",
    "topn_pure = ktopn_pure + itopn_pure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog_owner_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dog_owner_df[\"age_range\"] = pd.Categorical(\n",
    "    dog_owner_df[\"age_range\"],\n",
    "    ordered=True,\n",
    "    categories=[\"10s\", \"20s\", \"30s\", \"40s\", \"50s\", \"60s\", \"70s\", \"80s\", \"90s\"],\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "sns.violinplot(\n",
    "    x=\"age_range\",\n",
    "    y=\"dog_age\",\n",
    "    data=dog_owner_df,\n",
    "    order=[\"10s\", \"20s\", \"30s\", \"40s\", \"50s\", \"60s\", \"70s\", \"80s\", \"90s\"],\n",
    ")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.violinplot(\n",
    "    data=dog_owner_df.loc[dog_owner_df[\"standard\"].isin(topn_pure[:3])],\n",
    "    y=\"dog_age\",\n",
    "    x=\"standard\",\n",
    "    hue=\"roster\",\n",
    "    orient=\"v\",\n",
    ")\n",
    "plt.show()\n",
    "\n",
    "g = sns.FacetGrid(dog_owner_df, col=\"district\", height=5, aspect=1.5, col_wrap=4)\n",
    "g.map_dataframe(\n",
    "    sns.violinplot,\n",
    "    \"age_range\",\n",
    "    \"dog_age\",\n",
    "    hue=\"is_male_owner\",\n",
    "    split=True,\n",
    ")\n",
    "g.add_legend()\n",
    "# add title\n",
    "plt.subplots_adjust(top=0.9)\n",
    "g.fig.suptitle(\"Dog Age | Owner Age | Male Owner bool | District\")\n",
    "\n",
    "# compare the is_male_owner and the is_male_dog columns\n",
    "dog_owner_df[[\"is_male_owner\", \"is_male_dog\"]].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "sns.violinplot(\n",
    "    y=\"age_range\",\n",
    "    x=\"dog_age\",\n",
    "    data=dog_owner_df,\n",
    "    inner=\"stick\",\n",
    "    jitter=True,\n",
    "    split=True,\n",
    "    hue=\"is_male_owner\",\n",
    "    orient=\"h\",\n",
    "    legend=False,\n",
    ")\n",
    "plt.title(\"Dog Age dist | Male Owner bool | Age Range\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "sns.catplot(\n",
    "    dog_owner_df,\n",
    "    x=\"age_range\",\n",
    "    hue=\"roster\",\n",
    "    kind=\"count\",\n",
    "    # col=\"roster\",\n",
    "    # col=\"breed_type\",\n",
    "    row=\"is_male_owner\",\n",
    "    # color=\"blue\",\n",
    "    height=5,\n",
    "    aspect=2,\n",
    ")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_tab = pd.crosstab(\n",
    "    dog_owner_df[\"age_range\"], dog_owner_df[\"is_male_owner\"])\n",
    "cross_tab.plot(kind=\"bar\", stacked=True)\n",
    "\n",
    "chi2, p, dof, expected = chi2_contingency(cross_tab)\n",
    "print(f\"Chi-square statistic: {chi2}\")\n",
    "print(f\"P-value: {p}\")\n",
    "cross_tab.divide(cross_tab.sum(axis=1), axis=0).plot(\n",
    "    kind=\"bar\", stacked=True, legend=False\n",
    ")\n",
    "rosters = dog_owner_df[\"roster\"].unique().tolist()\n",
    "fig, axs = plt.subplots(1, len(rosters), figsize=(10, 3))\n",
    "for i, roster in enumerate(rosters):\n",
    "    data = dog_owner_df[dog_owner_df[\"roster\"] == roster]\n",
    "    cross_tab = pd.crosstab(\n",
    "        dog_owner_df[\"age_range\"], dog_owner_df[\"is_male_owner\"])\n",
    "    cross_tab_percent = cross_tab.divide(cross_tab.sum(axis=1), axis=0)\n",
    "    cross_tab_percent.plot(kind=\"bar\", stacked=True, legend=False, ax=axs[i])\n",
    "    axs[i].set_title(roster)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the age plots which are not attached to any widgets. These are not interactive. They are three separate plots:\n",
    "- a step plot with the `dog_age` distribution color coordinated by roster\n",
    "- a kde plot  of the `dog_age` again\n",
    "- a bar plot of the `holder_id` age."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools_opts = dict(active_tools=[\"box_zoom\"], toolbar=\"above\")\n",
    "# bar plot of the owner age distribution\n",
    "owner_age_groups_all = (\n",
    "    dog_owner_df.groupby([\"age\", \"roster\"])\n",
    "    .size()\n",
    "    .unstack()\n",
    "    .rename(columns={0: \"Count\"})\n",
    "    .hvplot.bar(\n",
    "        xlabel=\"\",\n",
    "        rot=90,\n",
    "        legend=True,\n",
    "        tools=[\"hover\", \"box_select\"],\n",
    "        title=\"Owners Age distribution\",\n",
    "    )\n",
    "    .opts(**tools_opts)\n",
    ")\n",
    "# kde plot of the dog age distribution\n",
    "dog_age_all = dog_owner_df.hvplot.kde(\n",
    "    y=\"dog_age\",\n",
    "    by=\"roster\",\n",
    "    xlim=(0, 21),\n",
    "    ylim=(0, 0.1),\n",
    "    xlabel=\"\",\n",
    "    rot=90,\n",
    "    legend=True,\n",
    "    tools=[\"hover\", \"box_select\"],\n",
    "    title=\"Dog Age Density distribution\",\n",
    "    muted_alpha=0.01,\n",
    ").opts(**tools_opts)\n",
    "# step plot of the dog age distribution\n",
    "dog_age_all_step = (\n",
    "    dog_owner_df.groupby([\"dog_age\", \"roster\"])\n",
    "    .size()\n",
    "    .hvplot.step(\n",
    "        x=\"dog_age\",\n",
    "        by=\"roster\",\n",
    "        xlim=(0, 21),\n",
    "        title=\"Dog Age distribution\",\n",
    "    )\n",
    "    .opts(**tools_opts)\n",
    ")\n",
    "# panel card with the 3 plots\n",
    "all_ages_card = pn.Card(\n",
    "    # add spacer\n",
    "    pn.Spacer(height=70),\n",
    "    dog_age_all_step,\n",
    "    dog_age_all,\n",
    "    owner_age_groups_all,\n",
    "    title=\"Age Distribution for ALL Dogs and Owners\",\n",
    "    styles={\"background\": \"gainsboro\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the same age distribution plots as above but these are interactive. They are controlled by widgets:\n",
    "- a checkbox for `pure_breed` which will filter for only pure breed dogs which affects all the plots\n",
    "- A single select dropdown for breed which reacts width all the plots\n",
    "- An float slider for bandwidth of the kde plot only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_age_range_stats(df, breed, bw, pure_breed):\n",
    "    \"\"\"Function to plot the age_range stats for the breed owners and the dog age distribution\"\"\"\n",
    "    if pure_breed:\n",
    "        breed_df = df.query(\n",
    "            f'standard.str.contains(\"{breed}\", case=False, regex=True, na=False) & pure_breed == True'\n",
    "        )\n",
    "    else:\n",
    "        breed_df = df.query(\n",
    "            f'standard.str.contains(\"{breed}\", case=False, regex=True, na=False)'\n",
    "        )\n",
    "    # plot a step plot of the dog_age\n",
    "    step = (\n",
    "        breed_df.groupby([\"dog_age\", \"roster\"])\n",
    "        .size()\n",
    "        .unstack()\n",
    "        .hvplot.step(title=f\"Dog Age distribution | {breed.title()}\", shared_axes=False)\n",
    "    )\n",
    "\n",
    "    # plot age_range of breed_df kde plot\n",
    "    kde = breed_df.hvplot.kde(\n",
    "        y=\"dog_age\",\n",
    "        by=\"roster\",\n",
    "        bandwidth=bw,\n",
    "        xlim=(0, 20),\n",
    "        ylim=(0, None),\n",
    "        xlabel=\"\",\n",
    "        muted_alpha=0.01,\n",
    "        title=f\"Dog Age density distribution | {breed.title()}\",\n",
    "    )\n",
    "    # plot age_range of breed_df bar plot\n",
    "\n",
    "    bar = (\n",
    "        breed_df.groupby([\"age_range\", \"roster\"])\n",
    "        .size()\n",
    "        .unstack()\n",
    "        .hvplot.bar(\n",
    "            rot=90,\n",
    "            legend=True,\n",
    "            tools=[\"hover\", \"box_select\"],\n",
    "            title=f\"Owner Age distribution | {breed.title()} \",\n",
    "            shared_axes=False,\n",
    "            xlabel=\"\",\n",
    "        )\n",
    "        .opts(active_tools=[\"box_select\"])\n",
    "    )\n",
    "    return (step + kde + bar).cols(1)\n",
    "\n",
    "\n",
    "# create widgets for the breed, bandwidth\n",
    "breed_selector = pnw.Select(name=\"Breed\", options=topn, value=\"french bulldog\")\n",
    "top_n_slider = pnw.IntSlider(name=\"Top N\", start=1,\n",
    "                             end=30, step=1, value=10, width=200)\n",
    "bandwidth_slider = pnw.FloatSlider(\n",
    "    name=\"Bandwidth\", start=0.1, end=2, step=0.1, value=0.5, width=200\n",
    ")\n",
    "pure_breed_checkbox = pnw.Checkbox(name=\"Pure Breed\", value=True, width=200)\n",
    "holder_gender_checkbox = pnw.Checkbox(\n",
    "    name='Male Dog Owner', value=True, width=200)\n",
    "roster_slider = pnw.DiscreteSlider(\n",
    "    options=[\"2015\", \"2016\", \"2017\"], name=\"Roster\", width=200\n",
    ")\n",
    "show_labels_checkbox = pnw.Checkbox(\n",
    "    name=\"Show Annotations\", value=True, width=200)\n",
    "\n",
    "\n",
    "# create a dynamic map\n",
    "\n",
    "dynamic_age_plot = pn.bind(\n",
    "    plot_age_range_stats,\n",
    "    df=dog_owner_df,\n",
    "    breed=breed_selector,\n",
    "    bw=bandwidth_slider,\n",
    "    pure_breed=pure_breed_checkbox,\n",
    ")\n",
    "widget_controls = pn.Row(\n",
    "    pure_breed_checkbox,\n",
    "    breed_selector,\n",
    "    bandwidth_slider,\n",
    "    styles={\"background\": \"mintcream\"},\n",
    ")\n",
    "dynamic_age_card = pn.Card(\n",
    "    widget_controls,\n",
    "    dynamic_age_plot,\n",
    "    title=\"Age Distribution of Dog and Owners by Breeds\",\n",
    "    styles={\"background\": \"mintcream\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On a map of Zurich, plot the number of dogs in each district\n",
    "# show any trend is clear like observed with the line plot with the French Bulldog and Chihuahua\n",
    "# plot the distribution by roster\n",
    "\n",
    "z_gdf = gdf.drop(columns=[\"kname\"]).rename(columns={\"knr\": \"district\"})\n",
    "z_gdf = z_gdf.set_index(z_gdf.district)\n",
    "\n",
    "z_set = gv.Dataset(z_gdf)\n",
    "zurich_poly = gv.Polygons(z_set).opts(\n",
    "    **poly_opts, selection_color=\"pink\", alpha=0, selection_alpha=0.5\n",
    ")\n",
    "basemap = gv.tile_sources.OSM().opts(alpha=0.5, bgcolor=\"black\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Breed District Polygons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a polygon chloropeth dynamic map which is interactive with the \n",
    "- breed selector widget (same single selector as above)\n",
    "- roster slider widget.\n",
    "The color of the colormap of the polygon map is specific to the selected breed. \n",
    "\n",
    "In addition you can interact with the map. If you click on anyone of the Polygon districts a short paragraph With the description of that neighborhood will show below the map and a word cloud from that paragraph will be shown above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pn.state.kill_all_servers()\n",
    "\n",
    "\n",
    "# get the count of the french bulldog in each district for each roster and plot it\n",
    "# plot it on a dynamic map with a slider for the roster\n",
    "def get_breed_count(breed, roster):\n",
    "    df = dog_owner_df[\n",
    "        (dog_owner_df[\"standard\"] == breed)\n",
    "        & (dog_owner_df[\"roster\"].str.contains(roster))\n",
    "    ]\n",
    "    df = df.groupby(\"district\").size().reset_index(name=\"count\")\n",
    "    df = df.set_index(\"district\")\n",
    "\n",
    "    breed_gdf = z_gdf.merge(df, left_index=True, right_index=True, how=\"left\")\n",
    "    breed_gdf = breed_gdf.drop(columns=[\"desc\", \"km2\"])\n",
    "    breed_color = explicit_mapping[breed]\n",
    "    # Start from white and go to the breed color\n",
    "    breed_cmap = list(sns.color_palette(\n",
    "        \"light:\"+breed_color, n_colors=6).as_hex())\n",
    "    return gv.Polygons(breed_gdf).opts(\n",
    "        **poly_opts,\n",
    "        color=\"count\",\n",
    "        cmap=breed_cmap,\n",
    "        clim=(0, 50),\n",
    "        colorbar=True,\n",
    "        tools=[\"hover\", \"tap\", \"box_select\"],\n",
    "        title=f\"{breed.title()} | {roster}\",\n",
    "    )\n",
    "\n",
    "\n",
    "standard_selecter = pnw.Select(\n",
    "    name=\"Breed\", options=topn, value=\"french bulldog\")\n",
    "# create the dynamic map\n",
    "breed_chloro = gv.DynamicMap(\n",
    "    pn.bind(get_breed_count, breed=breed_selector, roster=roster_slider)\n",
    ")\n",
    "\n",
    "# pn.Column(standard_selecter, pn.Row(roster_slider, basemap * breed_chloro))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a stream which selects a district from the map\n",
    "select_district = streams.Selection1D(source=zurich_poly)\n",
    "\n",
    "\n",
    "def display_info(index):\n",
    "    if not index:\n",
    "        return pn.pane.Markdown(\"No district selected\")\n",
    "    else:\n",
    "        selected_district = (\n",
    "            zurich_poly.iloc[index[0]]\n",
    "            .data[[\"district\", \"district_name\", \"desc\"]]\n",
    "            .drop_duplicates()\n",
    "        )\n",
    "        dname = selected_district[\"district_name\"].values[0]\n",
    "        dnum = selected_district[\"district\"].values[0]\n",
    "        ddesc = selected_district[\"desc\"].values[0]\n",
    "        return pn.pane.Markdown(f\"#### {dnum}\\n ### {dname}\\n {ddesc}\")\n",
    "\n",
    "\n",
    "def display_wordcloud(index, breed):\n",
    "    breed_color = explicit_mapping[breed]\n",
    "    if len(index) == 0:\n",
    "        text = \"district select on map\"\n",
    "        wordcloud = WordCloud(width=800, height=500, background_color=\"white\").generate(\n",
    "            text\n",
    "        )\n",
    "        return hv.RGB(np.array(wordcloud))\n",
    "    else:\n",
    "        selected_district = (\n",
    "            zurich_poly.iloc[index[0]]\n",
    "            .data[[\"district\", \"district_name\", \"desc\"]]\n",
    "            .drop_duplicates()\n",
    "        )\n",
    "        dname = selected_district[\"district_name\"].values[0]\n",
    "        dnum = selected_district[\"district\"].values[0]\n",
    "        ddesc = selected_district[\"desc\"].values[0]\n",
    "        text = f\"{dnum} {dname} {ddesc}\"\n",
    "\n",
    "        polygon = zurich_poly.iloc[index[0]].data['geometry'].iloc[0]\n",
    "\n",
    "        # Get the bounding box of the polygon\n",
    "        minx, miny, maxx, maxy = polygon.bounds\n",
    "\n",
    "        # Calculate the width and height of the bounding box\n",
    "        width = maxx - minx\n",
    "        height = maxy - miny\n",
    "\n",
    "        # Create a new image with the same aspect ratio as the bounding box\n",
    "        image_width = 800\n",
    "        image_height = int(image_width * height / width)\n",
    "        test = Image.new('1', (image_width, image_height), 0)\n",
    "\n",
    "        # Convert the coordinates to a numpy array\n",
    "        coords = np.array(list(polygon.exterior.coords))\n",
    "        coords -= [minx, miny]\n",
    "        coords *= [image_width / width, image_height / height]\n",
    "        coords[:, 1] = image_height - coords[:, 1]\n",
    "        # Convert the coordinates back to a list of tuples\n",
    "        scaled_coords = list(map(tuple, coords))\n",
    "\n",
    "        # Draw the scaled polygon onto the image\n",
    "        ImageDraw.Draw(test).polygon(scaled_coords, outline=1, fill=1)\n",
    "\n",
    "        wordcloud = WordCloud(\n",
    "            mask=~np.array(test)*255,\n",
    "            color_func=lambda *args, **kwargs: breed_color,\n",
    "            include_numbers=True,\n",
    "            margin=20,\n",
    "            contour_color=breed_color,\n",
    "            contour_width=5,\n",
    "            width=800,\n",
    "            height=500,\n",
    "            background_color=\"white\",\n",
    "        ).generate(text)\n",
    "        return hv.RGB(np.array(wordcloud)).opts(\n",
    "            width=800,\n",
    "            height=500,\n",
    "            tools=[\"box_zoom\"],\n",
    "            active_tools=[\"box_zoom\"],\n",
    "            xaxis=None,\n",
    "            yaxis=None,\n",
    "            # toolbar=None,\n",
    "        )\n",
    "\n",
    "\n",
    "layout = pn.Column(\n",
    "    pn.bind(display_wordcloud, select_district.param.index, breed=breed_selector),\n",
    "    zurich_poly * breed_chloro,\n",
    "    pn.bind(display_info, select_district.param.index),\n",
    ")\n",
    "\n",
    "breed_chloro_card = pn.Card(\n",
    "    roster_slider, layout, title=\"Chloropleth of Selected Breed\"\n",
    ")\n",
    "# breed_chloro_card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pn.state.kill_all_servers()\n",
    "#  create a panel layout\n",
    "\n",
    "\n",
    "pn.Row(\n",
    "    dynamic_age_card,\n",
    "    breed_chloro_card,\n",
    "    all_ages_card,\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### HeatMaps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have some heatmaps. \n",
    "- small breed heat map with the top 10 k breed type dogs and against the `districts` and also controlled by the `roster` widget\n",
    "- large breed heat map with the top 10 large breed type dogs and against the `districts` and also controlled by the `roster` widget\n",
    "- gender heatmap with the breeds against the `district` and is also controlled by the `roster` widget. Includes the `gender` checkbox to display only 1 gender of the dog_owners"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Small breed heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# state the breeds that we wnat in the heatmap\n",
    "\n",
    "small_heatmap_breeds = ktopn\n",
    "# group by roster also and see how the distribution changes\n",
    "small_breeds_df = dog_owner_df[dog_owner_df[\"standard\"].isin(\n",
    "    small_heatmap_breeds)]\n",
    "small_heatmap_breed_count = (\n",
    "    small_breeds_df.groupby([\"standard\", \"district\", \"roster\"])\n",
    "    .size()\n",
    "    .reset_index(name=\"size\")\n",
    ")\n",
    "# Define a function to create a heatmap\n",
    "\n",
    "\n",
    "def get_small_heatmap(roster, show_labels):\n",
    "    small_df = small_heatmap_breed_count[small_heatmap_breed_count[\"roster\"] == roster]\n",
    "    small_heatmap = hv.HeatMap(small_df, [\"district\", \"standard\"], \"size\").redim(\n",
    "        standard=\"small_standard\"\n",
    "    )\n",
    "    small_heatmap.opts(\n",
    "        # **heatmap_opts,\n",
    "        # cmap=cc.dimgray[::-1],\n",
    "        colorbar=True,\n",
    "        active_tools=[\"box_zoom\"],\n",
    "        title=f\"Top small breeds in {roster} by district\",\n",
    "        clim=(0, 50),\n",
    "    )\n",
    "    if show_labels:\n",
    "        labels = hv.Labels(small_df, [\"district\", \"standard\"], \"size\").opts(\n",
    "            text_color=\"crimson\"\n",
    "        )\n",
    "        return small_heatmap * labels\n",
    "    return small_heatmap\n",
    "\n",
    "\n",
    "small_dynamic_heatmap = pn.bind(\n",
    "    get_small_heatmap,\n",
    "    roster=roster_slider.param.value,\n",
    "    show_labels=show_labels_checkbox.param.value,\n",
    ")\n",
    "# pn.panel(small_dynamic_heatmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Large Breed Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_heatmap_breeds = itopn\n",
    "\n",
    "large_breed_df = dog_owner_df[dog_owner_df[\"standard\"].isin(\n",
    "    large_heatmap_breeds)]\n",
    "large_heatmap_breed_count = (\n",
    "    large_breed_df.groupby([\"standard\", \"district\", \"roster\"])\n",
    "    .size()\n",
    "    .reset_index(name=\"size\")\n",
    ")\n",
    "\n",
    "\n",
    "def get_large_heatmap(roster, show_labels):\n",
    "    large_df = large_heatmap_breed_count[large_heatmap_breed_count[\"roster\"] == roster]\n",
    "    large_heatmap = hv.HeatMap(large_df, [\"district\", \"standard\"], \"size\").redim(\n",
    "        standard=\"large_standard\"\n",
    "    )\n",
    "    large_heatmap.opts(\n",
    "        # **heatmap_opts,\n",
    "        # cmap=cc.dimgray[::-1],\n",
    "        colorbar=True,\n",
    "        active_tools=[\"box_zoom\"],\n",
    "        title=f\"Top large breeds in {roster} by district\",\n",
    "        clim=(\n",
    "            large_heatmap_breed_count[\"size\"].min(),\n",
    "            large_heatmap_breed_count[\"size\"].max(),\n",
    "        ),\n",
    "    )\n",
    "    if show_labels:\n",
    "        labels = hv.Labels(large_df, [\"district\", \"standard\"], \"size\").opts(\n",
    "            text_color=\"crimson\"\n",
    "        )\n",
    "        return large_heatmap * labels\n",
    "    return large_heatmap\n",
    "\n",
    "\n",
    "# Bind the widget to the function\n",
    "\n",
    "large_dynamic_heatmap = pn.bind(\n",
    "    get_large_heatmap,\n",
    "    roster=roster_slider.param.value,\n",
    "    show_labels=show_labels_checkbox.param.value,\n",
    ")\n",
    "# pn.panel(large_dynamic_heatmap)\n",
    "\n",
    "# Create a Panel layout\n",
    "# pn.Row(pn.Column(roster_slider, show_labels_checkbox), dynamic_heatmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gender Heatmap\n",
    "\n",
    "This is named gender heat map because one of its widgets checkbox filters for the gender of the dog owner. This could be used to be able to tell where the distribution is for only one specific dog owner gender."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Tap stream linked to the HeatMap\n",
    "breed_tap = streams.Tap(source=None)\n",
    "\n",
    "\n",
    "@pn.depends(roster_slider.param.value, holder_gender_checkbox.param.value)\n",
    "def get_gender_roster_df(roster, gender):\n",
    "    return dog_owner_df.loc[\n",
    "        (dog_owner_df[\"is_male_owner\"] == gender) & (dog_owner_df[\"roster\"] == roster)\n",
    "    ]\n",
    "\n",
    "\n",
    "@pn.depends(\n",
    "    roster_slider.param.value,\n",
    "    holder_gender_checkbox.param.value,\n",
    "    top_n_slider.param.value,\n",
    ")\n",
    "def get_top_n_gender_breeds(roster, gender, top_n):\n",
    "    gender_roster_df = get_gender_roster_df(roster=roster, gender=gender)\n",
    "    return gender_roster_df[\"standard\"].value_counts().head(top_n).index.tolist()\n",
    "\n",
    "\n",
    "@pn.depends(\n",
    "    roster_slider.param.value,\n",
    "    holder_gender_checkbox.param.value,\n",
    "    top_n_slider.param.value,\n",
    ")\n",
    "def get_gender_heatmap(roster, gender, top_n):\n",
    "    gender_roster_df = get_gender_roster_df(roster=roster, gender=gender)\n",
    "    topn_gender_breeds = get_top_n_gender_breeds(\n",
    "        roster=roster, gender=gender, top_n=top_n\n",
    "    )\n",
    "\n",
    "    top_gender_breeds_df = (\n",
    "        gender_roster_df.loc[gender_roster_df[\"standard\"].isin(topn_gender_breeds)]\n",
    "        .groupby([\"standard\", \"district\"])\n",
    "        .size()\n",
    "        .fillna(0)\n",
    "        .reset_index(name=\"count\")\n",
    "    )\n",
    "    sex = \"Male\" if gender else \"Female\"\n",
    "    top_gender_breeds_heatmap = hv.HeatMap(\n",
    "        top_gender_breeds_df, [\"district\", \"standard\"], \"count\"\n",
    "    ).redim(standard=\"gender_standard\")\n",
    "    top_gender_breeds_heatmap.opts(\n",
    "        height=(33 * top_n) + 50,\n",
    "        cmap=boy_cmap if gender else girl_cmap,\n",
    "        colorbar=True,\n",
    "        active_tools=[\"box_zoom\"],\n",
    "        title=f\"Top {top_n} breeds | {roster} | {sex} Owners\",\n",
    "        clim=(0, 50),\n",
    "    )\n",
    "    breed_tap.source = top_gender_breeds_heatmap\n",
    "\n",
    "    return top_gender_breeds_heatmap\n",
    "\n",
    "\n",
    "dynamic_gender_heatmap_panel = pn.pane.HoloViews(get_gender_heatmap)\n",
    "\n",
    "# pn.Column(\n",
    "#     roster_slider,\n",
    "#     holder_gender_checkbox,\n",
    "#     top_n_slider,\n",
    "#     dynamic_gender_heatmap_panel,\n",
    "# ).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chloropleth Map of the Dog owners.\n",
    "\n",
    "This is the geographical distribution of the gender heatmap. It includes all the filters of the gender heatmap and additionally the selected breed clicked on from the gender heatmap. The color of the map is specific to the selected breed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pn.depends(\n",
    "    breed_tap.param.x,\n",
    "    breed_tap.param.y,\n",
    "    roster_slider.param.value,\n",
    "    holder_gender_checkbox.param.value,\n",
    ")\n",
    "def get_breed_chloropleth(x, y, roster, gender):\n",
    "    if x is None or y is None:\n",
    "        return gv.Polygons(z_gdf).opts(**poly_opts, title=\"Select a cell\")\n",
    "    else:\n",
    "        data = get_gender_roster_df(roster=roster, gender=gender)\n",
    "        data = data.loc[data[\"standard\"] == y]\n",
    "        data = data.groupby(\"district\").size().reset_index(name=\"count\")\n",
    "        data = data.set_index(\"district\")\n",
    "\n",
    "        breed_gdf = z_gdf.merge(data, left_index=True,\n",
    "                                right_index=True, how=\"left\")\n",
    "        breed_gdf = breed_gdf.drop(columns=[\"desc\", \"km2\"])\n",
    "        breed_gdf.fillna(0, inplace=True)\n",
    "        breed_color = explicit_mapping[y]\n",
    "        breed_cmap = list(\n",
    "            sns.color_palette(\"light:\" + breed_color, n_colors=6).as_hex()\n",
    "        )\n",
    "        sex = \"Male\" if gender else \"Female\"\n",
    "\n",
    "        return gv.Polygons(breed_gdf).opts(\n",
    "            **poly_opts,\n",
    "            color=\"count\",\n",
    "            cmap=breed_cmap,\n",
    "            clim=(0, 50),\n",
    "            colorbar=True,\n",
    "            line_color=\"darkgray\",\n",
    "            tools=[\"hover\", \"tap\", \"box_select\"],\n",
    "            title=f\"{y.title()} | {roster} | {sex} Owners\",\n",
    "        )\n",
    "\n",
    "\n",
    "breed_chloropleth = pn.pane.HoloViews(get_breed_chloropleth)\n",
    "\n",
    "\n",
    "# Combine the heatmap and the text display into a layout\n",
    "layout = pn.Column(\n",
    "    roster_slider,\n",
    "    holder_gender_checkbox,\n",
    "    top_n_slider,\n",
    "    dynamic_gender_heatmap_panel,\n",
    "    breed_chloropleth,\n",
    ")\n",
    "\n",
    "layout.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a Tap stream linked to the owner age group\n",
    "owner_tap = streams.Tap(source=None, x=1, y=\"11-30\")\n",
    "\n",
    "\n",
    "@pn.depends(roster_slider.param.value, holder_gender_checkbox.param.value)\n",
    "def get_age_heatmap(roster, gender):\n",
    "    data = get_gender_roster_df(roster=roster, gender=gender)\n",
    "    data_grouped = (\n",
    "        data.groupby([\"age_group\", \"district\"])[\"holder_id\"]\n",
    "        .nunique()\n",
    "        .reset_index()\n",
    "        .rename(columns={\"holder_id\": \"count\"})\n",
    "    )\n",
    "    sex = \"Male\" if gender else \"Female\"\n",
    "    heatmap = hv.HeatMap(data_grouped, [\"district\", \"age_group\"], \"count\")\n",
    "\n",
    "    heatmap.opts(\n",
    "        # **heatmap_opts,\n",
    "        cmap=boy_cmap if gender else girl_cmap,\n",
    "        colorbar=True,\n",
    "        active_tools=[\"box_zoom\"],\n",
    "        tools=[\"hover\", \"tap\", \"box_select\"],\n",
    "        title=f\"{sex} Dog Owners | {roster} | by Age Group vs District\",\n",
    "    )\n",
    "    owner_tap.source = heatmap\n",
    "    return heatmap\n",
    "\n",
    "\n",
    "\n",
    "age_group_panel = pn.pane.HoloViews(get_age_heatmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "pn.state.kill_all_servers()\n",
    "# Bar Plot which shows the top 10 breeds for each district and age group as it is selected in the heatmap\n",
    "\n",
    "bar_plots_opts = dict(\n",
    "    height=500,\n",
    "    width=800,\n",
    "    invert_axes=True,\n",
    "    cmap=explicit_mapping,\n",
    "    show_legend=False,\n",
    "    xlabel=\"\",\n",
    "    fontscale=1.2,\n",
    ")\n",
    "\n",
    "\n",
    "@pn.depends(\n",
    "    owner_tap.param.x,\n",
    "    owner_tap.param.y,\n",
    "    roster_slider.param.value,\n",
    "    holder_gender_checkbox.param.value,\n",
    ")\n",
    "def update_barplot(x, y, roster, gender):\n",
    "    data = get_gender_roster_df(roster=roster, gender=gender)\n",
    "    if x is None or y is None:\n",
    "        bar_data = (\n",
    "            data[\"standard\"]\n",
    "            .value_counts()\n",
    "            .head(10)\n",
    "            .rename(\"count\")\n",
    "            .reset_index()\n",
    "            .rename(columns={\"index\": \"standard\"})\n",
    "        )\n",
    "        return hv.Bars(bar_data, kdims=[\"standard\"], vdims=\"count\").opts(\n",
    "            **bar_plots_opts,\n",
    "            color=\"standard\",\n",
    "            title=f\"Top 10 Breeds\",\n",
    "            tools=[\"hover\"],\n",
    "            active_tools=[\"box_zoom\"],\n",
    "        )\n",
    "    x = math.ceil(x - 0.5)\n",
    "    bar_data = (\n",
    "        data.loc[(data[\"district\"] == x) & (\n",
    "            data[\"age_group\"] == y)][\"standard\"]\n",
    "        .value_counts()\n",
    "        .head(10)\n",
    "        .reset_index()\n",
    "    )\n",
    "    bar_data.columns = [\"standard\", \"count\"]\n",
    "    if len(bar_data) == 0:\n",
    "        return hv.Bars([], \"standard\", \"count\").opts(\n",
    "            **bar_plots_opts,\n",
    "            title=f\"No Breeds for Age-group:{y} | Districts:{x}\",\n",
    "            active_tools=[\"box_zoom\"],\n",
    "        )\n",
    "\n",
    "    return hv.Bars(bar_data, \"standard\", \"count\").opts(\n",
    "        **bar_plots_opts,\n",
    "        color=\"standard\",\n",
    "        title=f\"Top {min(10,len(bar_data))} Popular Breeds | Age-group:{y} | Districts:{x}\",\n",
    "    )\n",
    "\n",
    "\n",
    "update_barplot_panel = pn.pane.HoloViews(update_barplot)\n",
    "pn.Column(\n",
    "    roster_slider,\n",
    "    holder_gender_checkbox,\n",
    "    age_group_panel,\n",
    "    update_barplot_panel,\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pn.state.kill_all_servers()\n",
    "# Create a Panel layout\n",
    "\n",
    "pn.Row(\n",
    "    pn.Column(roster_slider, show_labels_checkbox,\n",
    "              holder_gender_checkbox, width=300),\n",
    "    pn.Column(pn.panel(age_group_heatmap), update_barplot_panel),\n",
    "    pn.panel(small_dynamic_heatmap),\n",
    "    pn.panel(large_dynamic_heatmap),\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analytical interpretation of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for correlation between age and dog_age\n",
    "dog_owner_df[\"age_range_number\"] = dog_owner_df[\"age_range\"].cat.codes\n",
    "\n",
    "dog_owner_df[\"age_range_number\"].corr(dog_owner_df[\"dog_age\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog_owner_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dog_owner_df[\"age_group\"].cat.codes\n",
    "dog_owner_df[\"age_group_number\"] = dog_owner_df[\"age_group\"].cat.codes\n",
    "# check for a correlation between the age_group and the dog_age\n",
    "dog_owner_df[\"age_group_number\"].corr(dog_owner_df[\"dog_age\"])\n",
    "# check for a correlation between the age_group and the dog_age but for specific breeds and for each roster\n",
    "print(\"Correlation between age_group and dog_age for top breeds: \")\n",
    "\n",
    "correlations = []\n",
    "for breed in topn:\n",
    "    for roster in [\"2015\", \"2016\", \"2017\"]:\n",
    "        breed_roster_df = dog_owner_df[\n",
    "            (dog_owner_df[\"standard\"] == breed) & (\n",
    "                dog_owner_df[\"roster\"] == roster)\n",
    "        ]\n",
    "        correlation = breed_roster_df[\"age_range_number\"].corr(\n",
    "            breed_roster_df[\"dog_age\"]\n",
    "        )\n",
    "        correlations.append((breed, roster, correlation))\n",
    "\n",
    "correlation_df = (\n",
    "    pd.DataFrame(correlations, columns=[\"breed\", \"roster\", \"correlation\"])\n",
    "    .pivot(columns=\"roster\", index=\"breed\", values=\"correlation\")\n",
    "    .reset_index()\n",
    ")\n",
    "display(correlation_df)\n",
    "\n",
    "# chi Square test s\n",
    "cols_for_chi = [\n",
    "    \"is_male_dog\",\n",
    "    \"is_male_owner\",\n",
    "    \"pure_breed\",\n",
    "    \"breed_type\",\n",
    "    \"roster\",\n",
    "    \"age_group\",\n",
    "]\n",
    "# get empty dataframe\n",
    "chi_list = []\n",
    "# loop through for p values\n",
    "for roster in dog_owner_df[\"roster\"].unique():\n",
    "    for col in cols_for_chi:\n",
    "        cross_tab = pd.crosstab(dog_owner_df[col], dog_owner_df[\"age_group\"])\n",
    "        chi2, p, dof, expected = chi2_contingency(cross_tab)\n",
    "        chi_list.append(\n",
    "            {\n",
    "                \"roster\": roster,\n",
    "                \"var\": col,\n",
    "                \"chi2\": chi2,\n",
    "                \"p\": p,\n",
    "                \"dof\": dof,\n",
    "                \"expected\": expected,\n",
    "            }\n",
    "        )\n",
    "\n",
    "chi_df = pd.DataFrame(chi_list)\n",
    "# visualize the results of the Chi Test\n",
    "chi_heatmap = hv.HeatMap(chi_df, kdims=[\"roster\", \"var\"], vdims=[\"p\"]).opts(\n",
    "    cnorm=\"eq_hist\", colorbar=True, title=\"Chi Test P-Values\")\n",
    "pn.panel(chi_heatmap).show()\n",
    "\n",
    "print(f\"Stats for the dog age for each roster: \")\n",
    "display(\n",
    "    dog_owner_df.groupby([\"roster\"])[\"dog_age\"]\n",
    "    .agg(\n",
    "        [\n",
    "            \"mean\",\n",
    "            \"median\",\n",
    "            \"std\",\n",
    "            \"skew\",\n",
    "        ]\n",
    "    )\n",
    "    .round(2)\n",
    ")\n",
    "\n",
    "print(f\"Stats of the dog age for each roster and owner age group: \")\n",
    "dog_age_stats_by_owner_age = (\n",
    "    dog_owner_df.groupby([\"age\", \"roster\"])[\"dog_age\"]\n",
    "    .apply(\n",
    "        lambda x: pd.Series(\n",
    "            {\n",
    "                \"mean\": x.mean(),\n",
    "                \"median\": x.median(),\n",
    "                \"std\": x.std(),\n",
    "                \"skew\": x.skew(),\n",
    "                \"kurt\": x.kurt(),\n",
    "                \"size\": x.size,\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "    .round(2)\n",
    "    .unstack()\n",
    ")\n",
    "display(dog_age_stats_by_owner_age)\n",
    "\n",
    "for roster in dog_owner_df[\"roster\"].unique():\n",
    "    roster_df = dog_owner_df[dog_owner_df[\"roster\"] == roster]\n",
    "    correlation = roster_df[\"age\"].corr(roster_df[\"dog_age\"], method=\"kendall\")\n",
    "    print(\n",
    "        f\"Correlation between owner age and dog age for roster {roster}: {correlation}\"\n",
    "    )\n",
    "\n",
    "print(f\"Most common breeds for each age group and roster: \")\n",
    "most_common_breeds = (\n",
    "    dog_owner_df.groupby([\"age_group\", \"roster\"])[\"breed\"]\n",
    "    .apply(lambda x: x.value_counts().index[0])\n",
    "    .unstack()\n",
    ")\n",
    "print(most_common_breeds)\n",
    "\n",
    "# See which breeds tend to live the longest\n",
    "print(f\"Breeds with the longest lifespan: \")\n",
    "breed_stats = (\n",
    "    dog_owner_df.groupby([\"standard\", \"roster\"])[\"dog_age\"]\n",
    "    .apply(\n",
    "        lambda x: pd.Series(\n",
    "            {\n",
    "                \"mean\": x.mean(),\n",
    "                \"median\": x.median(),\n",
    "                \"std\": x.std(),\n",
    "                \"skew\": x.skew(),\n",
    "                \"kurt\": x.kurt(),\n",
    "                \"size\": x.size,\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "    .round(2)\n",
    "    .unstack()\n",
    ")\n",
    "breed_stats.loc[breed_stats[\"size\"] > 20].sort_values(\n",
    "    by=[\"mean\"], ascending=False\n",
    ").head(30)\n",
    "\n",
    "\n",
    "# Bootstrap analysis for dog_age for each top breed\n",
    "n_bootstrap_samples = 10000\n",
    "bootstrap_means = pd.DataFrame()\n",
    "\n",
    "for breed in topn:\n",
    "    for roster in dog_owner_df[\"roster\"].unique():\n",
    "        breed_df = dog_owner_df[\n",
    "            (dog_owner_df[\"standard\"] == breed) & (\n",
    "                dog_owner_df[\"roster\"] == roster)\n",
    "        ]\n",
    "        bootstrap_samples = np.random.choice(\n",
    "            breed_df[\"dog_age\"], size=(n_bootstrap_samples, len(breed_df)), replace=True\n",
    "        )\n",
    "        bootstrap_mean = bootstrap_samples.mean(axis=1)\n",
    "        bootstrap_means[f\"{breed}_{roster}\"] = bootstrap_mean\n",
    "\n",
    "\n",
    "print(f\"Bootstrap analysis for dog_age for each top breed: \")\n",
    "bootstrap_means.describe().T.sort_values(by=\"mean\", ascending=False)\n",
    "\n",
    "# check the bootstrap again but for the swiss breeds\n",
    "bootstrap_means_swiss = pd.DataFrame()\n",
    "for breed in swiss_breeds:\n",
    "    for roster in dog_owner_df[\"roster\"].unique():\n",
    "        breed_df = dog_owner_df[\n",
    "            (dog_owner_df[\"standard\"] == breed) & (\n",
    "                dog_owner_df[\"roster\"] == roster)\n",
    "        ]\n",
    "        bootstrap_samples = np.random.choice(\n",
    "            breed_df[\"dog_age\"], size=(n_bootstrap_samples, len(breed_df)), replace=True\n",
    "        )\n",
    "        bootstrap_mean_swiss = bootstrap_samples.mean(axis=1)\n",
    "        bootstrap_means_swiss[f\"{breed}_{roster}\"] = bootstrap_mean_swiss\n",
    "\n",
    "print(f\"Bootstrap analysis for dog_age for each swiss breed: \")\n",
    "bootstrap_means_swiss.describe().T.sort_values(by=\"mean\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dog_owner_df.info()\n",
    "# fa_cols = [\n",
    "#     \"breed_type\",\n",
    "#     \"district\",\n",
    "#     \"roster\",\n",
    "#     \"is_male_owner\",\n",
    "#     \"is_male_dog\",\n",
    "#     \"age_group\",\n",
    "#     \"dog_age\",\n",
    "#     \"dog_count\",\n",
    "#     \"is_swiss\",\n",
    "#     \"pure_breed\",\n",
    "#     \"color1\",\n",
    "# ]\n",
    "# len(fa_cols)\n",
    "\n",
    "# fa_df = dog_owner_df[fa_cols]\n",
    "# fa_df.info()\n",
    "# # Example of encoding a categorical variable\n",
    "# fa_df[\"district\"] = fa_df[\"district\"].astype(\"category\")\n",
    "# fa_df = pd.get_dummies(\n",
    "#     fa_df,\n",
    "#     columns=[\"breed_type\", \"district\", \"roster\", \"age_group\", \"color1\"],\n",
    "#     drop_first=True,\n",
    "# )\n",
    "# scaler = StandardScaler()\n",
    "# fa_df = pd.DataFrame(scaler.fit_transform(fa_df), columns=fa_df.columns)\n",
    "# fa_df.info()\n",
    "\n",
    "cluster_df = dog_owner_df.copy()\n",
    "# Define preprocessing for numeric columns (scale them)\n",
    "numeric_features = [\"dog_age\", \"dog_count\"]\n",
    "numeric_transformer = Pipeline(steps=[(\"scaler\", StandardScaler())])\n",
    "\n",
    "# Define preprocessing for categorical features (encode them)\n",
    "categorical_features = [\n",
    "    \"breed_type\",\n",
    "    \"district\",\n",
    "    \"roster\",\n",
    "    \"age_group\",\n",
    "    \"color1\",\n",
    "    \"is_male_owner\",\n",
    "    \"is_male_dog\",\n",
    "    \"is_swiss\",\n",
    "    \"pure_breed\",\n",
    "]\n",
    "categorical_transformer = Pipeline(\n",
    "    steps=[(\"onehot\", OneHotEncoder(drop=\"first\"))])\n",
    "\n",
    "# Combine preprocessing steps\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create preprocessing and training pipeline\n",
    "pipeline = Pipeline(steps=[(\"preprocessor\", preprocessor)])\n",
    "\n",
    "# Fit the pipeline to train data\n",
    "pipeline.fit(cluster_df[numeric_features + categorical_features])\n",
    "\n",
    "# Transform the dataset\n",
    "cluster_data = pipeline.transform(\n",
    "    cluster_df[numeric_features + categorical_features])\n",
    "\n",
    "kmeans = KMeans(init='k-means++', n_init='auto', n_clusters=5, random_state=42)\n",
    "clusters = kmeans.fit_predict(cluster_data)\n",
    "\n",
    "cluster_df[\"cluster\"] = clusters\n",
    "\n",
    "cluster_df[\"cluster\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inertias = []\n",
    "ks = range(2, 11)\n",
    "\n",
    "for k in ks:\n",
    "    kmeans = KMeans(n_init=\"auto\", n_clusters=k, random_state=628)\n",
    "    kmeans.fit_predict(cluster_data)\n",
    "    print(f\"k: {k}, Inertia: {kmeans.inertia_:.0f}\")\n",
    "\n",
    "    inertias.append(kmeans.inertia_)\n",
    "\n",
    "# plot inertia vs k\n",
    "plt.figure(figsize=(7, 7))\n",
    "plt.plot(ks, inertias, \"-o\")\n",
    "plt.xticks(ks)\n",
    "plt.xlabel(\"Number of cluster, k\")\n",
    "plt.ylabel(\"Inertia\")\n",
    "plt.title(\"Inertia for different number of clusters\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "# Fit PCA and get explained variance ratios\n",
    "pca = PCA().fit(fa_df)\n",
    "evr = pca.explained_variance_ratio_\n",
    "\n",
    "# # Plot explained variance ratios\n",
    "# plt.plot(range(1, len(evr) + 1), evr, \"o-\")\n",
    "# plt.xlabel(\"Number of components\")\n",
    "# plt.ylabel(\"Explained variance ratio\")\n",
    "# plt.show()\n",
    "\n",
    "# Number of components with eigenvalue > 1\n",
    "n_components = sum(pca.explained_variance_ > 1)\n",
    "print(f\"Number of components (Kaiser Criterion): {n_components}\")\n",
    "\n",
    "# Calculate cumulative explained variance\n",
    "cumulative_evr = np.cumsum(evr)\n",
    "\n",
    "# Plot cumulative explained variance\n",
    "plt.plot(range(1, len(cumulative_evr) + 1), cumulative_evr, \"o-\")\n",
    "plt.xlabel(\"Number of components\")\n",
    "plt.ylabel(\"Cumulative explained variance\")\n",
    "plt.axhline(y=0.8, color=\"r\", linestyle=\"--\")  # 80% threshold\n",
    "plt.show()\n",
    "\n",
    "# Number of components for 80% variance\n",
    "n_components = np.where(cumulative_evr >= 0.8)[0][0] + 1\n",
    "print(f\"Number of components (80% variance): {n_components}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import FactorAnalysis\n",
    "\n",
    "# Initialize FactorAnalysis object\n",
    "fa = FactorAnalysis(n_components=76)  # or 77 based on your previous analysis\n",
    "\n",
    "# Fit and transform the data\n",
    "fa_scores = fa.fit_transform(fa_df)\n",
    "# Get factor loadings\n",
    "loadings = pd.DataFrame(fa.components_, columns=fa_df.columns)\n",
    "\n",
    "# Get unique variances\n",
    "uniqueness = pd.Series(fa.noise_variance_, index=fa_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_significant_loadings(loadings_df, threshold=0.4):\n",
    "    return loadings_df.style.applymap(\n",
    "        lambda x: \"background-color: yellow\" if np.abs(x) > threshold else \"\")\n",
    "\n",
    "\n",
    "# highlight_significant_loadings(loadings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from factor_analyzer.factor_analyzer import calculate_kmo, calculate_bartlett_sphericity\n",
    "from factor_analyzer import FactorAnalyzer\n",
    "\n",
    "\n",
    "chi2, p = calculate_bartlett_sphericity(fa_df)\n",
    "print(f\"Bartlett's test of sphericity: {chi2} | {p}\")\n",
    "\n",
    "# ccreate factor analysis object and perform factor analysis\n",
    "fa = FactorAnalyzer()\n",
    "fa.fit(fa_df)\n",
    "# Check Eigenvalues\n",
    "ev, v = fa.get_eigenvalues()\n",
    "\n",
    "\n",
    "fa.loadings_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group by roster and district and get the number of dogs in each district\n",
    "district_dog_owners = (\n",
    "    dog_owner_df.groupby([\"roster\", \"district\"])[\"dog_count\"].count().reset_index()\n",
    ")\n",
    "district_dog_owners.rename(columns={0: \"dog_count\"}, inplace=True)\n",
    "# plot a bar chart of the number of dogs in each district groupby roster\n",
    "# plot the bars for each roster in ta separate row in one layout using holoviews\n",
    "bars = [\n",
    "    district_dog_owners[district_dog_owners[\"roster\"] == roster]\n",
    "    .hvplot.bar(\n",
    "        x=\"district\",\n",
    "        y=\"dog_count\",\n",
    "        title=f\"Number of dogs in each district in {roster}\",\n",
    "        xlabel=\"\",\n",
    "        ylabel=\"Number of dogs\",\n",
    "        tools=[\"hover\"],\n",
    "        width=600,\n",
    "        height=300,\n",
    "    )\n",
    "    .opts(\n",
    "        active_tools=[\"box_zoom\"],\n",
    "    )\n",
    "    for roster in district_dog_owners[\"roster\"].unique()\n",
    "]\n",
    "hv.Layout(bars).cols(1)\n",
    "\n",
    "district_dog_owners.hvplot(\n",
    "    x=\"district\",\n",
    "    y=\"dog_count\",\n",
    "    by=\"roster\",\n",
    "    kind=\"bar\",\n",
    "    stacked=False,\n",
    "    rot=90,\n",
    "    legend=True,\n",
    "    tools=[\"hover\"],\n",
    "    width=800,\n",
    "    height=500,\n",
    "    title=\"Number of dog owners in each district\",\n",
    ").opts(\n",
    "    active_tools=[\"box_zoom\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top Breed counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by standard and roster, and calculate the size for each group\n",
    "df_breed_counts = (\n",
    "    dog_owner_df[dog_owner_df[\"standard\"].isin(topn)]\n",
    "    .groupby([\"standard\", \"roster\"])\n",
    "    .size()\n",
    "    .reset_index(name=\"size\")\n",
    ")\n",
    "df_breed_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_overlay(\n",
    "    df_breed_counts,\n",
    "    color_mapping=explicit_mapping,\n",
    "    x_col=\"roster\",\n",
    "    y_col=\"size\",\n",
    "    color_col=\"standard\",\n",
    "):\n",
    "    points = hv.Points(df_breed_counts, [x_col, y_col], color_col).opts(\n",
    "        color=\"standard\",\n",
    "        cmap=color_mapping,\n",
    "        width=800,\n",
    "        height=500,\n",
    "        size=8,\n",
    "        legend_position=\"right\",\n",
    "        tools=[\"hover\"],\n",
    "    )\n",
    "\n",
    "    # Create a Curve for each 'standard' and then overlay them\n",
    "    curves = hv.NdOverlay(\n",
    "        {\n",
    "            standard: hv.Curve(data, x_col, y_col).opts(\n",
    "                color=color_mapping[standard])\n",
    "            for standard, data in df_breed_counts.groupby(color_col)\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Overlay the points on the curves\n",
    "    plot = curves * points\n",
    "\n",
    "    return plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_overlay(df_breed_counts, explicit_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the percentage change in the number of dogs for each breed\n",
    "df_trend_pivot = df_breed_counts.pivot(\n",
    "    index=\"standard\", columns=\"roster\", values=\"size\"\n",
    ")\n",
    "df_breed_trend = (\n",
    "    df_trend_pivot.T.pct_change().T.fillna(0).stack().reset_index(name=\"pct_change\")\n",
    ")\n",
    "pct_change_overlay = create_overlay(\n",
    "    df_breed_trend, explicit_mapping, x_col=\"roster\", y_col=\"pct_change\"\n",
    ")\n",
    "\n",
    "zero_line = hv.HLine(0).opts(\n",
    "    line_dash=\"dashed\",\n",
    "    line_color=\"lightgray\",\n",
    ")\n",
    "(pct_change_overlay * zero_line).opts(title=\"Top Breeds Percent Change YOY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the breeds to highlight\n",
    "highlight_breeds = [\"chihuahua\", \"french bulldog\", \"poodle\"]\n",
    "\n",
    "# Calculate the percentage change for each breed from year to year\n",
    "df_trend_pivot_pct_change = df_trend_pivot.pct_change(axis=\"columns\").fillna(0)\n",
    "\n",
    "\n",
    "# Plot the highlighted breeds\n",
    "highlight_line_plot = [\n",
    "    df_trend_pivot_pct_change.loc[highlight_breed].T.hvplot(\n",
    "        kind=\"line\",\n",
    "        legend=\"right\",\n",
    "        color=explicit_mapping[highlight_breed],\n",
    "    )\n",
    "    for highlight_breed in highlight_breeds\n",
    "]\n",
    "\n",
    "highlight_dot_plot = [\n",
    "    df_trend_pivot_pct_change.loc[highlight_breed].T.hvplot.scatter(\n",
    "        legend=\"right\",\n",
    "        color=explicit_mapping[highlight_breed],\n",
    "    )\n",
    "    for highlight_breed in highlight_breeds\n",
    "]\n",
    "\n",
    "# Plot the other breeds\n",
    "other_line_plot = df_trend_pivot_pct_change.drop(highlight_breeds).T.hvplot(\n",
    "    kind=\"line\", legend=\"right\", color=\"lightgray\"\n",
    ")\n",
    "other_dot_plot = df_trend_pivot_pct_change.drop(highlight_breeds).T.hvplot.scatter(\n",
    "    legend=\"right\", color=\"lightgray\"\n",
    ")\n",
    "\n",
    "# add in the zero like  dotted\n",
    "zero_line = hv.HLine(0).opts(line_dash=\"dashed\", line_color=\"lightgray\")\n",
    "# zero_line * line_plot_pct_change * dot_plot_pct_change\n",
    "# line_plot_pct_change * dot_plot_pct_change\n",
    "\n",
    "# Combine the plots\n",
    "(\n",
    "    zero_line\n",
    "    * other_line_plot\n",
    "    * other_dot_plot\n",
    "    * hv.Overlay(highlight_line_plot)\n",
    "    * hv.Overlay(highlight_dot_plot)\n",
    ").opts(\n",
    "    title=\"Percent Change in Breeds YOY\",\n",
    "    height=600,\n",
    "    width=800,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf[\"centroid\"] = gdf.to_crs(ccrs.GOOGLE_MERCATOR).geometry.centroid.to_crs(epsg=4326)\n",
    "gdf[\"lon\"], gdf[\"lat\"] = gdf[\"centroid\"].x, gdf[\"centroid\"].y\n",
    "districts_pts = gdf.hvplot.points(\n",
    "    x=\"lon\",\n",
    "    y=\"lat\",\n",
    "    geo=True,\n",
    "    tiles=\"OSM\",\n",
    "    hover_cols=[\"kname\"],\n",
    "    alpha=0.5,\n",
    "    color=\"skyblue\",\n",
    "    size=200,\n",
    "    title=\"Zurich Districts\",\n",
    "    width=800,\n",
    "    height=500,\n",
    "    tools=[\"tap\"],\n",
    "    selection_line_color=\"black\",\n",
    "    selection_fill_color=\"red\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_dog_owners = dog_owner_df.holder_id.nunique()  # 7720\n",
    "dog_owner_df[[\"standard\", \"roster\", \"roster_count\", \"holder_id\"]].sort_values(\n",
    "    \"holder_id\"\n",
    ")\n",
    "# owners each roster\n",
    "dog_owner_df.groupby([\"roster\"])[\"holder_id\"].nunique()\n",
    "\n",
    "# french bulldog owners each roster\n",
    "french_bulldog_owner_df = (\n",
    "    dog_owner_df[\n",
    "        dog_owner_df[\"standard\"].str.contains(\n",
    "            \"french bulldog\", case=False, regex=True, na=False\n",
    "        )\n",
    "    ]\n",
    "    .groupby([\"roster\"])[\"holder_id\"]\n",
    "    .unique()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_breed_owners_stats(dog_owner_df, breed):\n",
    "    \"\"\"Func for the row with the stats for the breed new, returning, and left owner numbers\"\"\"\n",
    "    if breed == \"all\":\n",
    "        breed_owner_df = dog_owner_df.copy()\n",
    "    else:\n",
    "        breed_owner_df = dog_owner_df.query(\n",
    "            f'standard.str.contains(\"{breed}\", case=False, regex=True, na=False)'\n",
    "        )\n",
    "    owner_stats = {}\n",
    "    for year in [\"2015\", \"2016\", \"2017\"]:\n",
    "        breed_owner_year = get_owners(breed_owner_df, year)\n",
    "        owner_stats[year] = len(breed_owner_year)\n",
    "\n",
    "        if year != \"2015\":\n",
    "            prev_year = str(int(year) - 1)\n",
    "            breed_owner_prev_year = get_owners(breed_owner_df, prev_year)\n",
    "\n",
    "            new_owners = get_new_owners(breed_owner_year, breed_owner_prev_year)\n",
    "            returning_owners = get_returning_owners(\n",
    "                breed_owner_year, breed_owner_prev_year\n",
    "            )\n",
    "            left_owners = get_left_owners(breed_owner_year, breed_owner_prev_year)\n",
    "\n",
    "            owner_stats[f\"new_{year}\"] = len(new_owners)\n",
    "            owner_stats[f\"returning_{year}\"] = len(returning_owners)\n",
    "            owner_stats[f\"left_{year}\"] = len(left_owners)\n",
    "\n",
    "    # constant owners for all 3 years\n",
    "    constant_owners = (\n",
    "        get_owners(breed_owner_df, \"2015\")\n",
    "        .intersection(get_owners(breed_owner_df, \"2016\"))\n",
    "        .intersection(get_owners(breed_owner_df, \"2017\"))\n",
    "    )\n",
    "    owner_stats[\"constant_owners\"] = len(constant_owners)\n",
    "\n",
    "    gap_owners = (\n",
    "        get_owners(breed_owner_df, \"2015\")\n",
    "        .intersection(get_owners(breed_owner_df, \"2017\"))\n",
    "        .difference(get_owners(breed_owner_df, \"2016\"))\n",
    "    )\n",
    "    owner_stats[\"gap_owners\"] = len(gap_owners)\n",
    "    # change the order of columns to make it more readable\n",
    "    owner_stats = {\n",
    "        \"breed\": breed,\n",
    "        \"constant_owners\": owner_stats[\"constant_owners\"],\n",
    "        \"gap_owners\": owner_stats[\"gap_owners\"],\n",
    "        \"2015\": owner_stats[\"2015\"],\n",
    "        \"2016\": owner_stats[\"2016\"],\n",
    "        \"2017\": owner_stats[\"2017\"],\n",
    "        \"new_2016\": owner_stats[\"new_2016\"],\n",
    "        \"returning_2016\": owner_stats[\"returning_2016\"],\n",
    "        \"left_2016\": owner_stats[\"left_2016\"],\n",
    "        \"new_2017\": owner_stats[\"new_2017\"],\n",
    "        \"returning_2017\": owner_stats[\"returning_2017\"],\n",
    "        \"left_2017\": owner_stats[\"left_2017\"],\n",
    "    }\n",
    "\n",
    "    return pd.DataFrame(owner_stats, index=[0])\n",
    "\n",
    "\n",
    "# Usage:\n",
    "french_bulldog_stats = get_breed_owners_stats(dog_owner_df, \"french bulldog\")\n",
    "get_breed_owners_stats(dog_owner_df, \"all\")\n",
    "\n",
    "# breed_owner_stats_list = [\n",
    "#     get_breed_owners_stats(dog_owner_df, breed) for breed in top_breeds\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "owner_2015 = get_owners(dog_owner_df, \"2015\")\n",
    "owner_2016 = get_owners(dog_owner_df, \"2016\")\n",
    "owner_2017 = get_owners(dog_owner_df, \"2017\")\n",
    "left_2016 = get_left_owners(owner_2016, owner_2015)\n",
    "left_2017 = get_left_owners(owner_2017, owner_2016)\n",
    "(\n",
    "    dog_owner_df.loc[dog_owner_df[\"holder_id\"].isin(left_2016)][\"age\"]\n",
    "    .value_counts()\n",
    "    .sort_index()\n",
    "    .hvplot.bar()\n",
    "    + dog_owner_df.loc[dog_owner_df[\"holder_id\"].isin(left_2017)][\"age\"]\n",
    "    .value_counts()\n",
    "    .sort_index()\n",
    "    .hvplot.bar()\n",
    ").cols(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Breed roster counts stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Owner ins and outs for the top 10 breeds\n",
    "pd.concat(\n",
    "    [get_breed_owners_stats(dog_owner_df, breed) for breed in ktopn], axis=0\n",
    ").reset_index(drop=True)\n",
    "pd.concat(\n",
    "    [get_breed_owners_stats(dog_owner_df, breed) for breed in topn], axis=0\n",
    ").reset_index(drop=True)\n",
    "\n",
    "# breed_ii_owners = set(\n",
    "#     dog_owner_df.loc[(dog_owner_df[\"breed_type\"] == \"II\")][\"holder_id\"].tolist()\n",
    "# )\n",
    "# dog_owner_df.loc[dog_owner_df[\"holder_id\"].isin(breed_ii_owners)].sort_values(\n",
    "#     \"holder_id\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dog_owner_df[(dog_owner_df[\"breed_type\"] == \"II\")].groupby(\n",
    "#     [\"standard\", \"roster\"]\n",
    "# ).size().unstack().sort_values(by=\"2017\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the widget\n",
    "roster_slider = pnw.DiscreteSlider(options=[\"2015\", \"2016\", \"2017\"], name=\"Roster\")\n",
    "district_slider = pnw.IntSlider(name=\"District\", value=1, start=1, end=12)\n",
    "\n",
    "\n",
    "selection_stream = streams.Selection1D(source=zurich_poly)\n",
    "\n",
    "\n",
    "def get_barplot(roster, district):\n",
    "    # Get the data for the selected district and roster\n",
    "    df = (\n",
    "        dog_owner_df[\n",
    "            (dog_owner_df[\"district\"] == district) & (dog_owner_df[\"roster\"] == roster)\n",
    "        ]\n",
    "        .groupby(\"standard\")\n",
    "        .size()\n",
    "        .sort_values(ascending=False)\n",
    "        .reset_index(name=\"count\")\n",
    "        .head()\n",
    "    )\n",
    "\n",
    "    # Create the barplot\n",
    "    barplot = hv.Bars(df, \"standard\", \"count\").opts(\n",
    "        **bar_opts,\n",
    "        color=\"standard\",\n",
    "        title=f\"Top 5 breeds in {roster} in district {district}\",\n",
    "    )\n",
    "    lables = hv.Labels(df, [\"standard\", \"count\"], \"standard\").opts(\n",
    "        text_font_size=\"14pt\", text_color=\"white\", text_align=\"right\"\n",
    "    )\n",
    "    return barplot\n",
    "\n",
    "\n",
    "bar_panel = pn.panel(\n",
    "    pn.bind(get_barplot, roster=roster_slider, district=district_slider)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_panel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Networkx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gap owners\n",
    "import matplotlib.pyplot as plt\n",
    "from networkx.algorithms import community\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# movers\n",
    "\n",
    "\n",
    "def get_district_targets(df, roster_year, target_column=\"district\"):\n",
    "    \"\"\"Return the values for the target column for the given roster year with holder_id\"\"\"\n",
    "    return df[df[\"roster\"] == roster_year][\n",
    "        [\"holder_id\", target_column]\n",
    "    ].drop_duplicates()\n",
    "\n",
    "\n",
    "# district_count_df = dog_owner_df[[\"holder_id\", \"district\", \"roster\"]]\n",
    "\n",
    "# district_count_pivot = (\n",
    "#     district_count_df.drop_duplicates()\n",
    "#     .pivot(columns=\"roster\", values=\"district\", index=\"holder_id\")\n",
    "#     .reset_index()\n",
    "# )\n",
    "\n",
    "# district_count_pivot[\"movers\"] = district_count_pivot.apply(\n",
    "#     lambda x: len(set(v for v in x[1:3] if pd.notnull(v))) > 1, axis=1\n",
    "# )\n",
    "\n",
    "# district_count_pivot[\"mover_count\"] = district_count_pivot.apply(\n",
    "#     lambda x: len(set(v for v in x[1:3] if pd.notnull(v))), axis=1\n",
    "# ).astype(str)\n",
    "\n",
    "\n",
    "# moves_df = (\n",
    "#     district_count_pivot.loc[district_count_pivot[\"movers\"]]\n",
    "#     .fillna(0)\n",
    "#     .drop(columns=[\"movers\"])\n",
    "# )\n",
    "\n",
    "# movers_df = district_count_pivot.fillna(0).rename(\n",
    "#     columns={\n",
    "#         \"2015\": \"holder_district_2015\",\n",
    "#         \"2016\": \"holder_district_2016\",\n",
    "#         # \"2017\": \"holder_district_2017\",\n",
    "#     }\n",
    "# )\n",
    "# movers_df\n",
    "\n",
    "get_district_targets(dog_owner_df, \"2015\", \"2016\", \"2017\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dict with histogram opts\n",
    "hist_opts = dict(\n",
    "    width=300, height=300, framewise=True, axiswise=True, active_tools=[\"box_zoom\"]\n",
    ")\n",
    "\n",
    "\n",
    "# Function to create a graph from a DataFrame\n",
    "def create_graph(df, source, target):\n",
    "    return nx.from_pandas_edgelist(df, source=source, target=target, edge_attr=True)\n",
    "\n",
    "\n",
    "# Function to calculate centralities\n",
    "def calculate_centralities(graph, centralities):\n",
    "    # Define the states dictionary\n",
    "    states = {node: 1 for node in graph.nodes}\n",
    "\n",
    "    results = {}\n",
    "    for name, function in centralities.items():\n",
    "        if name == \"Percolation\":\n",
    "            # Pass the states dictionary to the percolation_centrality function\n",
    "            results[name] = function(graph, states=states)\n",
    "        else:\n",
    "            results[name] = function(graph)\n",
    "    return results\n",
    "\n",
    "\n",
    "# Function to plot centralities\n",
    "def plot_centralities(centralities):\n",
    "    plots = [\n",
    "        hv.Histogram(\n",
    "            np.histogram(list(centrality.values()), bins=8),\n",
    "            kdims=\"Centrality\",\n",
    "            vdims=\"Frequency\",\n",
    "        ).opts(title=name, **hist_opts)\n",
    "        for name, centrality in centralities.items()\n",
    "    ]\n",
    "    return hv.Layout(plots)\n",
    "\n",
    "\n",
    "# Function to calculate communities\n",
    "def calculate_communities(graph):\n",
    "    return list(community.greedy_modularity_communities(graph))\n",
    "\n",
    "\n",
    "# Define the centralities\n",
    "centralities = {\n",
    "    \"Degree\": nx.degree_centrality,\n",
    "    \"Betweenness\": nx.betweenness_centrality,\n",
    "    \"Closeness\": nx.closeness_centrality,\n",
    "    \"Eigenvector\": nx.eigenvector_centrality,\n",
    "    \"Harmonic\": nx.harmonic_centrality,\n",
    "    \"Percolation\": nx.percolation_centrality,\n",
    "    \"PageRank\": nx.pagerank,\n",
    "}\n",
    "moves_graph_2015_2016 = create_graph(moves_df, \"2015\", \"2016\")\n",
    "# moves_graph_2016_2017 = create_graph(moves_df, \"2016\", \"2017\")\n",
    "\n",
    "# combined_graph = nx.compose(moves_graph_2015_2016, moves_graph_2016_2017)\n",
    "combined_graph = moves_graph_2015_2016\n",
    "\n",
    "# Calculate the communities\n",
    "communities = calculate_communities(combined_graph)\n",
    "print(f\"Number of communities: {len(communities)}\")\n",
    "print(f\"Communities: {communities}\")\n",
    "# Calculate the centralities\n",
    "calculated_centralities = calculate_centralities(combined_graph, centralities)\n",
    "\n",
    "# Plot the centralities\n",
    "plot_centralities(calculated_centralities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for node, attributes in moves_graph_2015_2017.nodes(data=True):\n",
    "#     print(f\"Node: {node} Attributes: {attributes}\")\n",
    "\n",
    "# gdf.sort_values(by=\"district\", inplace=True)\n",
    "# gdf[\"desc\"].iloc[0]\n",
    "\n",
    "combined_graph.edges\n",
    "# dog_owner_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def process_attribute(df, attr_col, rosters=(\"2015\", \"2016\")):\n",
    "    \"\"\"pivots on index holder_id and columns roster and values attr_col\"\"\"\n",
    "\n",
    "    dataframe = df[[\"roster\", attr_col, \"holder_id\"]]\n",
    "    dataframe = dataframe.loc[dataframe[\"roster\"].isin(rosters)]\n",
    "    df_pivot = (\n",
    "        dataframe.drop_duplicates()\n",
    "        .pivot(columns=\"roster\", values=attr_col, index=\"holder_id\")\n",
    "        .reset_index()\n",
    "    )\n",
    "    for col in df_pivot.columns:\n",
    "        if df_pivot[col].dtype.name == \"category\":\n",
    "            df_pivot[col] = df_pivot[col].cat.add_categories([0])\n",
    "            # if it is numeric with np.number fillna 0\n",
    "        elif df_pivot[col].dtype.name in [\"int64\", \"float64\"]:\n",
    "            df_pivot[col] = df_pivot[col].fillna(0)\n",
    "        else:\n",
    "            df_pivot[col] = df_pivot[col].fillna(\"\")\n",
    "\n",
    "    df_pivot = df_pivot.fillna(0)\n",
    "\n",
    "    df_pivot = df_pivot.rename(\n",
    "        columns={\n",
    "            str(roster): f\"{attr_col}_{roster}\"\n",
    "            for roster in rosters\n",
    "            if str(roster) in df_pivot.columns.values\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return df_pivot\n",
    "\n",
    "\n",
    "col_dict = {\n",
    "    \"dog_age\": [\"mean\", \"max\", \"min\"],\n",
    "    \"dog_count\": [\"mean\"],\n",
    "    \"standard\": [(\"owner\", lambda x: tuple(set(x)))],\n",
    "    \"age_group\": [(\"owner\", lambda x: tuple(set(x)))],\n",
    "    \"breed_type\": [(\"owner\", lambda x: tuple(set(x)))],\n",
    "    # \"district\": [(\"owner\", lambda x: tuple(x))],\n",
    "}\n",
    "\n",
    "\n",
    "def process_multi_attribute(df, rosters=(\"2015\", \"2016\"), attr_dict=col_dict):\n",
    "    dataframe = df[list(attr_dict.keys()) + [\"holder_id\", \"roster\"]].copy()\n",
    "    filtered_df = dataframe.loc[dataframe[\"roster\"].isin(rosters)]\n",
    "    filtered_df[\"roster\"] = filtered_df[\"roster\"].cat.remove_unused_categories()\n",
    "    df_grouped = (\n",
    "        filtered_df.groupby([\"roster\", \"holder_id\"]).agg(attr_dict).reset_index()\n",
    "    )\n",
    "    df_grouped.columns = [\"_\".join(col).strip(\"_\") for col in df_grouped.columns.values]\n",
    "\n",
    "    return df_grouped\n",
    "\n",
    "\n",
    "def ready_data(df, rosters=(\"2015\", \"2016\"), attr_dict=col_dict):\n",
    "    \"\"\"Takes in a dataframe and returns X and y ready for modeling\"\"\"\n",
    "    X = process_multi_attribute(df, rosters=rosters, attr_dict=attr_dict).dropna()\n",
    "    X_set = pd.concat(\n",
    "        [\n",
    "            process_attribute(X, col, rosters=(*rosters[:-1],))\n",
    "            for col in X.columns\n",
    "            if col not in [\"holder_id\", \"roster\"]\n",
    "        ],\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    # Drop duplicate columns\n",
    "    X_set = X_set.loc[:, ~X_set.columns.duplicated()].set_index(\"holder_id\")\n",
    "\n",
    "    # get the targets\n",
    "    targets = process_attribute(df, \"district\", rosters=rosters).set_index(\"holder_id\")\n",
    "\n",
    "    X_set = X_set.merge(targets, how=\"outer\", left_index=True, right_index=True)\n",
    "\n",
    "    # X_set.fillna(0, inplace=True)\n",
    "    y = X_set.iloc[:, -1:]\n",
    "    X_set.drop(columns=y.columns, inplace=True)\n",
    "    for col in X_set.columns:\n",
    "        if X_set[col].dtype.name == \"category\":\n",
    "            # X_set[col] = X_set[col].cat.add_categories([0])  # Remove this line\n",
    "            pass\n",
    "        elif X_set[col].dtype.name in [\"int64\", \"float64\"]:\n",
    "            X_set[col] = X_set[col].fillna(0)\n",
    "        else:\n",
    "            X_set[col] = X_set[col].fillna(\"\")\n",
    "\n",
    "    y = y.values.ravel().astype(int)\n",
    "    return X_set, y\n",
    "\n",
    "\n",
    "X_set, y = ready_data(dog_owner_df, (\"2015\", \"2016\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(X_set)\n",
    "\n",
    "columns_to_scale = [\n",
    "    col for col in X_set.columns if pd.api.types.is_numeric_dtype(X_set[col])\n",
    "]\n",
    "columns_to_encode = [\n",
    "    col\n",
    "    for col in X_set.columns\n",
    "    if col not in columns_to_scale and not col.startswith(\"district_\")\n",
    "]\n",
    "\n",
    "district_cols = [col for col in X_set.columns if col.startswith(\"district_\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder(sparse=False, handle_unknown=\"ignore\")\n",
    "for column in district_cols:\n",
    "    # Convert the district column to string\n",
    "    X_set[column] = X_set[column].astype(str)\n",
    "    encoded_features = ohe.fit_transform(X_set[column].values.reshape(-1, 1))\n",
    "    df_encoded_features = pd.DataFrame(\n",
    "        encoded_features, columns=ohe.categories_[0], index=X_set.index\n",
    "    )\n",
    "    X_set = pd.concat([X_set.drop(columns=[column]), df_encoded_features], axis=1)\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "for column in columns_to_encode:\n",
    "    encoded_features = mlb.fit_transform(X_set[column])\n",
    "    df_encoded_features = pd.DataFrame(\n",
    "        encoded_features, columns=mlb.classes_, index=X_set.index\n",
    "    )\n",
    "    X_set = pd.concat([X_set.drop(columns=[column]), df_encoded_features], axis=1)\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_set, y, stratify=y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "X_train[columns_to_scale] = scaler.fit_transform(X_train[columns_to_scale])\n",
    "\n",
    "X_test[columns_to_scale] = scaler.transform(X_test[columns_to_scale])\n",
    "print(X_set.shape, y.shape)\n",
    "display(X_train.head())\n",
    "rf_model = RandomForestClassifier(n_estimators=1000, random_state=42, n_jobs=-1)\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_pred = rf_model.predict(X_test)\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
    "\n",
    "\n",
    "print(f\"F1 Score: {f1_score(y_test, y_pred, average='weighted')}\")\n",
    "print(\n",
    "    f\"ROC AUC Score: {roc_auc_score(y_test, rf_model.predict_proba(X_test), multi_class='ovr')}\"\n",
    ")\n",
    "\n",
    "\n",
    "print(f\"Classification Report: \\n{classification_report(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHotEncoder(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Wraps `MultiLabelBinarizer` in a form that can work with `ColumnTransformer`. Note\n",
    "    that input X has to be a `pandas.DataFrame`.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.mlbs = list()\n",
    "        self.n_columns = 0\n",
    "        self.categories_ = self.classes_ = list()\n",
    "\n",
    "    def fit(self, X: pd.DataFrame, y=None):\n",
    "        for i in range(X.shape[1]):  # X can be of multiple columns\n",
    "            mlb = MultiLabelBinarizer()\n",
    "            mlb.fit(X.iloc[:, i])\n",
    "            self.mlbs.append(mlb)\n",
    "            self.classes_.append(mlb.classes_)\n",
    "            self.n_columns += 1\n",
    "        return self\n",
    "\n",
    "    def transform(self, X: pd.DataFrame):\n",
    "        if self.n_columns == 0:\n",
    "            raise ValueError(\"Please fit the transformer first.\")\n",
    "        if self.n_columns != X.shape[1]:\n",
    "            raise ValueError(\n",
    "                f\"The fit transformer deals with {self.n_columns} columns \"\n",
    "                f\"while the input has {X.shape[1]}.\"\n",
    "            )\n",
    "        result = list()\n",
    "        for i in range(self.n_columns):\n",
    "            result.append(self.mlbs[i].transform(X.iloc[:, i]))\n",
    "\n",
    "        result = np.concatenate(result, axis=1)\n",
    "        return result\n",
    "\n",
    "    def get_feature_names(self, input_features=None):\n",
    "        \"\"\"Return feature names for output features\"\"\"\n",
    "        feature_names = []\n",
    "        for i in range(self.n_columns):\n",
    "            # Get the column name\n",
    "            column_name = input_features[i] if input_features else f\"column_{i}\"\n",
    "            # Get the classes for this column\n",
    "            classes = self.classes_[i]\n",
    "            # Combine the column name and class names to create feature names\n",
    "            column_feature_names = [f\"{column_name}_{cls}\" for cls in classes]\n",
    "            # Append the feature names to the list\n",
    "            feature_names.extend(column_feature_names)\n",
    "        return feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PriorYearModel(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X: pd.DataFrame, y=None):\n",
    "        # Assume 'district_2015' is a column in X\n",
    "        self.prior_year = X.iloc[:, -1].copy()\n",
    "        # Store the unique classes and number of unique classes in y\n",
    "        self.classes_ = np.unique(y)\n",
    "        self.n_classes_ = len(self.classes_)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Return the prior year data for the given instances\n",
    "        return X.iloc[:, -1]\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        # Create an array with shape (n_samples, n_classes)\n",
    "        proba = np.zeros((X.shape[0], self.n_classes_))\n",
    "        # Get the predicted class for each sample\n",
    "        predictions = self.predict(X)\n",
    "        # Convert class labels to indices\n",
    "        predictions_indices = np.array(\n",
    "            [np.where(self.classes_ == pred)[0][0] for pred in predictions]\n",
    "        )\n",
    "        # Set the probability of the predicted class to 1 for each sample\n",
    "        for i, prediction_index in enumerate(predictions_indices):\n",
    "            proba[i, prediction_index] = 1\n",
    "        return proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the data ready for modeling\n",
    "X_set, y = ready_data(dog_owner_df, (\"2015\", \"2016\", \"2017\"))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_set, y, stratify=y, test_size=0.2, random_state=42\n",
    ")\n",
    "# list for the results\n",
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create an instance of the PriorYearModel\n",
    "prior_year_model = PriorYearModel()\n",
    "start = time.time()\n",
    "# Train the PriorYearModel\n",
    "prior_year_model.fit(X_train, y_train)\n",
    "\n",
    "# Test the PriorYearModel\n",
    "y_pred = prior_year_model.predict(X_test)\n",
    "end = time.time()\n",
    "elapsed_time = end - start\n",
    "\n",
    "# Calculate the metrics for the PriorYearModel\n",
    "prior_year_results = {\n",
    "    \"name\": \"prior_year\",\n",
    "    \"accuracy\": accuracy_score(y_test, y_pred),\n",
    "    \"f1_score\": f1_score(y_test, y_pred, average=\"macro\"),\n",
    "    \"roc_auc_score\": roc_auc_score(\n",
    "        y_test, prior_year_model.predict_proba(X_test), multi_class=\"ovo\"\n",
    "    ),\n",
    "    \"time\": elapsed_time,\n",
    "}\n",
    "results.append(prior_year_results)\n",
    "# print confusion matrix\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(f\" Classification Report: \\n{classification_report(y_test, y_pred)}\")\n",
    "# Print the results\n",
    "print(prior_year_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the numeric transformer pipeline\n",
    "numeric_transformer = Pipeline(steps=[(\"scaler\", StandardScaler(with_mean=False))])\n",
    "\n",
    "# Define the column transformer\n",
    "col_transformer = ColumnTransformer(\n",
    "    [\n",
    "        (\"multi-hot\", MultiHotEncoder(), columns_to_encode),  # Apply MultiHotEncoder to columns_to_encode\n",
    "        (\"one-hot\", OneHotEncoder(handle_unknown=\"ignore\"), district_cols),  # Apply OneHotEncoder to district_cols\n",
    "    ],\n",
    "    remainder=\"passthrough\",  # Passthrough the remaining columns\n",
    ")\n",
    "\n",
    "# Define the models\n",
    "models = [\n",
    "    (\"rf\", RandomForestClassifier(n_estimators=1000, random_state=42, n_jobs=-1)),  # Random Forest Classifier\n",
    "    (\"lgbm\", LGBMClassifier(n_estimators=1000, random_state=42, n_jobs=-1)),  # LightGBM Classifier\n",
    "    # (\"log_reg\", LogisticRegression(multi_class=\"multinomial\", n_jobs=-1)),  # Logistic Regression\n",
    "    # (\"xgb\", xgb.XGBClassifier(n_estimators=1000, random_state=42, n_jobs=-1)),  # XGBoost Classifier\n",
    "    # (\"gb\", GradientBoostingClassifier(n_estimators=1000, random_state=42)),  # Gradient Boosting Classifier\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "for i, (name, model) in enumerate(models):\n",
    "    print(f\"Training model {i+1}/{len(models)}: {name}\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    pipeline = Pipeline(\n",
    "        steps=[\n",
    "            (\"multi-hot\", col_transformer),\n",
    "            (\"scaler\", numeric_transformer),\n",
    "            (\"classifier\", model),\n",
    "        ]\n",
    "    )\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "\n",
    "    results.append(\n",
    "        {\n",
    "            \"name\": name,\n",
    "            \"accuracy\": accuracy_score(y_test, y_pred),\n",
    "            \"f1_score\": f1_score(y_test, y_pred, average=\"macro\"),\n",
    "            \"roc_auc_score\": roc_auc_score(\n",
    "                y_test, pipeline.predict_proba(X_test), multi_class=\"ovo\"\n",
    "            ),\n",
    "            \"time\": elapsed_time,\n",
    "        }\n",
    "\n",
    "    )\n",
    "    print(results[-1])\n",
    "\n",
    "    print(f\"Classification Report: \\n{classification_report(y_test, y_pred)}\")\n",
    "    print(\"--------------------------------------------------------------\")\n",
    "\n",
    "\n",
    "\n",
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the column transformer from the pipeline\n",
    "column_transformer = pipeline.named_steps[\"multi-hot\"]\n",
    "\n",
    "# Initialize an empty list to hold the feature names\n",
    "feature_names = []\n",
    "\n",
    "# Loop over each transformer in the column transformer\n",
    "for _, transformer, columns in column_transformer.transformers_:\n",
    "    print(f\"Processing columns: {columns}\")\n",
    "\n",
    "    # Check if the transformer is an instance of MultiHotEncoder\n",
    "    if isinstance(transformer, MultiHotEncoder):\n",
    "        print(f\"Classes: {transformer.classes_}\")\n",
    "\n",
    "    # Check if the transformer has a get_feature_names_out method\n",
    "    if hasattr(transformer, \"get_feature_names_out\"):\n",
    "        # Get the feature names from the transformer\n",
    "        transformer_feature_names = transformer.get_feature_names_out(\n",
    "            input_features=columns\n",
    "        )\n",
    "    else:\n",
    "        # If the transformer doesn't have a get_feature_names_out method, use the column names as feature names\n",
    "        transformer_feature_names = columns\n",
    "\n",
    "    print(f\"Feature names: {transformer_feature_names}\")\n",
    "\n",
    "    # Append the feature names to the list\n",
    "    feature_names.extend(transformer_feature_names)\n",
    "\n",
    "print(f\"Total number of features: {len(feature_names)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "# Fit the model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Create a SHAP explainer\n",
    "explainer = shap.Explainer(\n",
    "    pipeline.named_steps[\"classifier\"],\n",
    ")\n",
    "\n",
    "# Apply all transformation steps in the pipeline\n",
    "X_train_transformed = pipeline.named_steps[\"multi-hot\"].transform(X_train)\n",
    "X_train_transformed = pipeline.named_steps[\"scaler\"].transform(X_train_transformed)\n",
    "\n",
    "# Compute SHAP values\n",
    "shap_values = explainer(X_train_transformed)\n",
    "\n",
    "# Plot the SHAP values of the first prediction\n",
    "# shap.plots.waterfall(shap_values[0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.waterfall(shap_values[0, :, 0])\n",
    "shap.summary_plot(shap_values[:, :, 0], X_train_transformed)\n",
    "shap.plots.beeswarm(shap_values[:, :, 0], max_display=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "\n",
    "\n",
    "model = LGBMClassifier(objective=\"multiclass\", random_state=42)\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocessor\", col_transformer),\n",
    "        (\"scaler\", numeric_transformer),\n",
    "        (\"classifier\", model),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# Define the parameter grid\n",
    "param_distributions = {\n",
    "    \"classifier__n_estimators\": [500, 1000],\n",
    "    \"classifier__learning_rate\": [0.01, 0.1, 0.5, 1.0],\n",
    "    \"classifier__max_depth\": [3, 5, 7, 10],\n",
    "    \"classifier__class_weight\": [\"balanced\", None],\n",
    "    # add more parameters to tune\n",
    "}\n",
    "\n",
    "# Create a RandomizedSearchCV object\n",
    "random_search = RandomizedSearchCV(\n",
    "    pipeline,\n",
    "    param_distributions,\n",
    "    n_iter=10,\n",
    "    cv=4,\n",
    "    scoring=\"f1_macro\",\n",
    "    verbose=2,\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters\n",
    "print(random_search.best_params_)\n",
    "\n",
    "# Get the best model\n",
    "best_model = random_search.best_estimator_\n",
    "\n",
    "# plot the feature importance\n",
    "# lgb.plot_importance(best_model[\"classifier\"], figsize=(12, 8))\n",
    "\n",
    "# Evaluate the model\n",
    "\n",
    "\n",
    "y_pred = random_search.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(f\"F1 Score: {f1_score(y_test, y_pred, average='macro'):0.3f}\")\n",
    "print(\n",
    "    f\"ROC AUC Score: {roc_auc_score(y_test, random_search.predict_proba(X_test), multi_class='ovo'):.3f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "# Fit the model\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Create a SHAP explainer\n",
    "explainer = shap.Explainer(rf_model)\n",
    "\n",
    "# Compute SHAP values\n",
    "shap_values = explainer(X_train)\n",
    "\n",
    "# Plot the SHAP values of the first prediction\n",
    "shap.plots.waterfall(shap_values[0])\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = random_search.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(f\"F1 Score: {f1_score(y_test, y_pred, average='macro'):0.3f}\")\n",
    "print(\n",
    "    f\"ROC AUC Score: {roc_auc_score(y_test, random_search.predict_proba(X_test), multi_class='ovo'):.3f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
