{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import itertools as it\n",
    "from typing import Callable, Optional\n",
    "from contextlib import contextmanager\n",
    "import concurrent.futures as cf\n",
    "\n",
    "\n",
    "# import json\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "from urllib.request import urlopen\n",
    "from urllib.parse import urljoin\n",
    "import unicodedata\n",
    "\n",
    "# Third-party imports\n",
    "from bs4 import BeautifulSoup\n",
    "from fiona.io import ZipMemoryFile\n",
    "from lxml import etree\n",
    "import lxml\n",
    "from matplotlib import pyplot as plt\n",
    "import geopandas as gpd\n",
    "import geoviews as gv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import (\n",
    "    NoSuchElementException,\n",
    "    StaleElementReferenceException,\n",
    "    TimeoutException,\n",
    ")\n",
    "from thefuzz import fuzz\n",
    "from thefuzz import process\n",
    "from tqdm.notebook import tqdm\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# Local application imports\n",
    "from translate_app import translate_list_to_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# suppress warnings\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "pd.options.display.max_columns = 50\n",
    "pd.options.display.max_rows = 100\n",
    "pd.set_option(\"display.max_colwidth\", 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "def convert_to_snake_case(item):\n",
    "    # Add _ before uppercase in camelCase\n",
    "    s1 = re.sub(r\"(.)([A-Z][a-z]+)\", r\"\\1_\\2\", item)\n",
    "    # Add _ before uppercase following lowercase or digit\n",
    "    s2 = re.sub(r\"([a-z0-9])([A-Z])\", r\"\\1_\\2\", s1)\n",
    "    # Add _ between letter and digit\n",
    "    s3 = re.sub(r\"([a-zA-Z])([0-9])\", r\"\\1_\\2\", s2)\n",
    "    s4 = re.sub(r\"[-\\s]\", \"_\", s3).lower()  # Replace hyphen or space with _\n",
    "    return s4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def start_driver():\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--headless\")\n",
    "    driver = webdriver.Chrome(options=chrome_options)\n",
    "    try:\n",
    "        yield driver\n",
    "    finally:\n",
    "        driver.quit()\n",
    "\n",
    "\n",
    "def get_driver():\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--headless\")\n",
    "    driver = webdriver.Chrome(options=chrome_options)\n",
    "    return driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "def remove_accents(input_str):\n",
    "    \"\"\"Function to remove accents from a string.\n",
    "    It takes as argument a string and returns the same string\n",
    "    without accents.\"\"\"\n",
    "    nfkd_form = (\n",
    "        unicodedata.normalize(\"NFKD\", input_str).encode(\n",
    "            \"ASCII\", \"ignore\").decode()\n",
    "    )\n",
    "    # return \"\".join([c for c in nfkd_form if not unicodedata.combining(c)])\n",
    "    return nfkd_form\n",
    "\n",
    "\n",
    "remove_accents(\"résuméö\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "def sanitize_df_column_names(df):\n",
    "    \"\"\"Function to danitize column names by translating and conveting to snake case\"\"\"\n",
    "    column_list = df.columns.tolist()\n",
    "    # translate the column names\n",
    "    translated_dict = translate_list_to_dict(column_list)\n",
    "    # map the translated column names to the column names\n",
    "    df.rename(columns=translated_dict, inplace=True)\n",
    "    # convert the column names to snake case\n",
    "    df.columns = [convert_to_snake_case(col) for col in df.columns]\n",
    "    return df\n",
    "\n",
    "\n",
    "def rename_keys(d, prefix=\"zurich_gdf_\"):\n",
    "    return {f\"{prefix}{i}\": v for i, (k, v) in enumerate(d.items())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# define a function to match breed names using FuzzyWuzzy\n",
    "def match_breed_name(name, choices, scorer=fuzz.token_sort_ratio):\n",
    "    if name in choices:\n",
    "        return name, 100\n",
    "    mismo, score, *_ = process.extractOne(name, choices, scorer=scorer)\n",
    "    return mismo, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "def find_breed_match(\n",
    "    input_breed: str,\n",
    "    breeds_df: pd.DataFrame,\n",
    "    scoring_functions: list[Callable[[str, str], int]],\n",
    "    threshold: int = 90,\n",
    ") -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Find the match for the breed in the FCI breeds dataframe.\n",
    "    breeds_df dataframe must have both a breed_en and alt_names column.\n",
    "    \"\"\"\n",
    "    # Initialize the maximum score and best match\n",
    "    max_score = threshold\n",
    "    best_match = np.nan\n",
    "\n",
    "    # Iterate over each row in the breeds dataframe\n",
    "    for index, breed_row in breeds_df.iterrows():\n",
    "        # Get the alternative names for the current breed\n",
    "        alternative_names = breed_row[\"alt_names\"]\n",
    "\n",
    "        # Calculate the score for the input breed and each alternative name\n",
    "        # using each scoring function, and take the maximum of these scores\n",
    "        current_score = max(\n",
    "            max(\n",
    "                scoring_function(input_breed, alt_name)\n",
    "                for scoring_function in scoring_functions\n",
    "            )\n",
    "            for alt_name in alternative_names\n",
    "        )\n",
    "        # If the current score is greater than the maximum score, update the\n",
    "        # maximum score and best match\n",
    "        if current_score >= max_score:\n",
    "            best_match, max_score = breed_row[\"breed_en\"], current_score\n",
    "\n",
    "        # If the maximum score is 100, we have a perfect match and can break\n",
    "        # out of the loop early\n",
    "        if max_score == 100:\n",
    "            break\n",
    "\n",
    "    # print(\n",
    "    # f\"Best match: {best_match} | score: {max_score} | input: {input_breed}\")\n",
    "    # Return the best match\n",
    "    return best_match\n",
    "\n",
    "\n",
    "def apply_fuzzy_matching_to_breed_column(\n",
    "    dataframe: pd.DataFrame,\n",
    "    breed_column: str,\n",
    "    fci_df: pd.DataFrame,\n",
    "    scoring_functions: list[Callable[[str, str], int]],\n",
    "    threshold: int = 90,\n",
    ") -> pd.Series:\n",
    "    \"\"\"Apply fuzzy matching to the breed column in the dataframe.\"\"\"\n",
    "\n",
    "    return dataframe[breed_column].apply(\n",
    "        lambda breed: find_breed_match(\n",
    "            breed, fci_df, scoring_functions, threshold=threshold\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Info about Zurich districts\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the url of the website\n",
    "zurich_districts_url = \"https://www.zuerich.com/en/visit/about-zurich/zurichs-districts\"\n",
    "\n",
    "# get the html content of the website\n",
    "zurich_response = urlopen(zurich_districts_url)\n",
    "zurich_html_content = zurich_response.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse the html content\n",
    "zurich_soup = BeautifulSoup(zurich_html_content, \"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select all elements with id starting with 's-' and a number between 1 and 12\n",
    "pattern = re.compile(r\"s-[1-9]|s-1[0-2]\")\n",
    "elements = zurich_soup.find_all(id=pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe with the information of the districts\n",
    "districts = {element.find(\"h2\").text: element.find(\"p\").text for element in elements}\n",
    "districts_df = pd.DataFrame.from_dict(districts, orient=\"index\", columns=[\"desc\"])\n",
    "\n",
    "\n",
    "# make the index into a column and split it into district number and district name\n",
    "districts_df = districts_df.reset_index()\n",
    "districts_df = (\n",
    "    districts_df[\"index\"]\n",
    "    .str.split(\"–\", expand=True)\n",
    "    .rename({0: \"district_number\", 1: \"district_name\"}, axis=1)\n",
    "    .join(districts_df)\n",
    "    .drop(\"index\", axis=1)\n",
    ")\n",
    "# strip the whitespace from the columns\n",
    "districts_df[\"district_number\"] = districts_df[\"district_number\"].str.strip()\n",
    "# create regex to get the number from the district_number column\n",
    "regex_pattern = re.compile(r\"([\\d]+)\")\n",
    "\n",
    "# create a new column with the district number\n",
    "districts_df[\"district\"] = (\n",
    "    districts_df[\"district_number\"]\n",
    "    .str.extract(\n",
    "        regex_pattern,\n",
    "    )\n",
    "    .astype(\"category\")\n",
    ")\n",
    "districts_df.drop(\"district_number\", axis=1, inplace=True)\n",
    "\n",
    "districts_df[\"district_name\"] = districts_df[\"district_name\"].str.strip()\n",
    "districts_df[\"desc\"] = districts_df[\"desc\"].str.strip()\n",
    "\n",
    "# Add column for the length of the desc\n",
    "districts_df[\"desc_length\"] = districts_df[\"desc\"].str.len()\n",
    "\n",
    "print(districts_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "districts_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a styler object and set the wrap parameter to True\n",
    "styler = districts_df.style.set_properties(**{\"white-space\": \"pre-wrap\"})\n",
    "\n",
    "formatted_df = styler.format({\"description\": lambda x: x})\n",
    "formatted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "districts_df.to_csv(\"../data/zurich_districts.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Info for Dog breeds from hunde-zauber.de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hz_url = \"https://hunde-zauber.de/liste-aller-hunderassen-von-a-bis-z/\"\n",
    "hz_size_weight_url = \"https://hunde-zauber.de/hund-gewicht-groesse-tabelle/\"\n",
    "\n",
    "hz_response = urlopen(hz_url)\n",
    "hz_html_content = hz_response.read()\n",
    "hz_soup = BeautifulSoup(hz_html_content, \"lxml\")\n",
    "\n",
    "hz_size_weight_response = urlopen(hz_size_weight_url)\n",
    "hz_size_weight_html_content = hz_size_weight_response.read()\n",
    "hz_size_weight_soup = BeautifulSoup(hz_size_weight_html_content, \"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hz_size_weight_tree = etree.HTML(hz_size_weight_html_content)\n",
    "# get the table header\n",
    "header = hz_size_weight_tree.xpath(\"//table/thead/tr\")\n",
    "column_headers = [th.text for th in header[0].xpath(\"//th\")]\n",
    "# get the table body\n",
    "body = hz_size_weight_tree.xpath(\"//table/tbody\")\n",
    "rows = body[0].xpath(\"//tr\")\n",
    "row_data = [[td.text for td in row.xpath(\".//td\")] for row in rows]\n",
    "# convert nested list into a dataframe\n",
    "hz_size_weight_df = pd.DataFrame()\n",
    "hz_size_weight_df = pd.DataFrame(row_data[1:], columns=column_headers)\n",
    "hz_size_weight_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the first column and column names, translate them\n",
    "german_to_translate = (\n",
    "    hz_size_weight_df.iloc[:, 0].tolist() + hz_size_weight_df.columns.tolist()\n",
    ")\n",
    "translated_dict = translate_list_to_dict(german_to_translate)\n",
    "\n",
    "# Apply translations to column names and first column\n",
    "hz_size_weight_df.columns = [\n",
    "    translated_dict.get(col, col) for col in hz_size_weight_df.columns\n",
    "]\n",
    "hz_size_weight_df[\"breed_en\"] = hz_size_weight_df.iloc[:, 0].map(\n",
    "    lambda x: translated_dict.get(x, x)\n",
    ")\n",
    "\n",
    "# hz_size_weight_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hz_size_weight_df.columns = [\n",
    "    \"breed_de\",\n",
    "    \"f_height_cm\",\n",
    "    \"f_weight_kg\",\n",
    "    \"m_height_cm\",\n",
    "    \"m_weight_kg\",\n",
    "    \"breed_en\",\n",
    "]\n",
    "\n",
    "\n",
    "def split_column(df, column):\n",
    "    \"\"\"Function to extract the numbers from a column and create two new columns.\"\"\"\n",
    "    df_copy = df[[column]]\n",
    "    df_copy[[f\"{column}_low\", f\"{column}_high\"]] = df_copy[column].str.extract(\n",
    "        r\"(\\d+).*?(\\d+)\"\n",
    "    )\n",
    "    df_copy.drop(column, axis=1, inplace=True)\n",
    "    return df_copy\n",
    "\n",
    "\n",
    "columns_to_split = [\"f_height_cm\", \"f_weight_kg\", \"m_height_cm\", \"m_weight_kg\"]\n",
    "numbers_df = pd.concat(\n",
    "    [split_column(hz_size_weight_df, column) for column in columns_to_split], axis=1\n",
    ")\n",
    "hz_size_weight_df[[\"breed_de\", \"breed_en\"]].join(numbers_df)\n",
    "hz_size_weight_df[\"breed_de\"] = hz_size_weight_df[\"breed_de\"].str.lower()\n",
    "hz_size_weight_df[\"breed_en\"] = hz_size_weight_df[\"breed_en\"].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save the dataframe as a json file\n",
    "hz_size_weight_df.to_json(\"../data/hz_breeds_size.json\", orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hz_size_weight_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with start_driver() as driver:\n",
    "    driver.get(hz_url)\n",
    "    WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_element_located((By.XPATH, \"//table\"))\n",
    "    )\n",
    "    cells = driver.find_elements(By.XPATH, \"//table//td\")\n",
    "    cell_orig = [cell.text for cell in cells]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breed_de = pd.DataFrame(cell_orig)\n",
    "# for each element extract the number and the breed name ('142. English Pointer' -> '142', 'English Pointer')\n",
    "pattern = re.compile(r\"(\\d+\\.)?(.*)\")\n",
    "# put in a new column in the dataframe\n",
    "breed_de[[\"breed_number\", \"breed_de\"]] = (\n",
    "    breed_de[0]\n",
    "    .str.extract(pattern)\n",
    "    .rename({0: \"breed_number\", 1: \"breed_de\"}, axis=1)\n",
    "    .dropna()\n",
    ")\n",
    "\n",
    "breed_de.dropna(inplace=True)\n",
    "\n",
    "breed_de[\"breed_number\"] = breed_de[\"breed_number\"].str.strip(\n",
    "    \".\").astype(\"int\")\n",
    "breed_de[\"breed_de\"] = breed_de[\"breed_de\"].str.strip().str.lower()\n",
    "breed_de[\"breed_en\"] = breed_de[\"breed_de\"].map(\n",
    "    translate_list_to_dict(breed_de[\"breed_de\"].tolist())\n",
    ")\n",
    "breed_de[\"breed_en\"] = breed_de[\"breed_en\"].str.lower()\n",
    "breed_de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the dataframe as a json file\n",
    "breed_de[[\"breed_en\", \"breed_de\"]].to_json(\n",
    "    \"../data/hz_breeds.json\", orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_set = set(breed_de[\"breed_de\"].tolist()).symmetric_difference(\n",
    "    set(hz_size_weight_df[\"breed_de\"].tolist())\n",
    ")\n",
    "\n",
    "diff_set_df = pd.concat(\n",
    "    [\n",
    "        breed_de.loc[breed_de[\"breed_de\"].isin(\n",
    "            diff_set)][[\"breed_de\", \"breed_en\"]],\n",
    "        hz_size_weight_df.loc[hz_size_weight_df[\"breed_de\"].isin(diff_set)][\n",
    "            [\"breed_de\", \"breed_en\"]\n",
    "        ],\n",
    "    ],\n",
    ")\n",
    "diff_set_df.sort_values(by=\"breed_de\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Info for Dog breeds from FCI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fci_url = \"https://www.fci.be/en/Nomenclature/educationGroupe.aspx\"\n",
    "fci_response = urlopen(fci_url)\n",
    "fci_html_content = fci_response.read()\n",
    "\n",
    "fci_parsed_html = etree.HTML(fci_html_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breed_groups = {}\n",
    "elements = fci_parsed_html.xpath(\"//*[@class='nom']\")\n",
    "for element in elements:\n",
    "    breed_groups[element.text] = element.get(\"href\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fci_breeds_df = (\n",
    "    pd.DataFrame.from_dict(breed_groups, orient=\"index\", columns=[\"link\"])\n",
    "    .reset_index()\n",
    "    .rename(columns={\"index\": \"breed\"})\n",
    ")\n",
    "\n",
    "# define regex pattern to get what is in the most right brackets\n",
    "regex_pattern = re.compile(r\"\\((?=[^()]*\\))([^()]+)\\)$\")\n",
    "\n",
    "fci_breeds_df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fci_breeds_df[[\"breed_orig\", \"breed_en\"]] = fci_breeds_df[\"breed\"].str.split(\n",
    "    \"(\", n=1, expand=True\n",
    ")\n",
    "fci_breeds_df.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turned out that webpage only had 33 breeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_letters_pattern = r\"\\(?([A-Za-z-\\.\\s]+)\\)\"\n",
    "fci_breeds_df[\"breed_en\"] = fci_breeds_df[\"breed_en\"].str.extract(only_letters_pattern)\n",
    "fci_breeds_df[\"breed_en\"] = fci_breeds_df[\"breed_en\"].fillna(\n",
    "    fci_breeds_df[\"breed_orig\"].transform(lambda x: x)\n",
    ")\n",
    "fci_breeds_df[\"breed_orig\"] = fci_breeds_df[\"breed_orig\"].str.strip().str.lower()\n",
    "fci_breeds_df[\"breed_en\"] = fci_breeds_df[\"breed_en\"].str.strip().str.lower()\n",
    "# fci_breeds_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fci_breeds_df[\"weblink\"] = fci_breeds_df[\"link\"].apply(lambda x: \"www.fci.be\" + x)\n",
    "\n",
    "\n",
    "# fci_breeds_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get all the breeds from the FCI individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def click_element(driver, elements, index):\n",
    "#     try:\n",
    "#         elements[index].click()\n",
    "#     except StaleElementReferenceException:\n",
    "#         elements = driver.find_element(\n",
    "#             By.CLASS_NAME, elements[0].get_attribute(\"class\")\n",
    "#         )\n",
    "#         elements[index].click()\n",
    "\n",
    "\n",
    "# def get_fci_breed_info(driver, breeds, n2):\n",
    "#     breed_text = breeds[n2].text\n",
    "#     breed_ref = breeds[n2].get_attribute(\"href\")\n",
    "#     click_element(driver, breeds, n2)\n",
    "\n",
    "#     WebDriverWait(driver, 10).until(\n",
    "#         EC.presence_of_element_located((By.ID, \"ContentPlaceHolder1_GroupeHyperLink\"))\n",
    "#     )\n",
    "#     breed_group = driver.find_element(By.ID, \"ContentPlaceHolder1_GroupeHyperLink\").text\n",
    "#     table = driver.find_element(By.CLASS_NAME, \"racesgridview\")\n",
    "#     breed_translations = [\n",
    "#         row.find_elements(By.TAG_NAME, \"span\")[0].text\n",
    "#         for row in table.find_elements(By.TAG_NAME, \"tr\")[1:]\n",
    "#     ]\n",
    "\n",
    "#     table2 = driver.find_elements(By.CLASS_NAME, \"racetable\")\n",
    "#     left_rows2 = table2[0].find_elements(By.TAG_NAME, \"tr\")\n",
    "#     right_rows2 = table2[1].find_elements(By.TAG_NAME, \"tr\")\n",
    "\n",
    "#     breed_section = None\n",
    "#     breed_subsection = None\n",
    "#     breed_date_of_acceptance = None\n",
    "#     breed_country_of_origin = None\n",
    "\n",
    "#     for row in left_rows2:\n",
    "#         cells = row.find_elements(By.TAG_NAME, \"td\")\n",
    "#         if len(cells) >= 2:\n",
    "#             if \"subsection\" in cells[0].text.lower():\n",
    "#                 breed_subsection = cells[1].text\n",
    "#             elif \"section\" in cells[0].text.lower():\n",
    "#                 breed_section = cells[1].text\n",
    "#             elif \"date of acceptance\" in cells[0].text.lower():\n",
    "#                 breed_date_of_acceptance = cells[1].text\n",
    "\n",
    "#     breed_country_of_origin = [\n",
    "#         cells[1].text\n",
    "#         for row in right_rows2\n",
    "#         if len(cells := row.find_elements(By.TAG_NAME, \"td\")) >= 2\n",
    "#         and \"country of origin\" in cells[0].text.lower()\n",
    "#     ]\n",
    "\n",
    "#     try:\n",
    "#         table3 = driver.find_element(By.CLASS_NAME, \"varietes\")\n",
    "#         breed_varieties = [\n",
    "#             spans[0].text\n",
    "#             for variety in table3.find_elements(By.CLASS_NAME, \"variete\")\n",
    "#             if (spans := variety.find_elements(By.TAG_NAME, \"span\"))\n",
    "#         ]\n",
    "#     except NoSuchElementException:\n",
    "#         breed_varieties = []\n",
    "\n",
    "#     return (\n",
    "#         breed_text,\n",
    "#         breed_ref,\n",
    "#         breed_group,\n",
    "#         breed_translations,\n",
    "#         breed_section,\n",
    "#         breed_subsection,\n",
    "#         breed_date_of_acceptance,\n",
    "#         breed_country_of_origin,\n",
    "#         breed_varieties,\n",
    "#     )\n",
    "\n",
    "\n",
    "# def get_fci_breeds(link):\n",
    "#     name_link_list = []\n",
    "#     driver = None\n",
    "#     try:\n",
    "#         driver = get_driver()\n",
    "#         driver.get(link)\n",
    "#         WebDriverWait(driver, 10).until(\n",
    "#             EC.presence_of_element_located((By.CLASS_NAME, \"initiales\"))\n",
    "#         )\n",
    "#         letters = driver.find_element(By.CLASS_NAME, \"initiales\").find_elements(\n",
    "#             By.TAG_NAME, \"a\"\n",
    "#         )\n",
    "\n",
    "#         for n, _ in enumerate(letters):\n",
    "#             click_element(driver, letters, n)\n",
    "#             WebDriverWait(driver, 10).until(\n",
    "#                 EC.presence_of_element_located((By.CLASS_NAME, \"listeraces\"))\n",
    "#             )\n",
    "#             breeds = driver.find_element(By.CLASS_NAME, \"listeraces\").find_elements(\n",
    "#                 By.TAG_NAME, \"a\"\n",
    "#             )\n",
    "\n",
    "#             for n2, _ in enumerate(breeds):\n",
    "#                 breed_info = get_fci_breed_info(driver, breeds, n2)\n",
    "#                 name_link_list.append(breed_info)\n",
    "#                 driver.back()\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f\"An error occurred: {e}\")\n",
    "#     finally:\n",
    "#         if driver is not None:\n",
    "#             driver.quit()\n",
    "\n",
    "#     return name_link_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_breed(breed_link):\n",
    "    soup = BeautifulSoup(urlopen(breed_link).read(), \"html.parser\")\n",
    "    breed_info = {\n",
    "        \"breed_text\": soup.find(\"h2\").text.strip() if soup.find(\"h2\") else None,\n",
    "        \"link\": breed_link,\n",
    "        \"breed_group\": soup.find(id=\"ContentPlaceHolder1_GroupeHyperLink\").text.strip()\n",
    "        if soup.find(id=\"ContentPlaceHolder1_GroupeHyperLink\")\n",
    "        else None,\n",
    "        \"breed_translations\": [\n",
    "            row.find_all(\"span\")[0].text\n",
    "            for row in soup.find(class_=\"racesgridview\").find_all(\"tr\")[1:]\n",
    "        ]\n",
    "        if soup.find(class_=\"racesgridview\")\n",
    "        else None,\n",
    "        \"subsection\": next(\n",
    "            (\n",
    "                cells[1].text.strip()\n",
    "                for row in soup.find_all(class_=\"racetable\")[0].find_all(\"tr\")\n",
    "                if (cells := row.find_all(\"td\"))\n",
    "                and \"subsection\" in cells[0].text.lower()\n",
    "            ),\n",
    "            None,\n",
    "        ),\n",
    "        \"section\": next(\n",
    "            (\n",
    "                cells[1].text.strip()\n",
    "                for row in soup.find_all(class_=\"racetable\")[0].find_all(\"tr\")\n",
    "                if (cells := row.find_all(\"td\")) and \"section\" in cells[0].text.lower()\n",
    "            ),\n",
    "            None,\n",
    "        ),\n",
    "        \"date_of_acceptance\": next(\n",
    "            (\n",
    "                cells[1].text.strip()\n",
    "                for row in soup.find_all(class_=\"racetable\")[0].find_all(\"tr\")\n",
    "                if (cells := row.find_all(\"td\"))\n",
    "                and \"date of acceptance\" in cells[0].text.lower()\n",
    "            ),\n",
    "            None,\n",
    "        ),\n",
    "        \"country_of_origin\": [\n",
    "            cells[1].text.strip()\n",
    "            for row in soup.find_all(class_=\"racetable\")[1].find_all(\"tr\")\n",
    "            if (cells := row.find_all(\"td\"))\n",
    "            and \"country of origin\" in cells[0].text.lower()\n",
    "        ],\n",
    "        \"varieties\": [\n",
    "            spans[0].text\n",
    "            for variety in soup.find(class_=\"varietes\").find_all(class_=\"variete\")\n",
    "            if (spans := variety.find_all(\"span\"))\n",
    "        ]\n",
    "        if soup.find(class_=\"varietes\")\n",
    "        else [],\n",
    "    }\n",
    "    return breed_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_letter(letter, link):\n",
    "    letter_page = urlopen(link)\n",
    "    soup = BeautifulSoup(letter_page, \"html.parser\")\n",
    "\n",
    "    # Get the breeds on this page and process them\n",
    "    breeds_element = soup.find(\"ul\", {\"class\": \"listeraces\"})\n",
    "    breed_links = [urljoin(link, a[\"href\"])\n",
    "                   for a in breeds_element.find_all(\"a\")]\n",
    "    breed_info_futures = []\n",
    "    with cf.ThreadPoolExecutor() as executor:\n",
    "        breed_info_futures = [\n",
    "            executor.submit(process_breed, breed_link)\n",
    "            for breed_link in tqdm(\n",
    "                breed_links, total=len(breed_links), desc=f\"Processing {letter}\"\n",
    "            )\n",
    "        ]\n",
    "    return breed_info_futures\n",
    "\n",
    "\n",
    "def get_fci_breed_data():\n",
    "    fci_nonmenclature_url = \"https://fci.be/en/Nomenclature/Default.aspx\"\n",
    "\n",
    "    fci_response = urlopen(fci_nonmenclature_url)\n",
    "    fci_content = fci_response.read()\n",
    "    fci_soup = BeautifulSoup(fci_content, \"html.parser\")\n",
    "\n",
    "    letters_element = fci_soup.find(\"ul\", {\"class\": \"initiales\"})\n",
    "    # we have 'D':href=../../nomenclature/races.aspx?init=D\n",
    "\n",
    "    # we want https://fci.be/en/nomenclature/races.aspx?init=D so use urljoin\n",
    "    letter_link = {\n",
    "        a.text: urljoin(fci_nonmenclature_url, a[\"href\"])\n",
    "        for a in letters_element.find_all(\"a\")\n",
    "    }\n",
    "\n",
    "    with cf.ThreadPoolExecutor() as executor:\n",
    "        letter_futures = {\n",
    "            executor.submit(process_letter, letter, link)\n",
    "            for letter, link in letter_link.items()\n",
    "        }\n",
    "        fci_breed_data = []\n",
    "        for future in tqdm(\n",
    "            cf.as_completed(letter_futures),\n",
    "            total=len(letter_futures),\n",
    "            desc=\"Processing letters\",\n",
    "        ):\n",
    "            breed_info_futures = future.result()\n",
    "            for breed_future in cf.as_completed(breed_info_futures):\n",
    "                fci_breed_data.append(breed_future.result())\n",
    "        return fci_breed_data\n",
    "\n",
    "\n",
    "fci_breed_data = get_fci_breed_data()\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fci_breed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fci_breed_df = pd.DataFrame()\n",
    "fci_breeds_df = pd.DataFrame(fci_breed_data)\n",
    "fci_breeds_df.to_json(\"../data/fci_breeds_raw.json\", orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fci_breeds_df = pd.read_json(\"../data/fci_breeds_raw.json\")\n",
    "fci_breeds_df.sample()\n",
    "# fci_breeds_df[fci_breeds_df[\"breed\"] == \"KA\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the number in ()\n",
    "fci_breeds_df[\"fci_num\"] = fci_breeds_df[\"breed_text\"].str.extract(\n",
    "    r\"\\((\\d+)\\)\", expand=False\n",
    ")\n",
    "# get the name before the \\r\\n\\t\n",
    "fci_breeds_df[\"breed\"] = fci_breeds_df[\"breed_text\"].str.extract(r\"(.*?)\\r\\n\\t\")\n",
    "# add the value in the breed column to the list in the translations column in each respective row\n",
    "fci_breeds_df[\"alt_names\"] = fci_breeds_df.apply(\n",
    "    lambda x: x[\"breed_translations\"] + [x[\"breed\"]], axis=1\n",
    ")\n",
    "# convert to lower case\n",
    "fci_breeds_df[\"alt_names\"] = fci_breeds_df[\"alt_names\"].apply(\n",
    "    lambda x: [i.lower() for i in x]\n",
    ")\n",
    "# english version is the first translation\n",
    "fci_breeds_df[\"breed_en\"] = fci_breeds_df[\"breed_translations\"].apply(\n",
    "    lambda x: x[0].lower()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fci_breeds_df.loc[\n",
    "#     fci_breeds_df[\"breed_en\"].str.contains(r\"point\", case=False, regex=True)\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# edit all breeds with '- haired' in the name to remove the space and the '-'\n",
    "fci_breeds_df[\"breed_en\"] = fci_breeds_df[\"breed_en\"].str.replace(\n",
    "    r\"- ?haired\", \"haired\", regex=True\n",
    ")\n",
    "# add the 'breed_en' breed to the list in alt_names column\n",
    "fci_breeds_df[\"alt_names\"] = fci_breeds_df.apply(\n",
    "    lambda x: x[\"alt_names\"] + [x[\"breed_en\"]], axis=1\n",
    ")\n",
    "\n",
    "# create a column for the number of varieties from the varieties column\n",
    "fci_breeds_df[\"n_varieties\"] = fci_breeds_df[\"varieties\"].transform(len)\n",
    "# clean up the letter-numbering in the varieties column 'a)'\n",
    "fci_breeds_df[\"varieties\"] = fci_breeds_df[\"varieties\"].apply(\n",
    "    lambda x: [re.sub(r\"^[a-z]\\) \", \"\", i).lower() for i in x]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the group number and name from the group column\n",
    "fci_breeds_df[\"group_num\"] = fci_breeds_df[\"breed_group\"].str.extract(r\"(\\d+)\")\n",
    "fci_breeds_df[\"group_name\"] = (\n",
    "    fci_breeds_df[\"breed_group\"].str.split(\n",
    "        \"-\", n=1, expand=True)[1].str.strip()\n",
    ")\n",
    "# fci_breeds_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if there is a breed name with 'pointing dog' in its alt_names, also add the breed name with 'pointer' in its name\n",
    "fci_breeds_df[\"breed_en\"] = fci_breeds_df[\"breed_en\"].str.replace(\n",
    "    r\"pointing dog\", \"pointer\", regex=True\n",
    ")\n",
    "fci_breeds_df[\"alt_names\"] = fci_breeds_df.apply(\n",
    "    lambda x: x[\"alt_names\"] + [x[\"breed_en\"]], axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display only 3 of the the breeds with varieties\n",
    "fci_breeds_df[fci_breeds_df[\"n_varieties\"] > 0][\n",
    "    [\"breed\", \"varieties\", \"alt_names\", \"breed_en\"]\n",
    "].sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the `varieties` are just variations in size, coat-color, -hair-length of the same breed. Still, some variations are so popular that they are referred to by this variation name. We will add these variations to the their `alt_names` list.These include:\n",
    "- swiss hound\n",
    "- small swiss hound\n",
    "- german spitz\n",
    "- belgian shepherd dog\n",
    "- continental toy spaniel\n",
    "- chinese crested dog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the varieties to the alt_names column of some popular breeds\n",
    "\n",
    "\n",
    "popular_breeds = [\n",
    "    \"swiss hound\",\n",
    "    \"small swiss hound\",\n",
    "    \"german spitz\",\n",
    "    \"belgian shepherd dog\",\n",
    "    \"continental toy spaniel\",\n",
    "    \"chinese crested dog\",\n",
    "]\n",
    "\n",
    "\n",
    "popular_names_mask = fci_breeds_df[\"breed_en\"].isin(popular_breeds)\n",
    "\n",
    "\n",
    "fci_breeds_df.loc[popular_names_mask, \"alt_names\"] = (\n",
    "    fci_breeds_df.loc[popular_names_mask, \"alt_names\"]\n",
    "    + fci_breeds_df.loc[popular_names_mask, \"varieties\"]\n",
    ")\n",
    "\n",
    "fci_breeds_df.loc[\n",
    "    fci_breeds_df[\"breed_en\"].str.contains(\"belgian shepherd dog\"), \"alt_names\"\n",
    "] = fci_breeds_df.loc[\n",
    "    fci_breeds_df[\"breed_en\"].str.contains(\"belgian shepherd dog\"), \"alt_names\"\n",
    "].apply(\n",
    "    lambda x: x\n",
    "    + [\n",
    "        \"belgian sheepdog\",\n",
    "        \"belgian tervuren\",\n",
    "        \"belgian malinois\",\n",
    "        \"belgian groenendael\",\n",
    "        \"belgian laekenois\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "fci_breeds_df.loc[\n",
    "    fci_breeds_df[\"breed_en\"].str.contains(\"vallhund\"), \"alt_names\"\n",
    "] = fci_breeds_df.loc[\n",
    "    fci_breeds_df[\"breed_en\"].str.contains(\"vallhund\"), \"alt_names\"\n",
    "].apply(\n",
    "    lambda x: x + [\"westgotenspitz\"]\n",
    ")\n",
    "fci_breeds_df.loc[\n",
    "    fci_breeds_df[\"breed_en\"].str.contains(\"bernese\"), \"alt_names\"\n",
    "] = fci_breeds_df.loc[\n",
    "    fci_breeds_df[\"breed_en\"].str.contains(\"bernese\"), \"alt_names\"\n",
    "].apply(\n",
    "    lambda x: x + [\"durbachler\"]\n",
    ")\n",
    "fci_breeds_df.loc[\n",
    "    fci_breeds_df[\"breed_en\"].str.contains(\"shetland\"), \"alt_names\"\n",
    "] = fci_breeds_df.loc[\n",
    "    fci_breeds_df[\"breed_en\"].str.contains(\"shetland\"), \"alt_names\"\n",
    "].apply(\n",
    "    lambda x: x + [\"sheltie\"]\n",
    ")\n",
    "fci_breeds_df.loc[\n",
    "    fci_breeds_df[\"breed_en\"].str.contains(\"german spitz\"), \"alt_names\"\n",
    "] = fci_breeds_df.loc[\n",
    "    fci_breeds_df[\"breed_en\"].str.contains(\"german spitz\"), \"alt_names\"\n",
    "].apply(\n",
    "    lambda x: x\n",
    "    + [\n",
    "        \"wolfsspitz\",\n",
    "        \"keeshond\",\n",
    "        \"kleinspitz\",\n",
    "        \"mittelspitz\",\n",
    "        \"grossspitz\",\n",
    "        \"zwergspitz\",\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fci_breeds_df[\"no_accent\"] = fci_breeds_df[\"alt_names\"].apply(\n",
    "    lambda x: [remove_accents(i) for i in x]\n",
    ")\n",
    "# add the no_accent to the alt_names column and remove duplicates\n",
    "fci_breeds_df[\"alt_names\"] = fci_breeds_df[\"alt_names\"] + \\\n",
    "    fci_breeds_df[\"no_accent\"]\n",
    "fci_breeds_df[\"alt_names\"] = fci_breeds_df[\"alt_names\"].apply(\n",
    "    lambda x: [i.lower() for i in x]\n",
    ")\n",
    "# reduce the duplicates within each alt_names list\n",
    "fci_breeds_df[\"alt_names\"] = fci_breeds_df[\"alt_names\"].transform(set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the '()' from the alt_names\n",
    "fci_breeds_df[\"alt_names\"] = fci_breeds_df[\"alt_names\"].apply(\n",
    "    lambda x: [i.replace(\"(\", \"\").replace(\")\", \"\") for i in x]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fci_breeds_df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to json\n",
    "fci_breeds_df.to_json(\"../data/fci_breeds.json\", orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fci_breeds_df.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From AKC dog breeds page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "akc_home_url = \"https://www.akc.org/dog-breeds/\"\n",
    "\n",
    "\n",
    "def get_breed_link_info(link):\n",
    "    breed_link = {}\n",
    "    driver = get_driver()\n",
    "    try:\n",
    "        driver.get(link)\n",
    "        WebDriverWait(driver, 30).until(\n",
    "            EC.presence_of_element_located(\n",
    "                (By.XPATH, \"//select[@class='custom-select__select']/option\")\n",
    "            )\n",
    "        )\n",
    "        # navigate_to_akc_homepage(driver, link)\n",
    "        options = driver.find_elements(\n",
    "            By.XPATH, \"//select[@class='custom-select__select']/option\"\n",
    "        )\n",
    "        for option in options:\n",
    "            breed_link[option.text] = option.get_attribute(\"value\")\n",
    "        print(f\"Number of breeds: {len(breed_link)}\")\n",
    "\n",
    "        return breed_link\n",
    "    except TimeoutException:\n",
    "        print(f\"Timeout while loading page: {link}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while loading page: {link}\\n{e}\")\n",
    "    finally:\n",
    "        driver.quit()\n",
    "\n",
    "\n",
    "# get the links for each breed\n",
    "breed_link = get_breed_link_info(akc_home_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function which takes the column names and creates a column with a unique list of those column values in each row\n",
    "def create_alt_names(dataframe, list_of_columns):\n",
    "    \"\"\"creates a column with a unique list of those column values in each row\"\"\"\n",
    "    dataframe[\"alt_names\"] = dataframe[list_of_columns].apply(\n",
    "        lambda row: set(x for x in row if pd.notna(x)), axis=1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breed_link"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AKC physical traits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "akc_breed_link_dict = {\n",
    "    key.lower(): value for (key, value) in breed_link.items() if value != \"\"\n",
    "}\n",
    "len(akc_breed_link_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_breed_info(page_source):\n",
    "    \"\"\"Function to get the breed info from the AKC website.\"\"\"\n",
    "    breed_metadata = defaultdict(str)\n",
    "\n",
    "    soup = BeautifulSoup(page_source, \"html.parser\")\n",
    "\n",
    "    def extract_text(tag, class_name):\n",
    "        \"\"\"Helper function to extract text from a tag with error handling.\"\"\"\n",
    "        try:\n",
    "            return soup.find(tag, {\"class\": class_name}).text\n",
    "        except AttributeError:\n",
    "            return \"\"\n",
    "\n",
    "    # Extract breed, temperment, popularity rank,  year recognized, group\n",
    "    breed_metadata[\"breed_page\"] = extract_text(\"h1\", \"page-header__title\")\n",
    "    breed_metadata[\"temperment\"] = extract_text(\n",
    "        \"p\", \"breed-page__intro__temperment\")\n",
    "    breed_metadata[\"popularity\"] = extract_text(\n",
    "        \"span\", \"breed-page__popularity__custom-label\"\n",
    "    )\n",
    "    breed_metadata[\"year_recognized\"] = extract_text(\n",
    "        \"p\", \"breed-page__popularity__ranking-title\"\n",
    "    )\n",
    "    breed_metadata[\"group\"] = extract_text(\n",
    "        \"a\", \"breed-page__intro__group__tooltip\")\n",
    "\n",
    "    # Extract height, weight, life expectancy\n",
    "    try:\n",
    "        element = soup.find(\n",
    "            \"div\", {\"class\": \"breed-page__hero__overview__icon-block-wrap\"}\n",
    "        )\n",
    "        attribute_map = {\n",
    "            \"height\": \"height\",\n",
    "            \"weight\": \"weight\",\n",
    "            \"life expectancy\": \"life_expectancy\",\n",
    "        }\n",
    "        for ele in element:\n",
    "            for attribute, key in attribute_map.items():\n",
    "                if attribute in ele.text.lower():\n",
    "                    breed_metadata[key] = ele.text\n",
    "    except AttributeError:\n",
    "        breed_metadata[\"height\"] = \"\"\n",
    "        breed_metadata[\"weight\"] = \"\"\n",
    "        breed_metadata[\"life_expectancy\"] = \"\"\n",
    "\n",
    "    return breed_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "SELECTORS = [\n",
    "    \"h1.page-header__title\",\n",
    "    \"p.breed-page__intro__temperment\",\n",
    "    \"div.breed-page__hero__overview__icon-block-wrap\",\n",
    "    \"div.breed-page__intro__group\",\n",
    "]\n",
    "\n",
    "\n",
    "def navigate_to_page(driver, link):\n",
    "    \"\"\"Navigate to the page and return the page source.\"\"\"\n",
    "    try:\n",
    "        driver.get(link)\n",
    "        # Wait for the specific elements to be loaded\n",
    "        for selector in SELECTORS:\n",
    "            WebDriverWait(driver, 20).until(\n",
    "                EC.presence_of_element_located((By.CSS_SELECTOR, selector))\n",
    "            )\n",
    "        # Get the webpage's HTML content\n",
    "        return driver.page_source\n",
    "    except TimeoutException:\n",
    "        print(f\"Timeout while loading page: {link}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while loading page: {link}\\n{e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def get_contents(breed, link):\n",
    "    driver = get_driver()\n",
    "    try:\n",
    "        page_source = navigate_to_page(driver, link)\n",
    "        if page_source is not None:\n",
    "            breed_info = get_breed_info(page_source)\n",
    "            breed_info[\"breed\"] = breed\n",
    "            return breed_info\n",
    "            # return parse_page_source(page_source)\n",
    "    except TimeoutException:\n",
    "        print(f\"Timeout while loading page: {link}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while loading page: {link}\\n{e}\")\n",
    "    finally:\n",
    "        driver.quit()\n",
    "\n",
    "\n",
    "with cf.ThreadPoolExecutor() as executor:\n",
    "    futures = {\n",
    "        executor.submit(get_contents, breed, link)\n",
    "        for breed, link in akc_breed_link_dict.items()\n",
    "    }\n",
    "    breed_data = list(\n",
    "        tqdm(\n",
    "            (future.result() for future in cf.as_completed(futures)),\n",
    "            total=len(akc_breed_link_dict),\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# breed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breed_data = [x for x in breed_data if x is not None]\n",
    "\n",
    "akc_physical_traits = pd.DataFrame(breed_data)\n",
    "akc_physical_traits[\"breed\"] = (\n",
    "    akc_physical_traits[\"breed\"]\n",
    "    .str.lower()\n",
    "    .str.replace(\"-\", \" \")\n",
    "    .str.replace(\"'\", \"\")\n",
    "    .apply(remove_accents)\n",
    ")\n",
    "# add comments\n",
    "\n",
    "\n",
    "def parse_range(s):\n",
    "    if isinstance(s, str):\n",
    "        numbers = list(map(float, re.findall(r\"\\d+(?:\\.\\d+)?\", s)))\n",
    "        if numbers:\n",
    "            return numbers + [None] * (2 - len(numbers))\n",
    "    return [None, None]\n",
    "\n",
    "\n",
    "def get_upper_lower_bound(dataframe, column):\n",
    "    \"\"\"Parse a range string and return the lower and upper bounds.\"\"\"\n",
    "    dataframe[column + \"_ll\"], dataframe[column + \"_ul\"] = zip(\n",
    "        *dataframe[column].map(parse_range)\n",
    "    )\n",
    "    dataframe[column + \"_ul\"].fillna(dataframe[column + \"_ll\"], inplace=True)\n",
    "\n",
    "\n",
    "# add in the columns of the upper and lower bounds for height, weight, and life expectancy\n",
    "get_upper_lower_bound(akc_physical_traits, \"weight\")\n",
    "get_upper_lower_bound(akc_physical_traits, \"height\")\n",
    "get_upper_lower_bound(akc_physical_traits, \"life_expectancy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "akc_physical_traits[\"group\"] = akc_physical_traits[\"group\"].str.strip(\" »\")\n",
    "akc_physical_traits[\"breed_page\"] = akc_physical_traits[\"breed_page\"].str.lower()\n",
    "akc_physical_traits[\"year_accepted\"] = akc_physical_traits[\n",
    "    \"year_recognized\"\n",
    "].str.extract(r\"(\\d{4})\")\n",
    "akc_physical_traits[\"is_recognized_breed\"] = akc_physical_traits[\n",
    "    \"year_accepted\"\n",
    "].notna()\n",
    "\n",
    "create_alt_names(akc_physical_traits, [\"breed_page\", \"breed\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{akc_physical_traits.shape=}\")\n",
    "akc_physical_traits.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "akc_physical_traits.sample(3)\n",
    "# akc_physical_traits.group.value_counts()\n",
    "# akc_physical_traits.popularity.value_counts()\n",
    "# akc_physical_traits.sort_values(by=[\"life_expectancy_ll\"])\n",
    "\n",
    "akc_physical_traits.query('popularity==\"1 of 201\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "columns_to_drop = ['height', 'weight', 'year_recognized', 'life_expectancy', ]\n",
    "\n",
    "# save dataframe to a json file\n",
    "akc_physical_traits.to_json(\"../data/akc_breeds.json\", orient='records')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matching breeds among the breeds lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fuzz_funcs = [\n",
    "    fuzz.WRatio,\n",
    "    fuzz.UWRatio,\n",
    "    fuzz.UQRatio,\n",
    "    fuzz.token_set_ratio,\n",
    "    fuzz.token_sort_ratio,\n",
    "    # fuzz.partial_token_sort_ratio,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FCI breeds\n",
    "fci_breeds_df = pd.read_json(\"../data/fci_breeds.json\", orient=\"records\")\n",
    "\n",
    "\n",
    "fci_breeds_df[\"alt_names\"] = fci_breeds_df[\"alt_names\"].transform(set)\n",
    "fci_breeds_df.sample().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AKC breeds\n",
    "new_akc_df = pd.read_json(\"../data/akc_breeds.json\", orient=\"records\")\n",
    "new_akc_df[\"breed_en\"] = new_akc_df[\"breed\"].copy()\n",
    "new_akc_df[\"alt_names\"] = new_akc_df[\"alt_names\"].apply(\n",
    "    lambda x: [i for i in x if i is not None]\n",
    ")\n",
    "new_akc_df[\"alt_names\"] = new_akc_df[\"alt_names\"].transform(set)\n",
    "\n",
    "new_akc_df[\"match_breed\"] = None\n",
    "new_akc_df.sample().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_akc_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the akc breeds with the fci breeds\n",
    "\n",
    "akc_nan_mask = new_akc_df[\"match_breed\"].isna()\n",
    "print(f\"Nan count:{akc_nan_mask.sum()} |Column: match_breed \")\n",
    "# find matches for the fci breeds which match the akc breeds\n",
    "new_akc_df.loc[akc_nan_mask, \"match_breed\"] = apply_fuzzy_matching_to_breed_column(\n",
    "    new_akc_df.loc[akc_nan_mask], \"breed_en\", fci_breeds_df, fuzz_funcs\n",
    ")[akc_nan_mask]\n",
    "\n",
    "akc_nan_mask = new_akc_df[\"match_breed\"].isna()\n",
    "print(f\"Nan count:{akc_nan_mask.sum()} |Column: match_breed \")\n",
    "# group for when 1 fci breed matches more than 1 akc breed eg. belgian shephard dog\n",
    "akc_grouped = (\n",
    "    new_akc_df.groupby(\"match_breed\")[\"alt_names\"]\n",
    "    .apply(lambda x: set.union(*x))\n",
    "    .reset_index()\n",
    ")\n",
    "# merge the akc breeds with the fci breeds\n",
    "fci_akc_breeds = fci_breeds_df.merge(\n",
    "    akc_grouped,\n",
    "    how=\"left\",\n",
    "    left_on=\"breed_en\",\n",
    "    right_on=\"match_breed\",\n",
    "    suffixes=(\"_fci\", \"_akc\"),\n",
    ")\n",
    "# add any variation in the breed to the alt_names column\n",
    "fci_akc_breeds[\"alt_names\"] = fci_akc_breeds.apply(\n",
    "    lambda row: row[\"alt_names_fci\"].union(row[\"alt_names_akc\"])\n",
    "    if pd.notnull(row[\"match_breed\"])\n",
    "    else row[\"alt_names_fci\"],\n",
    "    axis=1,\n",
    ")\n",
    "# add the unmatched akc breeds  to the fci_akc_breeds dataframe\n",
    "fci_akc_breeds = (\n",
    "    pd.concat(\n",
    "        [\n",
    "            fci_akc_breeds[[\"breed_en\", \"alt_names\"]],\n",
    "            new_akc_df[akc_nan_mask][[\"breed_en\", \"alt_names\"]],\n",
    "        ]\n",
    "    )\n",
    "    .sort_values(\"breed_en\")\n",
    "    .reset_index(drop=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unrecognized_breeds = [\n",
    "#     \"waller\",\n",
    "#     \"tamaskan\",\n",
    "#     \"ratonero bodeguero\",\n",
    "#     \"bobtail\",\n",
    "#     \"elo\",\n",
    "#     \"bardino majorero\",\n",
    "# ]\n",
    "# unrecog_df = pd.DataFrame(\n",
    "#     ((breed, {breed}) for breed in unrecognized_breeds),\n",
    "#     columns=[\"breed_en\", \"alt_names\"],\n",
    "# )\n",
    "# fci_akc_breeds = pd.concat([fci_akc_breeds, unrecog_df]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hz website breeds\n",
    "hz_breeds_df = pd.read_json(\"../data/hz_breeds.json\", orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_breeds = translate_list_to_dict(breeds)\n",
    "# hz_breeds_df = hz_size_weight_df[[\"breed_de\", \"breed_en\"]]\n",
    "# Remove the accents from the German breed names\n",
    "hz_breeds_df[\"no_accents\"] = hz_breeds_df[\"breed_de\"].apply(remove_accents)\n",
    "hz_breeds_df[\"combined_breeds\"] = hz_breeds_df.apply(\n",
    "    lambda row: {row[\"breed_de\"], row[\"breed_en\"], row[\"no_accents\"]}, axis=1\n",
    ")\n",
    "\n",
    "hz_breeds_df[\"match_breed\"] = None\n",
    "\n",
    "columns_to_match = [\"breed_de\", \"breed_en\", \"no_accents\"]\n",
    "\n",
    "for column in columns_to_match:\n",
    "    nan_mask = hz_breeds_df[\"match_breed\"].isna()\n",
    "    print(f\"Nan count:{nan_mask.sum()} |Column: {column} \")\n",
    "\n",
    "    hz_breeds_df.loc[nan_mask, \"match_breed\"] = apply_fuzzy_matching_to_breed_column(\n",
    "        hz_breeds_df.loc[nan_mask],\n",
    "        column,\n",
    "        fci_akc_breeds,\n",
    "        fuzz_funcs,\n",
    "    )[nan_mask]\n",
    "\n",
    "    nan_mask = hz_breeds_df[\"match_breed\"].isna()\n",
    "    print(f\"Nan count:{nan_mask.sum()} |Column: {column} \")\n",
    "    # print(f\"Number of NaNs after matching on {column}: {nan_mask.sum()}\")\n",
    "\n",
    "hz_breeds_grouped = (\n",
    "    hz_breeds_df.groupby(\"match_breed\")[\"combined_breeds\"]\n",
    "    .apply(lambda x: set.union(*x))\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Then, merge the two dataframes on the column that they share\n",
    "merged_df = pd.merge(\n",
    "    fci_akc_breeds,\n",
    "    hz_breeds_grouped,\n",
    "    how=\"left\",\n",
    "    left_on=\"breed_en\",\n",
    "    right_on=\"match_breed\",\n",
    ")\n",
    "merged_df[\"was_merged\"] = ~merged_df[\"match_breed\"].isna()\n",
    "\n",
    "# Then, apply the function to add 'combined_breeds' to 'alt_names'\n",
    "merged_df[\"alt_names\"] = merged_df.apply(\n",
    "    lambda row: row[\"alt_names\"].union(row[\"combined_breeds\"])\n",
    "    if pd.notnull(row[\"match_breed\"])\n",
    "    else row[\"alt_names\"],\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "# If you want to update the original fci_breeds_df DataFrame, you can do so\n",
    "fci_akc_breeds = merged_df.drop(columns=[\"combined_breeds\", \"match_breed\"])\n",
    "nan_mask = hz_breeds_df[\"match_breed\"].isna()\n",
    "print(f\"{nan_mask.sum()} NaN values remaining.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fci_akc_breeds.to_json(\"../data/fci_akc_breeds.json\", orient=\"records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "matching the akc breeds to the FCI breeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hz_breeds_df.query('breed_en.str.contains(\"elo\")').head(50)\n",
    "\n",
    "hz_breeds_df.loc[\n",
    "    (\n",
    "        hz_breeds_df[\"combined_breeds\"].apply(\n",
    "            lambda x: any(i in x for i in unrecognized_breeds)\n",
    "        )\n",
    "    )\n",
    "]\n",
    "\n",
    "\n",
    "# new_akc_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wikipedia list of breeds of dogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog_breeds_list_url = \"https://en.wikipedia.org/wiki/List_of_dog_breeds\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_breeds(driver, link):\n",
    "    \"\"\"Function to get the breeds from the wikipedia page.\"\"\"\n",
    "    breeds = []\n",
    "    driver.get(link)\n",
    "    try:\n",
    "        # get all the elements with the dog breeds\n",
    "        div_cols = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_all_elements_located((By.CLASS_NAME, \"div-col\"))\n",
    "        )\n",
    "        # get the breeds in each div_col except the last\n",
    "        for div_col in div_cols[:-1]:\n",
    "            breed_elements = div_col.find_elements(By.TAG_NAME, \"li\")\n",
    "            for breed_element in breed_elements:\n",
    "                breeds.append(breed_element.text)\n",
    "\n",
    "    except NoSuchElementException as e:\n",
    "        print(\"No such element\", e)\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "    return breeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_d = start_driver()\n",
    "breed_driver = partial(get_breeds, my_d)\n",
    "\n",
    "breeds_list = breed_driver(dog_breeds_list_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removethe [\\d] from the breed names\n",
    "new_breed_list = [re.sub(r\"\\[\\d+\\]\", \"\", breed) for breed in breeds_list]\n",
    "new_breed_list = [breed.upper() for breed in new_breed_list]\n",
    "# show nnumber of breeds\n",
    "len(new_breed_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
